{
  "0": {
    "question": "What is the effect of performing a left-swap on a binary vector y at index j\u2032?",
    "ground_truth": "The left-swap increases the number of misclassified pairs by one.",
    "selected_figures_names": [
      "1709.02418v2-Figure1-1.png"
    ],
    "all_figures_names": [
      "1709.02418v2-Figure1-1.png",
      "1709.02418v2-Figure2-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 3,
    "rationale": "Image 0 visually demonstrates the effect of a left-swap on a binary vector, showing how it increases the number of misclassified pairs. Text 3 explains the concept of left-swapping and its impact on misclassification, which directly answers the question.",
    "answer": "Performing a left-swap on a binary vector y at index j\u2032 increases the number of misclassified pairs by one.",
    "text_chunks": [
      "This results in a proof that the number of possible ground-truth binary labelings, for any given value of n_1 and for which a given vector of guesses misclassifies d pairs of examples, is equal to the number of points in a n_1-dimensional discrete simplex \\Delta^{n_1_{d that has been truncated by the additional constraint that n_0 \\geq s_1\\geq \\ldots \\geq s_{n_1. To get started, we first define ``left-swap'' and ``right-most configuration'' more precisely: \\] Function \\rho is said to perform k consecutive left-swaps on {\\bf y from index i. \\end{definition Notice that \\tilde{\\mathcal{L_0 = (\\mathcal{L_0({\\bf y) \\setminus \\{ i' \\) \\cup \\{",
      "To generate a vector {\\bf y such that h({\\bf y, \\hat{\\bf y)=d for any desired d\\in\\{0,\\ldots,q\\, we start with a vector {\\bf r in ``right-most configuration'' -- i.e., where all the 0s occur to the left of all the 1s -- because (as we will show) h({\\bf r, \\hat{\\bf y)=0. We then apply a sequence of multiple left-swaps to each of the 1s in {\\bf r, and count the number of ways of doing so such that the total number is d. Because we want to determine the number of unique vectors {\\bf y such that h({\\bf y, \\hat{\\bf y)=d, we restrict the numbers s_1,\\ldots,s_{n_1 of left-swaps applied to the n_1 different 1s in {\\bf r so that s_i\\geq s_j for all i<j.",
      "Recursion Relation We can derive a recursion relation for v(n_0, n_1, d) as follows: Given any binary vector {\\bf r of length n, with n_1 1s, in right-most configuration, we can apply k \\in \\{0, 1, \\ldots, \\min(d,n_0)\\ left-swaps on {\\bf r from index n-n_1+1 (i.e., from the left-most 1) to yield {\\bf y = \\rho({\\bf r, n-n_1+1, k). Then the vector (y_{n-n_1-k+2, y_{n-n_1-k+3, y_{n-n_1-k+4, \\ldots, y_n) (i.e., the last n_1-1+k elements of {\\bf y) consists of k 0s followed by (n_1-1) 1s; in other words, it is in right-most configuration.",
      "Since we assume (without loss of generality) that the contestant's guesses are ordered such that \\hat{y_i < \\hat{y_j \\iff i <j , then we can simplify the definition of h to be: Computing the Exact Number of Binary Labelings for which AUC=c In this paper, we are interested in determining the number of unique binary vectors {\\bf y \\in \\{0,1\\^n such that the contestant's guesses \\hat{\\bf y \\in \\mathbb{R^n achieve a fixed AUC of c. The bulk of the effort is to derive a recursive formula for the number of unique binary vectors with a fixed number n_1 of 1s that give the desired AUC value. {\\bf Intuition: Given a real-valued vector \\hat{\\bf y representing the contestant's guesses and a corresponding binary vector {\\bf y representing the ground-truth test labels, the number h({\\bf y, \\hat{\\bf y) of misclassified pairs of examples (such that each pair contains one example from each class) can be increased by 1 by ``left-swapping'' any occurrence of 1 in {\\bf y (at index j') with a 0 that occurs immediately to the left of it (i.e., at index j'-1) -- see Figure .",
      "Thus, by iterating over all possible k and computing for each choice how many more left-swaps are necessary to reach a total of d, we can define v recursively: \\[ v(n_0, n_1, d) = \\sum_{k=0^{\\min(d,n_0) v(k, n_1-1, d-k) \\] with initial conditions: Dynamic programming using a three-dimensional memoization table can be used to compute v in time O(n_0 n_1 d). Moreover, the recursive algorithm above can also be used constructively (though with large space costs) to compute the set of all binary vectors {\\bf y of length n, of which n_1 are 1, such that h({\\bf y, \\hat{\\bf y)=d for any d; conceivably, this could be useful for performing some kind of attack that uses the set of all compatible binary ground-truth vectors to improve the contestant's accuracy \\citep{Whitehill2016. In order to apply this construction, the test examples must first be sorted in increasing value of the contestant's guesses; the constructive algorithm is then applied to generate all possible {\\bf y; and then the components of each of the possible binary vectors must be reordered to recover the original order of the test examples.",
      "+ \\sum_{\\substack{j\\in\\\\ \\mathcal{L_1\\setminus\\{j'\\ \\mathbb{I[j'>j] \\quad + \\mathbb{I[j'>i'] \\\\ \\] Since i'+1=j', then there cannot exist any index i \\in \\mathcal{L_0\\setminus\\{i'\\ whose value is ``between'' i' and j'; in other words, i>i' \\iff i>j' for every i\\in \\mathcal{L_0\\setminus\\{i'\\. Similarly, j'>j \\iff i'>j for every j\\in \\mathcal{L_1\\setminus\\{j'\\. Hence: \\[ h({\\bf z,\\hat{\\bf y)",
      "j' \\, and hence \\mathcal{L_0({\\bf y)\\setminus\\{i'\\ = \\tilde{\\mathcal{L_0({\\bf z ) \\setminus \\{ j' \\. Similarly, \\tilde{\\mathcal{L_1\\setminus\\{i'\\ = \\mathcal{L_1\\setminus\\{j'\\. Then we have: \\[ h({\\bf z,\\hat{\\bf y) = \\sum_{\\substack{i\\in\\\\ \\mathcal{L_0\\setminus\\{i'\\ \\sum_{\\substack{j\\in\\\\ \\mathcal{L_1\\setminus\\{j'\\ \\mathbb{I[i>j] + \\sum_{\\substack{i\\in\\\\ \\mathcal{L_0\\setminus\\{i'\\ \\mathbb{I[i>i']",
      "showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by . They showed a weak form of lower bound on the number of possible binary ground-truth vectors {\\bf y \\in \\{0,1\\^n for which the contestant's guesses \\hat{\\bf y achieve any fixed AUC c. Specifically, for every AUC value c=p/q\\in (0,1), there exists an infinite sequence of dataset sizes (n = 4q, 8q, 12q, \\ldots) such that the number of satisfying ground-truth vectors {\\bf y\\in \\{0,1\\^n grows exponentially in n. However, this result does not preclude the possibility that there might be certain pathological cases -- combinations of p, q, n_0, and n_1 -- for which the number of satisfying ground-truth vectors is actually much smaller."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 3,\n    \"Rationale\": \"Image 0 visually demonstrates the effect of a left-swap on a binary vector, showing how it increases the number of misclassified pairs. Text 3 explains the concept of left-swapping and its impact on misclassification, which directly answers the question.\",\n    \"Answer\": \"Performing a left-swap on a binary vector y at index j\u2032 increases the number of misclassified pairs by one.\"\n}"
  }
}