{
  "0": {
    "question": "How does the performance of the two-way AdaQA model compare to the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset?",
    "ground_truth": "The two-way AdaQA model significantly outperforms the one-way AdaQA model and all other CNN-based baseline models on the WikiQA dataset. This is evident from the higher MAP and MRR values achieved by the two-way model (0.7107 and 0.7304 respectively) compared to the one-way model (0.7005 and 0.7161) and the baseline models.",
    "selected_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 5,
    "rationale": "Image 2 provides a direct comparison of the performance of the two-way AdaQA model with the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset. Text chunk 5 discusses the role of different modules in the AdaQA model, which is relevant to understanding the performance differences.",
    "answer": "The two-way AdaQA model outperforms the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset. Specifically, the two-way AdaQA model with attention achieves the highest MAP and MRR scores, indicating superior performance.",
    "text_chunks": [
      "The same trend is also observed on the SelQA dataset (as shown in Table~), which is a much larger dataset than WikiQA. Notably, our model yields significantly better results than an attentive pooling network and ABCNN (attention-based CNN) baselines. We attribute the improvement to two potential advantages of our AdaQA model: (\\romannumeral1) for the two previous baseline methods, the interaction between question and answer takes place either before or after convolution.",
      "Note that the self-adaptive ACNN model variant, which generates filters only for the input itself (without any interactions before the top matching module), slightly outperforms the vanilla CNN Siamese model. Combined with the results in document categorization experiments, we believe that our ACNN framework, in its simplest form, can be utilized as a powerful feature extractor for transforming natural language sentences into fixed-length vectors. More importantly, our two-way AdaQA model exhibits superior results compared with the one-way variant as well as other CNN-based baseline models on the WikiQA dataset.",
      "As illustrated in Table~, our two-way AdaQA model again exhibits superior performances compared with basic CNN models (as reported in ). Discussion \\vspace{-1mm \\paragraph{Reasoning ability To associate the improved answer sentence selection results with the reasoning capabilities of our AdaQA model , we further categorize the questions in the WikiQA test set into 5 types containing: `What', `Where', `How', `When' or `Who'.",
      "To evaluate the effectiveness of proposed AdaQA model, we compare it with several CNN-based sequence matching baselines, including Vanilla CNN \\citep{jurczyk2016selqa,santos2017learning, attentive pooling networks \\citep{dos2016attentive, and ABCNN \\citep{yin2015abcnn (where an attention mechanism is employed over the two sentence representations). \\paragraph{Evaluation Metrics For document categorization and paraphrase identification tasks, we employ the percentage of correct predictions on the test set to evaluate and compare different models. For the answer sentence selection task, mean average precision (MAP) and mean reciprocal rank (MRR) are utilized as the corresponding evaluation metrics.",
      "This observation indicates that the bidirectional filter generation mechanism is strongly associated with the performance gains. While combined with the multi-perspective attention layers, adopted after the ACNN encoding layer, our two-way AdaQA model achieves even better performance. This suggests that the proposed strategy is complementary, in terms of the incorporation of rich contextual information, to the standard attention mechanism.",
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods.",
      "We then calculate the MAP scores of the basic CNN and our AdaQA model on different question types. Similar to the findings in , we observe that the `How' question is the hardest to answer, with the lowest MAP scores. However, our AdaQA model improves most over the basic CNN on the `How' type question, see Figure~(b).",
      "So motivated, we propose an adaptive CNN-based question-answer (AdaQA) model for this problem. The AdaQA model can be divided into three modules: filter generation, adaptive convolution, and matching modules, as depicted schematically in Figure~. Assume there is a question-answer pair to be matched, represented by word-embedding matrices, i.e. \\boldsymbol{Q \\in \\mathbb{R^{T_q"
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 5,\n    \"Rationale\": \"Image 2 provides a direct comparison of the performance of the two-way AdaQA model with the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset. Text chunk 5 discusses the role of different modules in the AdaQA model, which is relevant to understanding the performance differences.\",\n    \"Answer\": \"The two-way AdaQA model outperforms the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset. Specifically, the two-way AdaQA model with attention achieves the highest MAP and MRR scores, indicating superior performance.\"\n}"
  },
  "1": {
    "question": "How does the ACNN framework learn context-sensitive filters?",
    "ground_truth": "The ACNN framework learns context-sensitive filters through two modules: the filter generation module and the adaptive convolution module. The filter generation module produces a set of filters conditioned on the input sentence, while the adaptive convolution module applies the generated filters to an input sentence. The two modules are jointly differentiable, and the overall architecture can be trained in an end-to-end manner.",
    "selected_figures_names": [
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Figure3-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 1,
    "rationale": "Image 0 visually represents the ACNN framework, showing the filter generation and convolution modules, which are key to understanding how context-sensitive filters are learned. Text 1 explains the architecture, detailing the filter generation and adaptive convolution modules, which are crucial for learning context-sensitive filters.",
    "answer": "The ACNN framework learns context-sensitive filters through a filter generation module that produces filters conditioned on the input sentence, and an adaptive convolution module that applies these filters. This architecture allows the filters to be sample-specific, enhancing the model's predictive power.",
    "text_chunks": [
      "In this regard, we propose a novel bidirectional filter generation mechanism to allow interactions between sentence pairs while constructing context-sensitive representations. We investigate the effectiveness of our Adaptive Context-sensitive CNN (ACNN) framework on several text processing tasks: ontology classification, sentiment analysis, answer sentence selection and paraphrase identification. We show that the proposed methods consistently outperforms the standard CNN and attention-based CNN baselines.",
      "The proposed architecture to learn context-sensitive filters is composed of two principal modules: (\\romannumeral1) a filter generation module, which produces a set of filters conditioned on the input sentence; and (\\romannumeral2) an adaptive convolution module, which applies the generated filters to an input sentence (this sentence may be either the same as or different from the first input, as discussed further in Section~). The two modules are jointly differentiable, and the overall architecture can be trained in an end-to-end manner. Since the generated filters are sample-specific, our ACNN feature extractor for text tends to have stronger predictive power than a basic CNN encoder.",
      "It can be observed that the filters for documents with the same label (ontology) are grouped into clusters, indicating that for different types of document, ACNN has leveraged distinct convolutional filters for better feature extraction. \\vspace{-1mm Conclusions \\vspace{-2mm We presented a context-sensitive convolutional filter-generation mechanism, introducing a meta network to adaptively produce a set of input-aware filters.",
      "However, these approaches suffer from the problem of high matching complexity, since a similarity matrix between pairwise words needs to be computed, and thus it is computationally inefficient or even prohibitive when applied to long sentences \\citep{mou2015natural. In this paper, we propose a generic approach to learn context-sensitive convolutional filters for natural language understanding. In contrast to traditional CNNs, the convolution operation in our framework does not have a fixed set of filters, and thus provides the network with stronger modeling flexibility and capacity.",
      "Notably, according to our experiments, the proposed filter generation module can be readily combined with (standard) attention mechanisms to further enhance the modeling expressiveness of CNN encoder. Experimental Setup \\paragraph{Datasets We investigate the effectiveness of the proposed ACNN framework on both document classification and text sequence matching tasks. Specifically, we consider two large-scale document classification datasets: Yelp Reviews Polarity, and DBPedia ontology datasets \\citep{zhang2015character.",
      "Connections to attention mechanism The adaptive context-sensitive filter generation mechanism proposed here bears close resemblance to attention mechanism widely adopted in the NLP community, in the sense that both methods intend to incorporate rich contextual information into text representations. However, attention is typically operated on top of the hidden units preprocessed by CNN or LSTM layers, and assigns different weights to each unit according to a context vector. By contrast, in our context-sensitive filter generation mechanism, the contextual information is inherently encoded into the convolutional filters, which directly interact with the input sentence during the convolution encoding operation.",
      "Notably, there are no additional parameters in the adaptive convolution module (no bias term is employed). Our ACNN framework can be seen as a generalization of the basic CNN, which can be represented as an ACNN by setting the outputs of the filter-generation module to a constant, regardless of the contextual information from input sentence(s). Because of the learning-to-learn \\citep{thrun2012learning nature of the proposed ACNN framework, it tends to have greater representational power than the basic CNN.",
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 1,\n    \"Rationale\": \"Image 0 visually represents the ACNN framework, showing the filter generation and convolution modules, which are key to understanding how context-sensitive filters are learned. Text 1 explains the architecture, detailing the filter generation and adaptive convolution modules, which are crucial for learning context-sensitive filters.\",\n    \"Answer\": \"The ACNN framework learns context-sensitive filters through a filter generation module that produces filters conditioned on the input sentence, and an adaptive convolution module that applies these filters. This architecture allows the filters to be sample-specific, enhancing the model's predictive power.\"\n}"
  },
  "2": {
    "question": "Which model performed the best on the Quora Question Pairs dataset?",
    "ground_truth": "AdaQA (two-way) + att.",
    "selected_figures_names": [
      "1709.08294v3-Table5-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 5,
    "rationale": "Image 0 provides a clear comparison of model accuracies on the Quora Question Pairs dataset. Text 5 discusses the different model variants, including the AdaQA model with attention, which is relevant to understanding the context of the results.",
    "answer": "The AdaQA (two-way) + att. model performed the best on the Quora Question Pairs dataset with an accuracy of 0.8794.",
    "text_chunks": [
      "So motivated, we propose an adaptive CNN-based question-answer (AdaQA) model for this problem. The AdaQA model can be divided into three modules: filter generation, adaptive convolution, and matching modules, as depicted schematically in Figure~. Assume there is a question-answer pair to be matched, represented by word-embedding matrices, i.e. \\boldsymbol{Q \\in \\mathbb{R^{T_q",
      "The same trend is also observed on the SelQA dataset (as shown in Table~), which is a much larger dataset than WikiQA. Notably, our model yields significantly better results than an attentive pooling network and ABCNN (attention-based CNN) baselines. We attribute the improvement to two potential advantages of our AdaQA model: (\\romannumeral1) for the two previous baseline methods, the interaction between question and answer takes place either before or after convolution.",
      "As illustrated in Table~, our two-way AdaQA model again exhibits superior performances compared with basic CNN models (as reported in ). Discussion \\vspace{-1mm \\paragraph{Reasoning ability To associate the improved answer sentence selection results with the reasoning capabilities of our AdaQA model , we further categorize the questions in the WikiQA test set into 5 types containing: `What', `Where', `How', `When' or `Who'.",
      "However, in our AdaQA model, the communication between two sentences is inherent in the convolution operation, and thus can provide the abstracted features with more flexibility; (\\romannumeral2) the bidirectional filter generation mechanism in our AdaQA model generates co-dependent representations for the question and candidate answer, which could enable the model to recover from initial local maxima corresponding to incorrect predictions . \\vspace{-2mm \\paragraph{Paragraph Identification Considering that the proposed AdaQA model can be readily generalized to other text sequence matching problems, we further evaluate the proposed framework on the paraphrase identification task with the Quora question pairs dataset. To ensure a fair comparison, we employ the same data splits as in .",
      "Further comparing our results with NASM in , our AdaQA model (with a MAP score of 0.579) outperforms their reported `How' question MAP scores (0.524) by a large margin, indicating that the adaptive convolutional filter-generation mechanism improves the model's ability to read and reason over natural language sentences. \\vspace{-2mm \\paragraph{Filter visualization To better understand what information has been encoded into our context-sensitive filters, we visualize one of the filters for sentences within the test set (on the DBpedia dataset) with t-SNE. The corresponding results are shown in Figure~(c).",
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods.",
      "For sentence matching, we evaluate the AdaQA model on two datasets for open-domain question answering: WikiQA \\citep{yang2015wikiqa and SelQA \\citep{jurczyk2016selqa. Given a question, the task is to rank the corresponding candidate answers, which, in the case of WikiQA, are sentences extracted from the summary section of a related Wikipedia article. To facilitate comparison with existing results \\citep{yin2015abcnn,yang2015wikiqa, Shen2018BaselineNM, we truncate the candidate answers to a maximum length of 40 tokens for all experiments on the WikiQA dataset.",
      "Notably, we share the weights of filter generating networks for both the question and answer, so that the model adaptivity for answer selection can be improved without an excessive increase in the number of parameters. All three modules in AdaQA model are jointly trained end-to-end. Note that the AdaQA model proposed can be readily adapted to other sentence matching tasks, such as paraphrase identification (see Section~)."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 5,\n    \"Rationale\": \"Image 0 provides a clear comparison of model accuracies on the Quora Question Pairs dataset. Text 5 discusses the different model variants, including the AdaQA model with attention, which is relevant to understanding the context of the results.\",\n    \"Answer\": \"The AdaQA (two-way) + att. model performed the best on the Quora Question Pairs dataset with an accuracy of 0.8794.\"\n}"
  },
  "3": {
    "question": "Based on the figure, which type of question does ACNN perform the best on?",
    "ground_truth": "ACNN performs best on \"Who\" questions.",
    "selected_figures_names": [
      "1709.08294v3-Figure3-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 7,
    "rationale": "Image 0 provides a visual comparison of ACNN and CNN performance across different question types, which directly answers the question. Text 7 discusses the performance of the AdaQA model on different question types, providing context for the image.",
    "answer": "ACNN performs the best on 'Who' type questions.",
    "text_chunks": [
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods.",
      "Note that the self-adaptive ACNN model variant, which generates filters only for the input itself (without any interactions before the top matching module), slightly outperforms the vanilla CNN Siamese model. Combined with the results in document categorization experiments, we believe that our ACNN framework, in its simplest form, can be utilized as a powerful feature extractor for transforming natural language sentences into fixed-length vectors. More importantly, our two-way AdaQA model exhibits superior results compared with the one-way variant as well as other CNN-based baseline models on the WikiQA dataset.",
      "Moreover, our method exhibits higher accuracy than n-grams, which is a very strong baseline as shown in . We attribute the superior performance of the ACNN framework to its stronger (adaptive) feature-extraction ability. Moreover, our M-ACNN also achieves slightly better performance than self-attentive sentence embeddings proposed in \\citet{lin2017structured, which requires significant more parameters than our method.",
      "Experimental Results Document Classification To explicitly explore whether our ACNN model can leverage the input-aware filter weights for better sentence representation, we perform a comparison between the basic CNN and ACNN models with only a single filter, which are denoted as S-CNN, S-ACNN, respectively (this setting may not yield best overall performance, since only a single filter is used, but it allows us to isolate the impact of adaptivity). As illustrated in Table~, S-ACNN significantly outperforms S-CNN on both datasets, demonstrating the advantage of the filter-generation module in our ACNN framework. As a result, with only one convolutional filter and thus very limited modeling capacity, our S-ACNN model tends to be much more expressive than the basic CNN model, due to the flexibility of applying different filters to different sentences.",
      "Notably, according to our experiments, the proposed filter generation module can be readily combined with (standard) attention mechanisms to further enhance the modeling expressiveness of CNN encoder. Experimental Setup \\paragraph{Datasets We investigate the effectiveness of the proposed ACNN framework on both document classification and text sequence matching tasks. Specifically, we consider two large-scale document classification datasets: Yelp Reviews Polarity, and DBPedia ontology datasets \\citep{zhang2015character.",
      "We further experiment on both ACNN and CNN models with multiple filters. The corresponding document categorization accuracies are presented in Table~. Although we only use one convolution layer for our ACNN model, it already outperforms other CNN baseline methods with much deeper architectures.",
      "In this regard, we propose a novel bidirectional filter generation mechanism to allow interactions between sentence pairs while constructing context-sensitive representations. We investigate the effectiveness of our Adaptive Context-sensitive CNN (ACNN) framework on several text processing tasks: ontology classification, sentiment analysis, answer sentence selection and paraphrase identification. We show that the proposed methods consistently outperforms the standard CNN and attention-based CNN baselines.",
      "As illustrated in Table~, our two-way AdaQA model again exhibits superior performances compared with basic CNN models (as reported in ). Discussion \\vspace{-1mm \\paragraph{Reasoning ability To associate the improved answer sentence selection results with the reasoning capabilities of our AdaQA model , we further categorize the questions in the WikiQA test set into 5 types containing: `What', `Where', `How', `When' or `Who'."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 7,\n    \"Rationale\": \"Image 0 provides a visual comparison of ACNN and CNN performance across different question types, which directly answers the question. Text 7 discusses the performance of the AdaQA model on different question types, providing context for the image.\",\n    \"Answer\": \"ACNN performs the best on 'Who' type questions.\"\n}"
  },
  "4": {
    "question": "How does the Adaptive Question Answering (AdaQA) model generate context-aware filters?",
    "ground_truth": "The AdaQA model generates context-aware filters through the filter generation module. This module takes the question and answer as input and outputs a set of filters that are specific to the question and answer pair.",
    "selected_figures_names": [
      "1709.08294v3-Figure2-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 2,
    "rationale": "Image 0 provides a schematic description of the AdaQA model, showing the flow and interaction between modules, which is crucial for understanding how context-aware filters are generated. Text 2 explains the division of the AdaQA model into modules, including filter generation, which directly addresses the question.",
    "answer": "The AdaQA model generates context-aware filters through a filter generation module. This module is part of a larger framework that includes adaptive convolution and matching modules. The filters are generated based on the input question-answer pair, represented by word-embedding matrices, allowing the model to adaptively process and match the sequences.",
    "text_chunks": [
      "Extension to text sequence matching % Considering the ability of our ACNN framework to generate context-sensitive filters, it can be naturally generalized to the task of text sequence matching. In this section, we will describe the proposed Adaptive Question Answering (AdaQA) model in the context of answer sentence selection task. Note that the corresponding model can be readily adapted to other sentence matching problems as well (see Section~).",
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods.",
      "So motivated, we propose an adaptive CNN-based question-answer (AdaQA) model for this problem. The AdaQA model can be divided into three modules: filter generation, adaptive convolution, and matching modules, as depicted schematically in Figure~. Assume there is a question-answer pair to be matched, represented by word-embedding matrices, i.e. \\boldsymbol{Q \\in \\mathbb{R^{T_q",
      "Further comparing our results with NASM in , our AdaQA model (with a MAP score of 0.579) outperforms their reported `How' question MAP scores (0.524) by a large margin, indicating that the adaptive convolutional filter-generation mechanism improves the model's ability to read and reason over natural language sentences. \\vspace{-2mm \\paragraph{Filter visualization To better understand what information has been encoded into our context-sensitive filters, we visualize one of the filters for sentences within the test set (on the DBpedia dataset) with t-SNE. The corresponding results are shown in Figure~(c).",
      "Note that the self-adaptive ACNN model variant, which generates filters only for the input itself (without any interactions before the top matching module), slightly outperforms the vanilla CNN Siamese model. Combined with the results in document categorization experiments, we believe that our ACNN framework, in its simplest form, can be utilized as a powerful feature extractor for transforming natural language sentences into fixed-length vectors. More importantly, our two-way AdaQA model exhibits superior results compared with the one-way variant as well as other CNN-based baseline models on the WikiQA dataset.",
      "Notably, we share the weights of filter generating networks for both the question and answer, so that the model adaptivity for answer selection can be improved without an excessive increase in the number of parameters. All three modules in AdaQA model are jointly trained end-to-end. Note that the AdaQA model proposed can be readily adapted to other sentence matching tasks, such as paraphrase identification (see Section~).",
      "This observation indicates that the bidirectional filter generation mechanism is strongly associated with the performance gains. While combined with the multi-perspective attention layers, adopted after the ACNN encoding layer, our two-way AdaQA model achieves even better performance. This suggests that the proposed strategy is complementary, in terms of the incorporation of rich contextual information, to the standard attention mechanism.",
      "However, in our AdaQA model, the communication between two sentences is inherent in the convolution operation, and thus can provide the abstracted features with more flexibility; (\\romannumeral2) the bidirectional filter generation mechanism in our AdaQA model generates co-dependent representations for the question and candidate answer, which could enable the model to recover from initial local maxima corresponding to incorrect predictions . \\vspace{-2mm \\paragraph{Paragraph Identification Considering that the proposed AdaQA model can be readily generalized to other text sequence matching problems, we further evaluate the proposed framework on the paraphrase identification task with the Quora question pairs dataset. To ensure a fair comparison, we employ the same data splits as in ."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 2,\n    \"Rationale\": \"Image 0 provides a schematic description of the AdaQA model, showing the flow and interaction between modules, which is crucial for understanding how context-aware filters are generated. Text 2 explains the division of the AdaQA model into modules, including filter generation, which directly addresses the question.\",\n    \"Answer\": \"The AdaQA model generates context-aware filters through a filter generation module. This module is part of a larger framework that includes adaptive convolution and matching modules. The filters are generated based on the input question-answer pair, represented by word-embedding matrices, allowing the model to adaptively process and match the sequences.\"\n}"
  },
  "5": {
    "question": "Based on Table 1, which dataset has the largest vocabulary size and how does this compare to the average number of words per document in that dataset?",
    "ground_truth": "The Yelp P. dataset has the largest vocabulary size with 25,709 unique words. This is significantly larger than the average number of words per document in the dataset, which is 138.",
    "selected_figures_names": [
      "1709.08294v3-Table1-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": null,
    "rationale": "The image provides the dataset statistics, including vocabulary size and average number of words per document, which directly answers the question.",
    "answer": "The Yelp Reviews Polarity dataset has the largest vocabulary size of 25,709. The average number of words per document in this dataset is 138.",
    "text_chunks": [
      "We also consider the task of paraphrase identification with the Quora Question Pairs dataset, with the same data splits as in . A summary of all datasets is presented in Table~. \\paragraph{Training Details For the document classification experiments, we randomly initialize the word embeddings uniformly within [-0.001, 0.001] and update them during training. For the generated filters, we set the window size as h=5, with K=100 feature maps (the dimension of z is set as 100).",
      "We observed that a larger dropout rate (e.g., 0.5) will hurt performance on document classifications and make training significantly slower. For the sentence matching tasks, we initialized the word embeddings with 50-dimensional Glove \\citep{pennington2014glove word vectors pretrained from Wikipedia 2014 and Gigaword 5 \\citep{pennington2014glove for all model variants. As for the filters, we set the window size as h=5, with K=300 feature maps.",
      "For sentence matching, we evaluate the AdaQA model on two datasets for open-domain question answering: WikiQA \\citep{yang2015wikiqa and SelQA \\citep{jurczyk2016selqa. Given a question, the task is to rank the corresponding candidate answers, which, in the case of WikiQA, are sentences extracted from the summary section of a related Wikipedia article. To facilitate comparison with existing results \\citep{yin2015abcnn,yang2015wikiqa, Shen2018BaselineNM, we truncate the candidate answers to a maximum length of 40 tokens for all experiments on the WikiQA dataset.",
      "Further comparing our results with NASM in , our AdaQA model (with a MAP score of 0.579) outperforms their reported `How' question MAP scores (0.524) by a large margin, indicating that the adaptive convolutional filter-generation mechanism improves the model's ability to read and reason over natural language sentences. \\vspace{-2mm \\paragraph{Filter visualization To better understand what information has been encoded into our context-sensitive filters, we visualize one of the filters for sentences within the test set (on the DBpedia dataset) with t-SNE. The corresponding results are shown in Figure~(c).",
      "Moreover, our framework is based on CNN models, which is advantageous due to fewer parameters and highly parallelizable computations relative to sequential-based models. Model Basic CNN for text representations The CNN architectures in \\citep{kim2014convolutional, collobert2011natural are typically utilized for extracting sentence representations, by a composition of a convolutional layer and a max-pooling operation over all resulting feature maps. Let the words of a sentence of length T (padded where necessary) be {x_1, {x_2, ... , {x_T. The sentence can be represented as a matrix \\boldsymbol{X \\in \\mathbb{R^{d \\times T, where each column represents a d-dimensional embedding of the corresponding word.",
      "Notably, according to our experiments, the proposed filter generation module can be readily combined with (standard) attention mechanisms to further enhance the modeling expressiveness of CNN encoder. Experimental Setup \\paragraph{Datasets We investigate the effectiveness of the proposed ACNN framework on both document classification and text sequence matching tasks. Specifically, we consider two large-scale document classification datasets: Yelp Reviews Polarity, and DBPedia ontology datasets \\citep{zhang2015character.",
      "The hyperparameters are selected by choosing the best model on the validation set. All models are implemented with TensorFlow and are trained using one NVIDIA GeForce GTX TITAN X GPU with 12GB memory. \\par \\paragraph{Baselines For document classification, we consider several baseline models: % (i) ngrams \\citep{zhang2015character, a bag-of-means method based on TFIDF representations built by choosing the 500,000 most frequent n-grams (up to 5-grams) from the training set and use their corresponding counts as features; (ii) small/large word CNN \\citep{zhang2015character: 6 layer word-based convolutional networks, with 256/1024 features at each layer, denoted as small/large, respectively; (iii) deep CNN \\citep{conneau2016very: deep convolutional neural networks with 9/17/29 layers.",
      "The same trend is also observed on the SelQA dataset (as shown in Table~), which is a much larger dataset than WikiQA. Notably, our model yields significantly better results than an attentive pooling network and ABCNN (attention-based CNN) baselines. We attribute the improvement to two potential advantages of our AdaQA model: (\\romannumeral1) for the two previous baseline methods, the interaction between question and answer takes place either before or after convolution."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": null,\n    \"Rationale\": \"The image provides the dataset statistics, including vocabulary size and average number of words per document, which directly answers the question.\",\n    \"Answer\": \"The Yelp Reviews Polarity dataset has the largest vocabulary size of 25,709. The average number of words per document in this dataset is 138.\"\n}"
  },
  "6": {
    "question": "Can you explain why the authors claim that their S-ACNN model with a single filter is \"much more expressive\" than the basic S-CNN model, even though it doesn't achieve the best overall performance on either dataset?",
    "ground_truth": "The authors claim that S-ACNN is more expressive than S-CNN because, despite having only one filter, it significantly outperforms S-CNN on both datasets. This suggests that the filter-generation module in ACNN allows for greater flexibility and adaptability, enabling the model to better capture the specific features of each sentence.",
    "selected_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Figure3-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 0,
    "rationale": "Image 0 provides test error rates for S-CNN and S-ACNN models, showing that S-ACNN outperforms S-CNN. Text 0 explains that S-ACNN's expressiveness comes from its adaptive filter weights, which allow it to apply different filters to different sentences, enhancing its expressiveness despite limited modeling capacity.",
    "answer": "The authors claim that their S-ACNN model is 'much more expressive' than the basic S-CNN model because it uses adaptive filter weights that allow it to apply different filters to different sentences. This adaptivity enhances its expressiveness, even with a single filter, as it can better capture sentence-specific features compared to the static filters of the S-CNN model.",
    "text_chunks": [
      "Experimental Results Document Classification To explicitly explore whether our ACNN model can leverage the input-aware filter weights for better sentence representation, we perform a comparison between the basic CNN and ACNN models with only a single filter, which are denoted as S-CNN, S-ACNN, respectively (this setting may not yield best overall performance, since only a single filter is used, but it allows us to isolate the impact of adaptivity). As illustrated in Table~, S-ACNN significantly outperforms S-CNN on both datasets, demonstrating the advantage of the filter-generation module in our ACNN framework. As a result, with only one convolutional filter and thus very limited modeling capacity, our S-ACNN model tends to be much more expressive than the basic CNN model, due to the flexibility of applying different filters to different sentences.",
      "\\paragraph{Effect of number of filters To further demonstrate that the performance gains in document categorization experiments originates from the improved adaptivity of our ACNN framework, we implement the basic CNN model with different numbers of filter sizes, ranging from 1 to 1000. As illustrated in Figure~(a), when the filter size is larger than 100, the test accuracy of the standard CNN model does not show any noticeable improvement with more filters. More importantly, even with a filter size of 1000, the classification accuracy of the CNN is worse than that of the ACNN model with the filter number restricted to 100.",
      "We further experiment on both ACNN and CNN models with multiple filters. The corresponding document categorization accuracies are presented in Table~. Although we only use one convolution layer for our ACNN model, it already outperforms other CNN baseline methods with much deeper architectures.",
      "Note that the self-adaptive ACNN model variant, which generates filters only for the input itself (without any interactions before the top matching module), slightly outperforms the vanilla CNN Siamese model. Combined with the results in document categorization experiments, we believe that our ACNN framework, in its simplest form, can be utilized as a powerful feature extractor for transforming natural language sentences into fixed-length vectors. More importantly, our two-way AdaQA model exhibits superior results compared with the one-way variant as well as other CNN-based baseline models on the WikiQA dataset.",
      "Moreover, our method exhibits higher accuracy than n-grams, which is a very strong baseline as shown in . We attribute the superior performance of the ACNN framework to its stronger (adaptive) feature-extraction ability. Moreover, our M-ACNN also achieves slightly better performance than self-attentive sentence embeddings proposed in \\citet{lin2017structured, which requires significant more parameters than our method.",
      "Notably, there are no additional parameters in the adaptive convolution module (no bias term is employed). Our ACNN framework can be seen as a generalization of the basic CNN, which can be represented as an ACNN by setting the outputs of the filter-generation module to a constant, regardless of the contextual information from input sentence(s). Because of the learning-to-learn \\citep{thrun2012learning nature of the proposed ACNN framework, it tends to have greater representational power than the basic CNN.",
      "This observation indicates that the bidirectional filter generation mechanism is strongly associated with the performance gains. While combined with the multi-perspective attention layers, adopted after the ACNN encoding layer, our two-way AdaQA model achieves even better performance. This suggests that the proposed strategy is complementary, in terms of the incorporation of rich contextual information, to the standard attention mechanism.",
      "In this manner, the filter weights vary from sample to sample, providing the CNN encoder network with more modeling flexibility and capacity. This framework is further generalized to model question-answer sentence pairs, leveraging a two-way feature abstraction process. We evaluate our models on several document-categorization and sentence matching benchmarks, and they consistently outperform the standard CNN and attention-based CNN baselines, demonstrating the effectiveness of our framework."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 0,\n    \"Rationale\": \"Image 0 provides test error rates for S-CNN and S-ACNN models, showing that S-ACNN outperforms S-CNN. Text 0 explains that S-ACNN's expressiveness comes from its adaptive filter weights, which allow it to apply different filters to different sentences, enhancing its expressiveness despite limited modeling capacity.\",\n    \"Answer\": \"The authors claim that their S-ACNN model is 'much more expressive' than the basic S-CNN model because it uses adaptive filter weights that allow it to apply different filters to different sentences. This adaptivity enhances its expressiveness, even with a single filter, as it can better capture sentence-specific features compared to the static filters of the S-CNN model.\"\n}"
  },
  "7": {
    "question": "Which model performs best on the SelQA dataset and how does it compare to the baseline CNN model reported in Jurczyk et al. (2016)?",
    "ground_truth": "The AdaQA (two-way) + att. model achieves the best performance on the SelQA dataset with a MAP score of 0.9021 and an MRR score of 0.9103. Compared to the baseline CNN model from Jurczyk et al. (2016) which has a MAP score of 0.8320 and an MRR score of 0.8420, the AdaQA (two-way) + att. model demonstrates a significant improvement in both metrics.",
    "selected_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png"
    ],
    "all_figures_names": [
      "1709.08294v3-Table2-1.png",
      "1709.08294v3-Table4-1.png",
      "1709.08294v3-Table3-1.png",
      "1709.08294v3-Figure1-1.png",
      "1709.08294v3-Table5-1.png",
      "1709.08294v3-Figure3-1.png",
      "1709.08294v3-Figure2-1.png",
      "1709.08294v3-Table1-1.png"
    ],
    "chosen_image_idx": 1,
    "chosen_text_idx": 1,
    "rationale": "Image 1 provides the MAP and MRR scores for different models on the SelQA dataset, showing the performance of the AdaQA model compared to baseline CNN models. Text 1 explains the evaluation metrics used, which are relevant for understanding the comparison.",
    "answer": "The AdaQA (two-way + att.) model performs best on the SelQA dataset with a MAP of 0.9021 and MRR of 0.9103. It outperforms the baseline CNN model reported in Jurczyk et al. (2016), which has a MAP of 0.8320 and MRR of 0.8420.",
    "text_chunks": [
      "The same trend is also observed on the SelQA dataset (as shown in Table~), which is a much larger dataset than WikiQA. Notably, our model yields significantly better results than an attentive pooling network and ABCNN (attention-based CNN) baselines. We attribute the improvement to two potential advantages of our AdaQA model: (\\romannumeral1) for the two previous baseline methods, the interaction between question and answer takes place either before or after convolution.",
      "To evaluate the effectiveness of proposed AdaQA model, we compare it with several CNN-based sequence matching baselines, including Vanilla CNN \\citep{jurczyk2016selqa,santos2017learning, attentive pooling networks \\citep{dos2016attentive, and ABCNN \\citep{yin2015abcnn (where an attention mechanism is employed over the two sentence representations). \\paragraph{Evaluation Metrics For document categorization and paraphrase identification tasks, we employ the percentage of correct predictions on the test set to evaluate and compare different models. For the answer sentence selection task, mean average precision (MAP) and mean reciprocal rank (MRR) are utilized as the corresponding evaluation metrics.",
      "Note that the self-adaptive ACNN model variant, which generates filters only for the input itself (without any interactions before the top matching module), slightly outperforms the vanilla CNN Siamese model. Combined with the results in document categorization experiments, we believe that our ACNN framework, in its simplest form, can be utilized as a powerful feature extractor for transforming natural language sentences into fixed-length vectors. More importantly, our two-way AdaQA model exhibits superior results compared with the one-way variant as well as other CNN-based baseline models on the WikiQA dataset.",
      "As illustrated in Table~, our two-way AdaQA model again exhibits superior performances compared with basic CNN models (as reported in ). Discussion \\vspace{-1mm \\paragraph{Reasoning ability To associate the improved answer sentence selection results with the reasoning capabilities of our AdaQA model , we further categorize the questions in the WikiQA test set into 5 types containing: `What', `Where', `How', `When' or `Who'.",
      "Given these observations, we believe that the boosted categorization accuracy does come from the improved flexibility and thus better feature extraction of our ACNN framework. \\vspace{-1mm Answer Sentence Selection \\vspace{-1.5mm To elucidate the role of different parts (modules) in our AdaQA model, we implement several model variants for comparison: (\\romannumeral1) a ``vanilla'' CNN model that independently encodes two sentence representations for matching; (\\romannumeral2) a self-adaptive ACNN-based model where the question/answer sentence generates adaptive filters only to convolve with the input itself; (\\romannumeral3) a one-way ACNN model where only the answer sentence representation is extracted with adaptive filters, which are generated conditioned on the question; (\\romannumeral4) a two-way AdaQA model as described in Section 2.4, where both sentences are adaptively encoded, with filters generated conditioned on the other sequence; (\\romannumeral5) considering that the proposed filter generation mechanism is complementary to the attention layer typically employed in sequence matching tasks (see Section~), we experiment with another model variant that combines the proposed context-sensitive filter generation mechanism with the multi-perspective attention layer introduced in . Tables~ and show experimental results of our models on WikiQA and SelQA datasets, along with other state-of-the-art methods.",
      "We then calculate the MAP scores of the basic CNN and our AdaQA model on different question types. Similar to the findings in , we observe that the `How' question is the hardest to answer, with the lowest MAP scores. However, our AdaQA model improves most over the basic CNN on the `How' type question, see Figure~(b).",
      "Further comparing our results with NASM in , our AdaQA model (with a MAP score of 0.579) outperforms their reported `How' question MAP scores (0.524) by a large margin, indicating that the adaptive convolutional filter-generation mechanism improves the model's ability to read and reason over natural language sentences. \\vspace{-2mm \\paragraph{Filter visualization To better understand what information has been encoded into our context-sensitive filters, we visualize one of the filters for sentences within the test set (on the DBpedia dataset) with t-SNE. The corresponding results are shown in Figure~(c).",
      "For sentence matching, we evaluate the AdaQA model on two datasets for open-domain question answering: WikiQA \\citep{yang2015wikiqa and SelQA \\citep{jurczyk2016selqa. Given a question, the task is to rank the corresponding candidate answers, which, in the case of WikiQA, are sentences extracted from the summary section of a related Wikipedia article. To facilitate comparison with existing results \\citep{yin2015abcnn,yang2015wikiqa, Shen2018BaselineNM, we truncate the candidate answers to a maximum length of 40 tokens for all experiments on the WikiQA dataset."
    ],
    "raw_gpt": "{\n    \"Image\": 1,\n    \"Text\": 1,\n    \"Rationale\": \"Image 1 provides the MAP and MRR scores for different models on the SelQA dataset, showing the performance of the AdaQA model compared to baseline CNN models. Text 1 explains the evaluation metrics used, which are relevant for understanding the comparison.\",\n    \"Answer\": \"The AdaQA (two-way + att.) model performs best on the SelQA dataset with a MAP of 0.9021 and MRR of 0.9103. It outperforms the baseline CNN model reported in Jurczyk et al. (2016), which has a MAP of 0.8320 and MRR of 0.8420.\"\n}"
  }
}