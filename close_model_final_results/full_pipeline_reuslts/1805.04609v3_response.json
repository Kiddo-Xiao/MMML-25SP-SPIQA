{
  "0": {
    "question": "Which algorithm has the highest percentage of switched instances?",
    "ground_truth": "US-HC-MQ",
    "selected_figures_names": [
      "1805.04609v3-Figure3-1.png"
    ],
    "all_figures_names": [
      "1805.04609v3-Figure1-1.png",
      "1805.04609v3-Figure3-1.png",
      "1805.04609v3-Figure2-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 2,
    "rationale": "The image provides a visual comparison of the percentage of switched instances for different algorithms, which directly answers the question. Text chunk 2 describes the algorithms being compared, providing context for the image.",
    "answer": "US-HC-MQ has the highest percentage of switched instances.",
    "text_chunks": [
      "We randomly chose a core set of 10 instances for each dataset and used each synthesis algorithm to generate 50 examples. The score for each algorithm is the portion of examples it generated that crossed the classification boundary. We repeat the experiment 20 times with different core sets and show the average results on all available datasets.",
      "The cross-validation accuracy of each artificial expert on its dataset is 86.8\\% in CMR, 94.4\\% in SUBJ, 86.2\\% in SST, 91.0\\% in HS, and 94.5\\% in KS. The expert achieves close to state-of-the-art performance for each dataset. One potential problematic aspect of this methodology is that the performance of the artificial expert was tested only on real examples from the datasets, and not on artificially generated instances.",
      "In this experiment, we tested the effect of our synthesis algorithms on the number of label changes they cause. Three algorithms were compared, Uncertainty hill-climbing (US-HC-MQ), Stochastic hill-climbing (S-HC-MQ), and Stochastic synthesis (S-MQ). US-HC-MQ uses a heuristic function to direct its search, S-HC-MQ applies multiple operators randomly, and S-MQ randomly applies only one operator at a time, just as described in Algorithms and .",
      "A simple way of utilizing the modification operators is to apply them in random to the core set of instances. The algorithm maintains a set of instances \\Omega. We initialize \\Omega with the core set C. At each step, we randomly choose an instance from \\Omega and apply a random operator to it.",
      "The accuracy achieved was very close to the one achieved for the real examples (with a maximum of 2\\% difference). This confirmed that the artificial expert can operate on our artificial examples. \\subsubsection{Compared Methods In the following experiments, we have used 3 variations of our methods:",
      "To account for this, we performed the following experiment. We used our algorithm to generate a test set of 100 instances for each of the 5 datasets and asked humans to label these instances. We then applied the artificial expert on these test sets.",
      "Our work tackles the problems in membership query synthesis and presents a novel algorithm for synthesizing new instances by defining a search space over the set of instances, actively searching for the most informative instances. Our method is capable of generating near-misses \u2014 negative examples that are only slightly different from the positive ones. Such examples have been shown to be helpful for learning .",
      "We would also like a single operator to minimally change the instance, as this will enable the generation of near-miss examples by consecutively applying operators which will slowly move the instance over the classification boundary. We will later discuss the implementation of the modification operators for the textual domain. \\subsubsection{Stochastic Query Synthesis"
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 2,\n    \"Rationale\": \"The image provides a visual comparison of the percentage of switched instances for different algorithms, which directly answers the question. Text chunk 2 describes the algorithms being compared, providing context for the image.\",\n    \"Answer\": \"US-HC-MQ has the highest percentage of switched instances.\"\n}"
  },
  "1": {
    "question": "How does the accuracy of the US-BS-MQ method compare to that of the S-MQ method when adding SST examples?",
    "ground_truth": "The US-BS-MQ method achieves higher accuracy than the S-MQ method when adding SST examples.",
    "selected_figures_names": [
      "1805.04609v3-Figure2-1.png"
    ],
    "all_figures_names": [
      "1805.04609v3-Figure1-1.png",
      "1805.04609v3-Figure3-1.png",
      "1805.04609v3-Figure2-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 2,
    "rationale": "Image 0 provides a visual comparison of accuracy across different methods, including US-BS-MQ and S-MQ, for the SST dataset. Text 2 discusses the performance of search-based approaches like US-BS-MQ compared to S-MQ, indicating that US-BS-MQ obtains more valuable examples.",
    "answer": "The accuracy of the US-BS-MQ method is higher than that of the S-MQ method when adding SST examples.",
    "text_chunks": [
      "Uncertainty sampling beam-search MQ synthesis (US-BS-MQ): Same as (a) but using the beam search algorithm. Stochastic Synthesis (S-MQ):",
      "In this experiment, we tested the effect of our synthesis algorithms on the number of label changes they cause. Three algorithms were compared, Uncertainty hill-climbing (US-HC-MQ), Stochastic hill-climbing (S-HC-MQ), and Stochastic synthesis (S-MQ). US-HC-MQ uses a heuristic function to direct its search, S-HC-MQ applies multiple operators randomly, and S-MQ randomly applies only one operator at a time, just as described in Algorithms and .",
      "The two search-based approaches (US-HC-MQ and US-BS-MQ) both exhibited excellent performance across the 5 datasets. The comparison of the search-based approaches to S-MQ showed that, as we expected, more valuable examples are obtained when using the utility function in the generation process. WNA performed admirably considering that in principle it is using only a small semantic neighborhood and therefore receives only synonyms.",
      "The cross-validation accuracy of each artificial expert on its dataset is 86.8\\% in CMR, 94.4\\% in SUBJ, 86.2\\% in SST, 91.0\\% in HS, and 94.5\\% in KS. The expert achieves close to state-of-the-art performance for each dataset. One potential problematic aspect of this methodology is that the performance of the artificial expert was tested only on real examples from the datasets, and not on artificially generated instances.",
      "a) Uncertainty sampling hill-climbing MQ synthesis (US-HC-MQ): The proposed search-based synthesis method, using hill-climbing search and uncertainty sampling-based heuristic function. b)",
      "Figure shows a clear hierarchy, where US-HC-MQ has the most label changes, followed by S-HC-MQ, and then by S-MQ. This result reinforces our hypothesis that using multiple operators on a single sentence as well as using heuristic functions during generation results in more diverse sentences as well shows that our framework does not only perform augmentations but significantly changes the meaning of the sentences. Human Evaluation - Sentence Generation",
      "This approach holds strong theoretical promise as its learning model is more robust than the standard PAC learning model in many cases , since it does not depend on the assumption that the training and testing instances are drawn from the same distribution. There is one major obstacle, however, when using the MQ model for real-world learning tasks. Traditionally, training instances, such as images or natural-language sentences, are mapped into feature vectors.",
      "The resulting new instance is added to \\Omega. When enough instances have been generated, we return \\Omega \\backslash C as the MQs. The pseudo-code for stochastic query synthesis is listed in Algorithm ."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 2,\n    \"Rationale\": \"Image 0 provides a visual comparison of accuracy across different methods, including US-BS-MQ and S-MQ, for the SST dataset. Text 2 discusses the performance of search-based approaches like US-BS-MQ compared to S-MQ, indicating that US-BS-MQ obtains more valuable examples.\",\n    \"Answer\": \"The accuracy of the US-BS-MQ method is higher than that of the S-MQ method when adding SST examples.\"\n}"
  }
}