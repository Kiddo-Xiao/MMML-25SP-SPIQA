{
  "0": {
    "question": "How does the performance of ITN-V2 compare to other methods when both DDT and ST transformations are applied to the CIFAR-10 dataset?",
    "ground_truth": "ITN-V2 achieves the lowest testing error (56.95%) among all methods listed when both DDT and ST transformations are applied to the CIFAR-10 dataset.",
    "selected_figures_names": [
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Table4-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Table4-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure1-1.png"
    ],
    "chosen_image_idx": 1,
    "chosen_text_idx": 0,
    "rationale": "Image 1 provides a comparison of testing errors for different methods, including ITN-V2, on the CIFAR-10 dataset with DDT and ST transformations. Text 0 discusses the performance improvements of ITN-V2 over other methods, specifically mentioning CIFAR-10.",
    "answer": "ITN-V2 achieves a testing error of 56.95% on the CIFAR-10 dataset with both DDT and ST transformations, which is lower than other methods listed in the table.",
    "text_chunks": [
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset.",
      "\\vspace{-10pt SVHN and CIFAR-10 Next, we evaluate the performance of ITN on SVHN and CIFAR-10 datasets. SVHN~ is a dataset that contains house number images from Google Street View.",
      "In other words, ITN successfully resists DDT type of variations by integrating with DDT transformation function. Together with results from Table , we see that ITN can work with different types of transformation function and resists the corresponding type of variations. Integrating multiple transformation functions Another important observation from Table is that ITN-V2 (B-CNN) can utilize multiple transformations at the same time to resist a mixture of corresponding variations.",
      "In this section, we also use ResNet-32~ as a baseline backbone to validate the performance of our framework with deeper network architectures, following the setting in~. ITN outperforms other methods on SVHN and CIFAR-10 datasets as shown in Table . Some samples generated by ITN are shown in Figure . \\vspace{-10pt A more challenging dataset -- miniImageNet We further verify the scalability of ITN by evaluating our proposed method on a new dataset named miniImageNet~. MiniImageNet dataset is a modified version of the ILSVRC-12 dataset~, in which 600 images for each of 100 classes were randomly chosen to be part of the dataset.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "Then, we include both STs and DDTs in our model and verify the performance again. Let MNIST dataset be the training set of the experiment while the testing set is the MNIST dataset with different types of transformation applied. We introduce two types of testing sets in this section.",
      "In the following experiments, we demonstrate the ability of ITN to resist large variations with spatial transformers (STs) as our transformation function unless specified. STs includes affine transformations, which are the most common unseen variations in most cases. More importantly, STs are fully differentiable, which allows learning by standard backpropagation."
    ],
    "raw_gpt": "{\n    \"Image\": 1,\n    \"Text\": 0,\n    \"Rationale\": \"Image 1 provides a comparison of testing errors for different methods, including ITN-V2, on the CIFAR-10 dataset with DDT and ST transformations. Text 0 discusses the performance improvements of ITN-V2 over other methods, specifically mentioning CIFAR-10.\",\n    \"Answer\": \"ITN-V2 achieves a testing error of 56.95% on the CIFAR-10 dataset with both DDT and ST transformations, which is lower than other methods listed in the table.\"\n}"
  },
  "1": {
    "question": "Which method performs the best when trained with only 1% of the MNIST training data, and how much does data augmentation improve its performance in this scenario?",
    "ground_truth": "When trained with only 1% of the MNIST training data, ITN (B-CNN) (w/ DA) performs the best with a testing error of 2.78%. Data augmentation further improves its performance by 0.4%, bringing the testing error down to 2.78% from 3.18% achieved by ITN (B-CNN) without data augmentation.",
    "selected_figures_names": [
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table6-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Table7-1.png"
    ],
    "chosen_image_idx": 1,
    "chosen_text_idx": 6,
    "rationale": "Image 1 provides a table with testing errors for different methods using limited training data, including 1% of the MNIST training data. Text 6 discusses the performance of ITN with standard data augmentation, which is relevant to understanding the impact of data augmentation.",
    "answer": "The ITN (B-CNN) method performs the best when trained with only 1% of the MNIST training data, achieving a testing error of 3.18%. Data augmentation improves its performance to 2.78%.",
    "text_chunks": [
      "The reduced training set is built by randomly sampling data from the MNIST training data while keeping the number of data per class identical. As shown in Table~, our method has better results on all tasks, which are consistent with our previous results. The constantly superior performance of ITN over data augmentation indicates its effectiveness.",
      "It is easy to observe that the performance improvements on MNIST and affNIST datasets are marginal compared to experiments in Section 4.1. The most likely explanation for this observation is that the training samples in MNIST and affNIST represent the data distribution very well. In this case, providing more samples will not significantly boost the performance of the classifier.",
      "Thus, we implicitly increase the variations between the training and testing data by reducing the number of samples in the training data. The purpose of this experiment is to demonstrate the potential of ITN to resist unseen variations from a different perspective. \\vspace{-10pt We design a new experiment where the training set is the MNIST dataset with only 0.1\\%, 1\\%, 10\\% and 25\\% of the whole training set while the testing set is the entire MNIST testing set.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "MNIST is a benchmark dataset that includes 55000, 5000 and 10000 handwritten digits in the training, validation and testing set, respectively. The affNIST dataset is a variant from the MNIST dataset and it is built by applying various affine transformations to the samples in MNIST dataset. To be consistent with the MNIST dataset and for the following experiments, we reduce the size of training, validation, and testing set of the affNIST dataset to 55000, 5000 and 10000, respectively.",
      "The most widely adopted approach is data augmentation which applies pre-defined transformations to the training data. Nevertheless, this method is lacking since the user has to specify by-hand the types and extent of transformations applied to the training set. Better methods have been proposed by building connections between generative models and discriminative classifiers~.",
      "As shown in Table , ITN outperforms other methods with standard data augmentation. Limited training data Another way to evaluate the ability of resisting variations is to reduce the number of training samples. Intuitively, data variations between training and testing sets become larger when the number of testing data remains the same while the number of samples in the training set shrinks.",
      "Then, we include both STs and DDTs in our model and verify the performance again. Let MNIST dataset be the training set of the experiment while the testing set is the MNIST dataset with different types of transformation applied. We introduce two types of testing sets in this section."
    ],
    "raw_gpt": "{\n    \"Image\": 1,\n    \"Text\": 6,\n    \"Rationale\": \"Image 1 provides a table with testing errors for different methods using limited training data, including 1% of the MNIST training data. Text 6 discusses the performance of ITN with standard data augmentation, which is relevant to understanding the impact of data augmentation.\",\n    \"Answer\": \"The ITN (B-CNN) method performs the best when trained with only 1% of the MNIST training data, achieving a testing error of 3.18%. Data augmentation improves its performance to 2.78%.\"\n}"
  },
  "2": {
    "question": "How does the ITN framework generate pseudo-negative samples?",
    "ground_truth": "The ITN framework generates pseudo-negative samples by applying learned transformations to positive samples.",
    "selected_figures_names": [
      "1805.06447v3-Figure1-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table7-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Table5-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 2,
    "rationale": "Image 0 visually illustrates the ITN framework, showing how pseudo-negative samples are generated and used to refine decision boundaries. Text 2 explains that ITN enhances the discriminator by generating additional pseudo-negative samples during training, which aligns with the visual representation.",
    "answer": "The ITN framework generates pseudo-negative samples by enhancing the discriminator during training. It uses a transformation module to create variations of positive samples, which are then used to generate pseudo-negative samples, refining the decision boundaries.",
    "text_chunks": [
      "Generating pseudo-negative samples \\ ITN generates pseudo-negative samples to further enrich the coverage of unseen variations. We follow the same generation procedure as WINN. Starting from randomly initialized pseudo-negative samples, the update formula is where x_{n is the pseudo-negative samples at n-th iteration, \\lambda_g is the step size, and \\eta \\sim N(0, \\lambda_g) is the random Gaussian noise.",
      "Pseudo-negative samples are considered as samples generated from the transformed positive distribution. Therefore, having a pool of pseudo-negative samples that approximate transformed positive samples will cover a wider range of unseen variations. A simple evaluation is to check the performance of ITN without the generation module.",
      "ITN enhances the discriminator by generating additional pseudo-negative samples in the training step. \\vspace{-10pt \\end{figure* Our proposed framework is general and can theoretically work with generative adversarial networks (GANs)~. We choose INs in our approach rather than more well known GANs because existing GANs are designed to produce high quality generators while INs have been shown to produce improved discriminators.",
      "The intuition of our approach is illustrated in Figure~. We use a min-max formulation to learn our ITN, where the transformation module transforms positive samples to maximize their variation from the original training samples and the CNN classifier is updated by minimizing the classification loss of the transformed positive and synthesized pseudo-negative samples. The transformation modules are learned jointly with the CNN classifier, which augments training data in an intelligent manner by narrowing down the search space for the variations. \\caption{Illustration of the intuition of our ITN framework.",
      "Generative step WINN follows the same generative methods introduced in~. Given a set of positive samples S^{+, WINN iteratively updates self-generated pseudo-negative samples S^{- to to move them closer to the positive distribution. To directly obtain fair samples from pseudo-negative distribution efficiently, ~ interpret the discriminative model as an estimate of the likelihood ratio At iteration t, the distribution of pseudo-negatives is written as: where p_{\\phi_t^{-(x) represents the negative distribution at t-th iteration, Z_t = \\int\\exp(f_{\\phi_t(x)) p_{0^{-(x) is the normalizing factor, and p_{0^{-(x) is some initial negative distribution (e.g. a Gaussian).",
      "WINN then updates the set of initial pseudo-negative samples to increase f_{\\phi_t(x) via backpropagation. The update of pseudo-negative samples is given by where \\lambda_g is a time-varying step size and \\eta \\sim N(0, \\lambda_g) is the random Gaussian noise. Resisting Variations via Introspective Learning WINN shows promising classification performance by adopting the reclassification-by-synthesis algorithm proposed by ICN~. However, both of them fail to capture large data variations between training and testing data since most of the generated pseudo-negatives are very similar to original samples.",
      "We term this alternate model {\\em auxiliary classifier generative adversarial transformation networks (AC-GATNs) and qualitatively compare ITN and AC-GATN in Section 4.3, demonstrating the benefit of choosing ITNs for building robust image classifiers. The main contribution of the paper is a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner. ITN enhances the classifier by generating additional training samples, including self-generated pseudo-negative samples and transformed input samples.",
      "An update threshold T_u is introduced to guarantee that the generated pseudo-negative samples are above certain criteria, which prevents bad samples from degrading the classifier performance. We modify the update threshold T_u proposed in~ and keep track of the f_{\\phi_t(x) in every iteration. In particular, we build a set D by recording \\mathbb{E"
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 2,\n    \"Rationale\": \"Image 0 visually illustrates the ITN framework, showing how pseudo-negative samples are generated and used to refine decision boundaries. Text 2 explains that ITN enhances the discriminator by generating additional pseudo-negative samples during training, which aligns with the visual representation.\",\n    \"Answer\": \"The ITN framework generates pseudo-negative samples by enhancing the discriminator during training. It uses a transformation module to create variations of positive samples, which are then used to generate pseudo-negative samples, refining the decision boundaries.\"\n}"
  },
  "3": {
    "question": "Which method performs best on the CIFAR-10 dataset?",
    "ground_truth": "ITN (ResNet-32) with data augmentation performs best on the CIFAR-10 dataset with a testing error of 5.82%.",
    "selected_figures_names": [
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure1-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table4-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Figure3-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 4,
    "rationale": "Image 2 provides a table of testing errors for various methods on the CIFAR-10 dataset, directly showing performance comparisons. Text 4 discusses the performance improvements of ITN-V2 on the CIFAR-10 dataset, indicating its effectiveness.",
    "answer": "ITN (ResNet-32) with data augmentation performs best on the CIFAR-10 dataset with a testing error of 5.82%.",
    "text_chunks": [
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset.",
      "There are 73257 digits for training, 26032 digits for testing in SVHN dataset. The CIFAR-10 dataset~ consists of 60000 color images of size 32 \\times 32. This set of 60000 images is split into two sets, 50000 images for training and 10000 images for testing.",
      "In this section, we also use ResNet-32~ as a baseline backbone to validate the performance of our framework with deeper network architectures, following the setting in~. ITN outperforms other methods on SVHN and CIFAR-10 datasets as shown in Table . Some samples generated by ITN are shown in Figure . \\vspace{-10pt A more challenging dataset -- miniImageNet We further verify the scalability of ITN by evaluating our proposed method on a new dataset named miniImageNet~. MiniImageNet dataset is a modified version of the ILSVRC-12 dataset~, in which 600 images for each of 100 classes were randomly chosen to be part of the dataset.",
      "One possible reason is that the generative ability of WINN is still limited on this challenging dataset. Additionally, the generation speed of pseudo-negatives are about 6 times slower compared to the CIFAR-10 dataset due to the complexity of samples. \\vspace{-10pt \\vspace{-10pt Discussion Against data augmentation \\",
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "\\vspace{-10pt SVHN and CIFAR-10 Next, we evaluate the performance of ITN on SVHN and CIFAR-10 datasets. SVHN~ is a dataset that contains house number images from Google Street View.",
      "The results shown in Figure illustrate that under our framework, using INs as the generative model achieve better performance than using GANs. By visualizing the generated samples from AC-GATN and ITN (shown in Figure ), both AC-GATN and ITN generate clear and sharp images. However, samples generated by AC-GATN have lower quality on average in terms of human standards as some of them are misleading and inaccurate, i.e. the number 3 is close to number 6 in epoch 100.",
      "Experiments In this section, we demonstrate the ability of our algorithm to resist large variations between training and testing data through a series of experiments. First, we will present a series of analyses of resisting ability and resisting flexibility of ITN. Following that we demonstrate the strong classification performance of ITN on a series of datasets, including MNIST, affNIST, SVHN, CIFAR-10 and a more challenging dataset, miniImageNet."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 4,\n    \"Rationale\": \"Image 2 provides a table of testing errors for various methods on the CIFAR-10 dataset, directly showing performance comparisons. Text 4 discusses the performance improvements of ITN-V2 on the CIFAR-10 dataset, indicating its effectiveness.\",\n    \"Answer\": \"ITN (ResNet-32) with data augmentation performs best on the CIFAR-10 dataset with a testing error of 5.82%.\"\n}"
  },
  "4": {
    "question": "Which method achieved the lowest testing error on the miniImageNet dataset?",
    "ground_truth": "ITTN (ResNet-32) (w/ DA) achieved the lowest testing error on the miniImageNet dataset with an error rate of 29.65%.",
    "selected_figures_names": [
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table6-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table4-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table5-1.png"
    ],
    "chosen_image_idx": 3,
    "chosen_text_idx": 0,
    "rationale": "Image 3 provides a table of testing errors for various methods on the miniImageNet dataset, which directly answers the question. Text 0 mentions the use of miniImageNet for evaluating ITN, supporting the context.",
    "answer": "ITN (ResNet-32) (w/DA) achieved the lowest testing error on the miniImageNet dataset.",
    "text_chunks": [
      "In this section, we also use ResNet-32~ as a baseline backbone to validate the performance of our framework with deeper network architectures, following the setting in~. ITN outperforms other methods on SVHN and CIFAR-10 datasets as shown in Table . Some samples generated by ITN are shown in Figure . \\vspace{-10pt A more challenging dataset -- miniImageNet We further verify the scalability of ITN by evaluating our proposed method on a new dataset named miniImageNet~. MiniImageNet dataset is a modified version of the ILSVRC-12 dataset~, in which 600 images for each of 100 classes were randomly chosen to be part of the dataset.",
      "All images in this dataset are of size 84 \\times 84 pixels. Compared to previously tested datasets in this section, miniImageNet is significantly harder choice both in terms of generation and classification. Each sample contains complicated natural scenes that pose a hard challenge in generating pseudo-negative samples.",
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "Additionally, the number of classes are also larger than previously seen datasets. The results are shown in Table and ITN shows consistent better performance than all other comparisons. Note that the performance improvement of ITN on miniImagenet is slightly lower than expected.",
      "MNIST is a benchmark dataset that includes 55000, 5000 and 10000 handwritten digits in the training, validation and testing set, respectively. The affNIST dataset is a variant from the MNIST dataset and it is built by applying various affine transformations to the samples in MNIST dataset. To be consistent with the MNIST dataset and for the following experiments, we reduce the size of training, validation, and testing set of the affNIST dataset to 55000, 5000 and 10000, respectively.",
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset.",
      "Experiments In this section, we demonstrate the ability of our algorithm to resist large variations between training and testing data through a series of experiments. First, we will present a series of analyses of resisting ability and resisting flexibility of ITN. Following that we demonstrate the strong classification performance of ITN on a series of datasets, including MNIST, affNIST, SVHN, CIFAR-10 and a more challenging dataset, miniImageNet.",
      "There are 73257 digits for training, 26032 digits for testing in SVHN dataset. The CIFAR-10 dataset~ consists of 60000 color images of size 32 \\times 32. This set of 60000 images is split into two sets, 50000 images for training and 10000 images for testing."
    ],
    "raw_gpt": "{\n    \"Image\": 3,\n    \"Text\": 0,\n    \"Rationale\": \"Image 3 provides a table of testing errors for various methods on the miniImageNet dataset, which directly answers the question. Text 0 mentions the use of miniImageNet for evaluating ITN, supporting the context.\",\n    \"Answer\": \"ITN (ResNet-32) (w/DA) achieved the lowest testing error on the miniImageNet dataset.\"\n}"
  },
  "5": {
    "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?",
    "ground_truth": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.",
    "selected_figures_names": [
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Figure5-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Figure2-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 0,
    "rationale": "Image 2 shows a comparison of testing errors between AC-GATN and ITN on the MNIST dataset, which directly relates to the accuracy of the generated samples. Text 0 discusses the quality of samples generated by AC-GATN and ITN, noting that ITN generates clearer and sharper images.",
    "answer": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.",
    "text_chunks": [
      "The results shown in Figure illustrate that under our framework, using INs as the generative model achieve better performance than using GANs. By visualizing the generated samples from AC-GATN and ITN (shown in Figure ), both AC-GATN and ITN generate clear and sharp images. However, samples generated by AC-GATN have lower quality on average in terms of human standards as some of them are misleading and inaccurate, i.e. the number 3 is close to number 6 in epoch 100.",
      "We term this alternate model {\\em auxiliary classifier generative adversarial transformation networks (AC-GATNs) and qualitatively compare ITN and AC-GATN in Section 4.3, demonstrating the benefit of choosing ITNs for building robust image classifiers. The main contribution of the paper is a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner. ITN enhances the classifier by generating additional training samples, including self-generated pseudo-negative samples and transformed input samples.",
      "These lower quality samples will mislead the classifier and lead to a performance decrease. Consequently, we choose INs rather than GANs in our approach. We will provide more comparisons of AC-GATN and ITN on other datasets in the supplementary material.",
      "AC-GAN can generate class-dependent samples, which is required in our framework. The loss function of AC-GAN is replaced with the loss function from WGAN-GP to directly compare it with ITN. All experimental settings are the same for a fair comparison.",
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "Choice w.r.t generative models \\ It is essential to validate our choice of generative models. We implement our framework by using AC-GAN as the generative model and name it AC-GATN.",
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 0,\n    \"Rationale\": \"Image 2 shows a comparison of testing errors between AC-GATN and ITN on the MNIST dataset, which directly relates to the accuracy of the generated samples. Text 0 discusses the quality of samples generated by AC-GATN and ITN, noting that ITN generates clearer and sharper images.\",\n    \"Answer\": \"ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.\"\n}"
  },
  "6": {
    "question": "How does the quality of the generated samples change as the update threshold increases?",
    "ground_truth": "The quality of the generated samples decreases as the update threshold increases.",
    "selected_figures_names": [
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure2-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table7-1.png",
      "1805.06447v3-Table1-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 2,
    "rationale": "Image 2 shows samples generated by ITN with different thresholds, illustrating how sample quality changes with threshold values. Text 2 discusses the relationship between sample quality and thresholds, noting that performance drops as the threshold increases due to decreased sample quality.",
    "answer": "As the update threshold increases, the quality of the generated samples decreases, leading to a drop in performance.",
    "text_chunks": [
      "\\vspace{-15pt Effects of the update threshold \\mathbf{T_u \\ The update threshold T_u introduced in INs quantitatively controls the quality of samples in the generation process.",
      "An update threshold T_u is introduced to guarantee that the generated pseudo-negative samples are above certain criteria, which prevents bad samples from degrading the classifier performance. We modify the update threshold T_u proposed in~ and keep track of the f_{\\phi_t(x) in every iteration. In particular, we build a set D by recording \\mathbb{E",
      "In Table~, we present the results of ITN on the MNIST dataset with different thresholds to explore the relationship between the samples quality and thresholds. Not surprisingly, we observe that the performance of ITN drops when increasing the threshold. By visualizing the samples generated by different thresholds, it is clear that the performance drops due to the decrease in the quality of generated samples (Fig.~).",
      "Although our performance drops with the increase of the threshold, in a certain range (<5e-3), our result is still better than others shown in Table~, which shows that our approach tolerates samples of low qualities in some extend. \\vspace{-10pt Effects of pseudo-negative samples \\ It is worth exploring how pseudo-negative samples affect the performance of the classifier.",
      "Furthermore, the range and type of such augmentations are chosen heuristically with no strong theoretical justification. An alternative to augmentation is to synthesize additional training examples using a generative model. {\\em How can we automatically generate synthetic samples that are useful as training data to improve the robustness of CNNs to large variations in testing data?",
      "Generating pseudo-negative samples \\ ITN generates pseudo-negative samples to further enrich the coverage of unseen variations. We follow the same generation procedure as WINN. Starting from randomly initialized pseudo-negative samples, the update formula is where x_{n is the pseudo-negative samples at n-th iteration, \\lambda_g is the step size, and \\eta \\sim N(0, \\lambda_g) is the random Gaussian noise.",
      "WINN then updates the set of initial pseudo-negative samples to increase f_{\\phi_t(x) via backpropagation. The update of pseudo-negative samples is given by where \\lambda_g is a time-varying step size and \\eta \\sim N(0, \\lambda_g) is the random Gaussian noise. Resisting Variations via Introspective Learning WINN shows promising classification performance by adopting the reclassification-by-synthesis algorithm proposed by ICN~. However, both of them fail to capture large data variations between training and testing data since most of the generated pseudo-negatives are very similar to original samples.",
      "As shown in Table , ITN outperforms other methods with standard data augmentation. Limited training data Another way to evaluate the ability of resisting variations is to reduce the number of training samples. Intuitively, data variations between training and testing sets become larger when the number of testing data remains the same while the number of samples in the training set shrinks."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 2,\n    \"Rationale\": \"Image 2 shows samples generated by ITN with different thresholds, illustrating how sample quality changes with threshold values. Text 2 discusses the relationship between sample quality and thresholds, noting that performance drops as the threshold increases due to decreased sample quality.\",\n    \"Answer\": \"As the update threshold increases, the quality of the generated samples decreases, leading to a drop in performance.\"\n}"
  },
  "7": {
    "question": "Describe the relationship between the update threshold (Tu) and the performance of ITN (B-CNN) on the MNIST dataset.",
    "ground_truth": "The performance of ITN (B-CNN) on the MNIST dataset decreases as the update threshold (Tu) increases. This is evident from the increasing ITN error percentages as Tu goes from 1e-3 to 1e-1.",
    "selected_figures_names": [
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure4-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table7-1.png",
      "1805.06447v3-Table6-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table4-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 0,
    "rationale": "Image 2 shows samples generated by ITN with different thresholds, illustrating how the quality of samples changes with varying Tu. Text 0 discusses the relationship between sample quality and thresholds, noting that performance drops as the threshold increases due to decreased sample quality.",
    "answer": "The update threshold (Tu) affects the performance of ITN (B-CNN) on the MNIST dataset by influencing the quality of generated samples. As Tu increases, the quality of samples decreases, leading to a drop in performance.",
    "text_chunks": [
      "In Table~, we present the results of ITN on the MNIST dataset with different thresholds to explore the relationship between the samples quality and thresholds. Not surprisingly, we observe that the performance of ITN drops when increasing the threshold. By visualizing the samples generated by different thresholds, it is clear that the performance drops due to the decrease in the quality of generated samples (Fig.~).",
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "\\vspace{-15pt Effects of the update threshold \\mathbf{T_u \\ The update threshold T_u introduced in INs quantitatively controls the quality of samples in the generation process.",
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "Classification MNIST and affNIST Now we want to back to the most common task, classification to ensure ITN not only work well on large data variations but also boost performance on well-known benchmark datatsets. We first compare the performance of ITN against other baselines on MNIST and affNIST datasets and then gradually switch to harder datasets. As shown in Table~, ITN outperforms other baselines.",
      "Thus, we implicitly increase the variations between the training and testing data by reducing the number of samples in the training data. The purpose of this experiment is to demonstrate the potential of ITN to resist unseen variations from a different perspective. \\vspace{-10pt We design a new experiment where the training set is the MNIST dataset with only 0.1\\%, 1\\%, 10\\% and 25\\% of the whole training set while the testing set is the entire MNIST testing set.",
      "Experiments In this section, we demonstrate the ability of our algorithm to resist large variations between training and testing data through a series of experiments. First, we will present a series of analyses of resisting ability and resisting flexibility of ITN. Following that we demonstrate the strong classification performance of ITN on a series of datasets, including MNIST, affNIST, SVHN, CIFAR-10 and a more challenging dataset, miniImageNet."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 0,\n    \"Rationale\": \"Image 2 shows samples generated by ITN with different thresholds, illustrating how the quality of samples changes with varying Tu. Text 0 discusses the relationship between sample quality and thresholds, noting that performance drops as the threshold increases due to decreased sample quality.\",\n    \"Answer\": \"The update threshold (Tu) affects the performance of ITN (B-CNN) on the MNIST dataset by influencing the quality of generated samples. As Tu increases, the quality of samples decreases, leading to a drop in performance.\"\n}"
  },
  "8": {
    "question": "Which method has the lower testing error on the MNIST task?",
    "ground_truth": "ITN",
    "selected_figures_names": [
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Figure3-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure5-1.png",
      "1805.06447v3-Figure4-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 0,
    "rationale": "Image 0 provides a direct comparison of testing errors for ITN and ITN-NG on the MNIST task. Text 0 discusses the performance improvements of ITN-V2 over ITN-V1, which is relevant to understanding the effectiveness of ITN.",
    "answer": "ITN has the lower testing error on the MNIST task.",
    "text_chunks": [
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "MNIST is a benchmark dataset that includes 55000, 5000 and 10000 handwritten digits in the training, validation and testing set, respectively. The affNIST dataset is a variant from the MNIST dataset and it is built by applying various affine transformations to the samples in MNIST dataset. To be consistent with the MNIST dataset and for the following experiments, we reduce the size of training, validation, and testing set of the affNIST dataset to 55000, 5000 and 10000, respectively.",
      "The reduced training set is built by randomly sampling data from the MNIST training data while keeping the number of data per class identical. As shown in Table~, our method has better results on all tasks, which are consistent with our previous results. The constantly superior performance of ITN over data augmentation indicates its effectiveness.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "Thus, we implicitly increase the variations between the training and testing data by reducing the number of samples in the training data. The purpose of this experiment is to demonstrate the potential of ITN to resist unseen variations from a different perspective. \\vspace{-10pt We design a new experiment where the training set is the MNIST dataset with only 0.1\\%, 1\\%, 10\\% and 25\\% of the whole training set while the testing set is the entire MNIST testing set.",
      "It is easy to observe that the performance improvements on MNIST and affNIST datasets are marginal compared to experiments in Section 4.1. The most likely explanation for this observation is that the training samples in MNIST and affNIST represent the data distribution very well. In this case, providing more samples will not significantly boost the performance of the classifier.",
      "Then, we include both STs and DDTs in our model and verify the performance again. Let MNIST dataset be the training set of the experiment while the testing set is the MNIST dataset with different types of transformation applied. We introduce two types of testing sets in this section.",
      "Resisting Large Data Variations Training-MNIST-Testing-affNIST (TMTA) We first design a challenging classification task TMTA to verify the ability to resist large data variations of ITN. The training set in this experiment is the MNIST training data while the testing set is the affNIST testing data."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 0,\n    \"Rationale\": \"Image 0 provides a direct comparison of testing errors for ITN and ITN-NG on the MNIST task. Text 0 discusses the performance improvements of ITN-V2 over ITN-V1, which is relevant to understanding the effectiveness of ITN.\",\n    \"Answer\": \"ITN has the lower testing error on the MNIST task.\"\n}"
  },
  "9": {
    "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?",
    "ground_truth": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.",
    "selected_figures_names": [
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Table4-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Table5-1.png",
      "1805.06447v3-Figure3-1.png",
      "1805.06447v3-Table4-1.png",
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table1-1.png",
      "1805.06447v3-Figure5-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 0,
    "rationale": "Image 2 shows a comparison of testing errors between AC-GATN and ITN on the MNIST dataset, indicating performance differences. Text 0 discusses the quality of samples generated by AC-GATN and ITN, noting that ITN generates clearer and sharper images.",
    "answer": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.",
    "text_chunks": [
      "The results shown in Figure illustrate that under our framework, using INs as the generative model achieve better performance than using GANs. By visualizing the generated samples from AC-GATN and ITN (shown in Figure ), both AC-GATN and ITN generate clear and sharp images. However, samples generated by AC-GATN have lower quality on average in terms of human standards as some of them are misleading and inaccurate, i.e. the number 3 is close to number 6 in epoch 100.",
      "We term this alternate model {\\em auxiliary classifier generative adversarial transformation networks (AC-GATNs) and qualitatively compare ITN and AC-GATN in Section 4.3, demonstrating the benefit of choosing ITNs for building robust image classifiers. The main contribution of the paper is a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner. ITN enhances the classifier by generating additional training samples, including self-generated pseudo-negative samples and transformed input samples.",
      "These lower quality samples will mislead the classifier and lead to a performance decrease. Consequently, we choose INs rather than GANs in our approach. We will provide more comparisons of AC-GATN and ITN on other datasets in the supplementary material.",
      "AC-GAN can generate class-dependent samples, which is required in our framework. The loss function of AC-GAN is replaced with the loss function from WGAN-GP to directly compare it with ITN. All experimental settings are the same for a fair comparison.",
      "Comparing against ITN-V1 (B-CNN), ITN-V2 (B-CNN) reduces the testing errors by 6.23\\% on MNIST dataset with random DDT + ST type of variations. Additionally, it reduces the testing errors by 6.61\\% on CIFAR-10 dataset. More importantly, the performance of ITN does not degrade when the model has transformation functions that do not match the type of variations in the testing data, e.g. ITN-V2 (B-CNN) on testing data with DDT only.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "Choice w.r.t generative models \\ It is essential to validate our choice of generative models. We implement our framework by using AC-GAN as the generative model and name it AC-GATN.",
      "Then the transformed images are randomly placed in a 42 \\times 42 images. Lastly, we replicate the same experiment on the CIFAR-10 dataset. \\vspace{-10pt Agnostic to different transformation functions We observe from Table~ that ITN-V1 (B-CNN) improves the discriminator performance by 4.35\\% from WINN (B-CNN) on MNIST with random DDT transformations and by 21.81\\% on CIFAR-10 dataset."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 0,\n    \"Rationale\": \"Image 2 shows a comparison of testing errors between AC-GATN and ITN on the MNIST dataset, indicating performance differences. Text 0 discusses the quality of samples generated by AC-GATN and ITN, noting that ITN generates clearer and sharper images.\",\n    \"Answer\": \"ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.\"\n}"
  },
  "10": {
    "question": "Which method performs best on the TMTA task and how much does data augmentation contribute to its performance?",
    "ground_truth": "The ITN (B-CNN) method with data augmentation (DA) performs best on the TMTA task, achieving a testing error of 21.31%. Data augmentation contributes significantly to its performance, as the ITN (B-CNN) method without DA has a higher testing error of 31.67%.",
    "selected_figures_names": [
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table2-1.png"
    ],
    "all_figures_names": [
      "1805.06447v3-Figure1-1.png",
      "1805.06447v3-Table3-1.png",
      "1805.06447v3-Figure2-1.png",
      "1805.06447v3-Table2-1.png",
      "1805.06447v3-Figure4-1.png",
      "1805.06447v3-Table7-1.png",
      "1805.06447v3-Table8-1.png",
      "1805.06447v3-Table1-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 5,
    "rationale": "Image 0 illustrates the ITN framework, which is relevant to understanding its performance. Text 5 discusses ITN's ability to handle large data variations, specifically mentioning its performance on challenging tasks like TMTA.",
    "answer": "The ITN method performs best on the TMTA task. Data augmentation contributes to its performance by allowing ITN to generate unseen variations, enhancing its ability to resist larger variations between training and testing data.",
    "text_chunks": [
      "However, data augmentation is faster than ITN, especially when the dataset becomes large and complicated. Note that ITN works well with data augmentation as ITN (w/DA) produces the best performance. This observation adds more practical value to ITN because they can be jointly applied without contradictions.",
      "Comparing ITN against data augmentation, they have their unique advantages and disadvantages. ITN outperforms data augmentation given all results reported in previous sections. It is also a well-formulated model compared to an exhaustively searching method like data augmentation.",
      "The reduced training set is built by randomly sampling data from the MNIST training data while keeping the number of data per class identical. As shown in Table~, our method has better results on all tasks, which are consistent with our previous results. The constantly superior performance of ITN over data augmentation indicates its effectiveness.",
      "Resisting Large Data Variations Training-MNIST-Testing-affNIST (TMTA) We first design a challenging classification task TMTA to verify the ability to resist large data variations of ITN. The training set in this experiment is the MNIST training data while the testing set is the affNIST testing data.",
      "In this case, the training objective will be correctly classifying original and transformed positive samples. We evaluate the performance of this baseline on MNIST dataset, affNIST dataset, and TMTA task. We observe from Table~ that ITN-NG has the same performance as ITN on simple dataset while it has lower performance than ITN when the task becomes harder.",
      "\\vspace{-10pt Conclusion \\vspace{-2mm We proposed a principled and efficient approach that endows the classifiers with the ability to resist larger variations between training and testing data. Our method, ITN, strengthens the classifiers by generating unseen variations with various learned transformations. Experimental results show consistent performance improvements not only on the classification tasks but also on the other challenging classification tasks, such as TMTA.",
      "As shown in Table , ITN outperforms other methods with standard data augmentation. Limited training data Another way to evaluate the ability of resisting variations is to reduce the number of training samples. Intuitively, data variations between training and testing sets become larger when the number of testing data remains the same while the number of samples in the training set shrinks.",
      "The most widely adopted approach is data augmentation which applies pre-defined transformations to the training data. Nevertheless, this method is lacking since the user has to specify by-hand the types and extent of transformations applied to the training set. Better methods have been proposed by building connections between generative models and discriminative classifiers~."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 5,\n    \"Rationale\": \"Image 0 illustrates the ITN framework, which is relevant to understanding its performance. Text 5 discusses ITN's ability to handle large data variations, specifically mentioning its performance on challenging tasks like TMTA.\",\n    \"Answer\": \"The ITN method performs best on the TMTA task. Data augmentation contributes to its performance by allowing ITN to generate unseen variations, enhancing its ability to resist larger variations between training and testing data.\"\n}"
  }
}