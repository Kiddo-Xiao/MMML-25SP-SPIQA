{
  "0": {
    "question": "Why is the model discouraged even though the generated response (RSP) incorporates relevant content from the N-best response candidates (C#1 and C#2)?",
    "ground_truth": "The model is discouraged because it is trained using the Maximum Likelihood Estimation (MLE) objective, which prioritizes generating responses that are identical to the ground-truth (GT) response. Even though the RSP integrates relevant content from the candidates and seems appropriate in the context, it is penalized because it deviates from the exact wording of the GT.",
    "selected_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png"
    ],
    "all_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png",
      "1809.04276v2-Figure1-1.png",
      "1809.04276v2-Table5-1.png",
      "1809.04276v2-Figure2-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 0,
    "rationale": "Image 0 provides an example of how the generated response (RSP) incorporates content from N-best response candidates (C#1 and C#2), which is relevant to the question. Text 0 explains why the model is discouraged despite this incorporation, as it deviates from the ground-truth response.",
    "answer": "The model is discouraged because the generated response, while incorporating relevant content from the N-best response candidates, differs from the ground-truth response. This deviation from the expected response is why the model's performance is not aligned with the desired outcome.",
    "text_chunks": [
      "Related contents of the candidates are appropriately integrated into the response, but the model is discouraged as the response is different from the ground-truth. On the other hand, rather than just provide materials for the generation, N-best response candidates also contain references for evaluating responses. Yet they are not efficiently utilized in the objective in the existing training process.",
      "Finally, the top N (set to 2, as in~\\citealp{song2018ensemble) responses are returned as the N-best response candidates. Note that when we collect N-best response candidates for a training message, the most similar document retrieved is always the one whose message is exactly the training message and responses contain the ground-truth response. We thus remove the document from the retrieved result before re-ranking to make sure that the N-best response candidates are different from the ground-truth response.",
      "Therefore, it is natural to enhance the response generation approach with retrieved responses. Previous work has been proposed to extend the input of a Seq2Seq model with N-best response candidates (or their contexts)~. On one hand, these approaches are trained using MLE objective, which correlates weakly with true quality of responses thus limits the effectiveness of the candidates in producing the responses. Table~ shows an example during the training process.",
      "Note that the improvement after introducing candidates in Dist-1 and Originality is not as significant as that in Dist-2. This is because responses of MLE based models (MS2S and EDIT) tend to contain informative content with simple sentence structures, like ``... is (not) good.'' (as shown in Figure~), resulting in high Dist-1 and Originality scores, but their Dist-2 scores are relatively lower than AL and Ours.",
      "To understand the importance of different components of our approach, we also train two variants: D+ and G+, where N-best response candidates are only available for the discriminator and the generator, respectively. Note that AL does not utilize candidates in the generator nor the discriminator, thus can be seen as a start point of D+ and G+. As shown in Table~, there is an improvement in the performance of both the two variants after introducing the candidates comparing to AL.",
      "In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) approach to make better use of N-best response candidates. A discriminator is introduced to replace the MLE objective to supervise the training process. Generated responses containing appropriate and informative contents with input messages are more likely to be seen as human-generated by the discriminator, which encourages the generation model to incorporate more information in candidates into responses.",
      "Figure~ shows an example of responses of different models along with the input message and N-best response candidates (C\\#1 and C\\#2). The C\\#1, which best matches the message among all the candidates, is also the response of the Rtr baseline. We can see that it contains diverse content, such as ``Unicom'' and ``Telecom''(two telecommunication operators in China, providing broadband, mobile communication as well as customized mobile phones).",
      "By introducing N-best response candidates, our approach further increases Dist-2 by 0.112 based on AL (from 0.124 to 0.236) and the improvement is significant (t-test, p<0.01). In contrast, the increase of Dist-2 after combining N-best response candidates in MLE based approach is only 0.062, comparing MS2S with S2S. This suggests that introducing a discriminator with adversarial training is more effective than MLE objective in utilizing N-best response candidates to generate more diverse n-grams."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 0,\n    \"Rationale\": \"Image 0 provides an example of how the generated response (RSP) incorporates content from N-best response candidates (C#1 and C#2), which is relevant to the question. Text 0 explains why the model is discouraged despite this incorporation, as it deviates from the ground-truth response.\",\n    \"Answer\": \"The model is discouraged because the generated response, while incorporating relevant content from the N-best response candidates, differs from the ground-truth response. This deviation from the expected response is why the model's performance is not aligned with the desired outcome.\"\n}"
  },
  "1": {
    "question": "How does the performance of the discriminator in the proposed approach compare to the conventional discriminator in AL? What evidence suggests this difference in performance?",
    "ground_truth": "The discriminator in the author's approach achieves higher accuracy (95.72%) compared to the conventional discriminator in AL (94.01%).",
    "selected_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png"
    ],
    "all_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png",
      "1809.04276v2-Figure1-1.png",
      "1809.04276v2-Table5-1.png",
      "1809.04276v2-Figure2-1.png"
    ],
    "chosen_image_idx": 2,
    "chosen_text_idx": 0,
    "rationale": "Image 2 shows the classification accuracy of discriminators in AL and the proposed approach, directly comparing their performance. Text 0 discusses the accuracy of different discriminators, indicating that the proposed approach achieves higher accuracy.",
    "answer": "The discriminator in the proposed approach performs better than the conventional discriminator in AL, achieving higher classification accuracy. Image 2 shows the accuracy as 95.72% for the proposed approach compared to 94.01% for AL, and Text 0 supports this by stating that the proposed discriminator achieves higher accuracy.",
    "text_chunks": [
      "Note that the two discriminators after pre-training or adversarial training cannot be compared directly because they are trained by different negative samples produced by different generators. We thus create a special dataset for this metric where negative samples are generated by a well-trained generator (otherwise, the accuracy will easily reach nearly 100\\% as fixed negative samples of low quality are too easy to be distinguished) of AL in advance. Analysis The results of the classification accuracy of different discriminators are presented in Table~. Trained on an identical dataset, our discriminator achieves higher accuracy than the conventional discriminator in AL.",
      "To understand the importance of different components of our approach, we also train two variants: D+ and G+, where N-best response candidates are only available for the discriminator and the generator, respectively. Note that AL does not utilize candidates in the generator nor the discriminator, thus can be seen as a start point of D+ and G+. As shown in Table~, there is an improvement in the performance of both the two variants after introducing the candidates comparing to AL.",
      "The improvement in G+ is more significant as its generator can directly utilize the candidates as generation materials. While candidates' information in D+ is compressed into a discriminative signal by the discriminator. Nevertheless, introducing candidates into the discriminator helps to generate more diverse responses comparing AL with D+, and G+ with Ours, demonstrating that the retrieval-enhanced discriminator is able to benefit the generator.",
      "By introducing N-best response candidates, our approach further increases Dist-2 by 0.112 based on AL (from 0.124 to 0.236) and the improvement is significant (t-test, p<0.01). In contrast, the increase of Dist-2 after combining N-best response candidates in MLE based approach is only 0.062, comparing MS2S with S2S. This suggests that introducing a discriminator with adversarial training is more effective than MLE objective in utilizing N-best response candidates to generate more diverse n-grams.",
      "We employ {\\it Dist-1 and {\\it Dist-2~ to evaluate the diversity of responses, where Dist-k is the number of distinct k-grams normalized by the total number of words of responses. We also evaluate the {\\it Originality by computing the ratio of responses that do not appear in the training set~. To validate the effectiveness of retrieved candidates in enhancing the discriminator, the classification accuracy of the discriminator in AL and our approach is also reported.",
      "The proposed approach is also related to \\citeauthor{lin2017adv\\shortcite{lin2017adv's work. They propose an unconditional GAN whose discriminator is augmented with references randomly sampled from the training set for the task of language generation. In contrast, the proposed approach focuses on the response generation and leverages the message as prior knowledge.",
      "In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) approach to make better use of N-best response candidates. A discriminator is introduced to replace the MLE objective to supervise the training process. Generated responses containing appropriate and informative contents with input messages are more likely to be seen as human-generated by the discriminator, which encourages the generation model to incorporate more information in candidates into responses.",
      "\\citeauthor{wu2019response\\shortcite{wu2019response augments the decoder with an edit vector representing lexical differences between retrieved contexts and the message. Different from previous work, our approach introduces a discriminator to replace the MLE objective to compute the loss. Besides, rather than merely being sent to the encoder as generation materials, response candidates in our approach are directly utilized by the discriminator to form a discriminative signal to guide the generator."
    ],
    "raw_gpt": "{\n    \"Image\": 2,\n    \"Text\": 0,\n    \"Rationale\": \"Image 2 shows the classification accuracy of discriminators in AL and the proposed approach, directly comparing their performance. Text 0 discusses the accuracy of different discriminators, indicating that the proposed approach achieves higher accuracy.\",\n    \"Answer\": \"The discriminator in the proposed approach performs better than the conventional discriminator in AL, achieving higher classification accuracy. Image 2 shows the accuracy as 95.72% for the proposed approach compared to 94.01% for AL, and Text 0 supports this by stating that the proposed discriminator achieves higher accuracy.\"\n}"
  },
  "2": {
    "question": "Can you explain the discrepancy between the number of messages and responses in each dataset?",
    "ground_truth": "Number of responses is significantly higher than number of messages in each dataset (training, validation, and test). This is because each message can have multiple responses associated with it. The passage mentions that users on Sina Weibo can post messages and also comment on other users' messages. These comments are considered as responses in the context of the table. Therefore, one message can have several responses, leading to a higher total number of responses compared to messages.",
    "selected_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png"
    ],
    "all_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png",
      "1809.04276v2-Figure1-1.png",
      "1809.04276v2-Table5-1.png",
      "1809.04276v2-Figure2-1.png"
    ],
    "chosen_image_idx": 1,
    "chosen_text_idx": 6,
    "rationale": "Image 1 provides the statistics of the datasets, showing the number of messages and responses in training, validation, and test sets. Text 6 explains the nature of retrieval-based methods, which involve selecting responses from a pre-constructed set, leading to a larger number of responses compared to messages.",
    "answer": "The discrepancy between the number of messages and responses in each dataset is due to the nature of retrieval-based methods. These methods use a pre-constructed set of responses, which results in a larger pool of responses compared to the number of messages.",
    "text_chunks": [
      "Then, we randomly select 10,000 messages associated with responses to form a validation set and another 10,000 messages with responses as a test set. Table shows some statistics of the datasets. \\caption{ Human evaluation results of mean score, proportions of three levels (+2, +1, and 0), and the agreements measured by Fleiss's Kappa in appropriateness, informativeness, and grammaticality.",
      "Figure~ shows an example of responses of different models along with the input message and N-best response candidates (C\\#1 and C\\#2). The C\\#1, which best matches the message among all the candidates, is also the response of the Rtr baseline. We can see that it contains diverse content, such as ``Unicom'' and ``Telecom''(two telecommunication operators in China, providing broadband, mobile communication as well as customized mobile phones).",
      "However, it may also contain some irrelevant information, leading to a bad performance in appropriateness. Besides, most responses in Rtr are annotated as +2 or 0 in informativeness. This is also because Rtr responses are extremely diverse which always include new content, making a response tend to get +2 if the content are relevant, otherwise 0.",
      "In contrast, generation-based methods can produce responses tailored to the messages. The most common method of this category in recent years is the sequence to sequence (Seq2Seq) model~. In practice, it usually suffers from the problem of generating generic responses, such as ``I don't know'' and ``Me, too''~. While the contents of retrieved responses, apart from the irrelevant parts, are of great diversity, making it a potential resource for tailoring appropriate and informative responses.",
      "However, it talks about ``the call'' between the two operators, which is irrelevant to the message. The response of S2S is a generic response. AL has a more diverse response than S2S, however, it does not have access to candidates, which limits the diversity.",
      "The contributions of this paper are summarized as follows: Related Work Data-driven dialogue systems can be roughly divided into two categories: retrieval-based and generation-based. Retrieval-based methods respond to users by selecting the response that best matches an input message from a pre-constructed response set. \\newcite{leuski2009building match a response with a message using a statistical language model.",
      "Recently, with the rise of social networking, conversational data have accumulated to a considerable scale. This promoted the development of data-driven methods, including retrieval-based methods~ and generation-based methods~. Retrieval-based methods reply to users by searching and re-ranking response candidates from a pre-constructed response set. Written mainly by humans, these responses are always diverse and informative, but may be inappropriate to input messages due to their being prepared in advance and thus incapable of being customized~.",
      "In the inference process, we generate responses using beam search with beam size set to 5. Results Evaluation Metrics \\paragraph{Human Evaluation We randomly sampled 200 messages from the test set to conduct the human evaluation as it is extremely time-consuming. Five annotators are recruited to judge a response from three aspects~: These aspects are evaluated independently."
    ],
    "raw_gpt": "{\n    \"Image\": 1,\n    \"Text\": 6,\n    \"Rationale\": \"Image 1 provides the statistics of the datasets, showing the number of messages and responses in training, validation, and test sets. Text 6 explains the nature of retrieval-based methods, which involve selecting responses from a pre-constructed set, leading to a larger number of responses compared to messages.\",\n    \"Answer\": \"The discrepancy between the number of messages and responses in each dataset is due to the nature of retrieval-based methods. These methods use a pre-constructed set of responses, which results in a larger pool of responses compared to the number of messages.\"\n}"
  },
  "3": {
    "question": "How does the discriminator in the proposed REAT approach use the N-best response candidates?",
    "ground_truth": "The discriminator takes as input a response and the N-best response candidates, and outputs the probability that the response is human-generated.",
    "selected_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png"
    ],
    "all_figures_names": [
      "1809.04276v2-Table1-1.png",
      "1809.04276v2-Table2-1.png",
      "1809.04276v2-Table4-1.png",
      "1809.04276v2-Table3-1.png",
      "1809.04276v2-Figure1-1.png",
      "1809.04276v2-Table5-1.png",
      "1809.04276v2-Figure2-1.png"
    ],
    "chosen_image_idx": 0,
    "chosen_text_idx": 7,
    "rationale": "Image 0 provides an example of how N-best response candidates are used in the training process, which is relevant to understanding the role of the discriminator. Text 7 explains the function of the discriminator in the REAT approach, specifically how it uses N-best response candidates to improve response generation.",
    "answer": "The discriminator in the REAT approach uses N-best response candidates as references to better distinguish a response, which in turn improves the generator by adversarial training.",
    "text_chunks": [
      "In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) approach to make better use of N-best response candidates. A discriminator is introduced to replace the MLE objective to supervise the training process. Generated responses containing appropriate and informative contents with input messages are more likely to be seen as human-generated by the discriminator, which encourages the generation model to incorporate more information in candidates into responses.",
      "In addition, the N-best response candidates are also conditioned to the discriminator as references to improve its classification accuracy, which in turn benefits the generation model by adversarial training. We conduct extensive experiments on a public available NTCIR corpus to verify the effectiveness of the proposed approach, comparing it with retrieval-based methods, generation-based methods, and previous retrieval-enhanced response generation approaches. The results show that the REAT approach significantly outperforms the baselines in both automatic and human evaluations.",
      "In addition, rather than sampling references from the training set, the candidates in our approach are retrieved according to the relevance to messages using a retrieval-based method. Method In this section, we introduce our proposed REAT approach.",
      "By introducing N-best response candidates, our approach further increases Dist-2 by 0.112 based on AL (from 0.124 to 0.236) and the improvement is significant (t-test, p<0.01). In contrast, the increase of Dist-2 after combining N-best response candidates in MLE based approach is only 0.062, comparing MS2S with S2S. This suggests that introducing a discriminator with adversarial training is more effective than MLE objective in utilizing N-best response candidates to generate more diverse n-grams.",
      "MLE based retrieval-enhanced models can make use of the content of candidates, like ``Telecom'' in EDIT, but the way they present the content is not as diverse as ours. Conclusion and Future Work We propose a Retrieval-Enhanced Adversarial Training method for neural response generation in dialogue systems. In contrast to existing approaches, our REAT method directly uses response candidates from retrieval-based systems to improve the discriminator in adversarial training.",
      "To understand the importance of different components of our approach, we also train two variants: D+ and G+, where N-best response candidates are only available for the discriminator and the generator, respectively. Note that AL does not utilize candidates in the generator nor the discriminator, thus can be seen as a start point of D+ and G+. As shown in Table~, there is an improvement in the performance of both the two variants after introducing the candidates comparing to AL.",
      "Therefore, it can benefit from the advantages of retrieval-based response candidates as well as neural responses from generation-based systems. Experiments show that the REAT method significantly improves the quality of the generated responses, which demonstrates the effectiveness of this approach. In future research, we will further investigate how to better leverage larger training data to improve the REAT method.",
      "As Figure~ shows, it consists of two main components: a discriminator D (Sec.~) and a generator G (Sec.~), both of which are enhanced by N-best response candidates from a retrieval-based method (Sec.~). The generator produces a response using the candidates as generation materials. While in the discriminator, the candidates are provided as references to better distinguish a response, which in turn improves the generator by adversarial training (Sec.~)."
    ],
    "raw_gpt": "{\n    \"Image\": 0,\n    \"Text\": 7,\n    \"Rationale\": \"Image 0 provides an example of how N-best response candidates are used in the training process, which is relevant to understanding the role of the discriminator. Text 7 explains the function of the discriminator in the REAT approach, specifically how it uses N-best response candidates to improve response generation.\",\n    \"Answer\": \"The discriminator in the REAT approach uses N-best response candidates as references to better distinguish a response, which in turn improves the generator by adversarial training.\"\n}"
  }
}