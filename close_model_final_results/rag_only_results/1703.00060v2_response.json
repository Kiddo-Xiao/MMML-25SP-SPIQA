{"0": {"question": "How does the discrimination in the prediction of the two-phase framework (MSG) compare to that of DI, both with and without classifier tweaking, when the sample size is 2000?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Text': 3, 'Rationale': 'Image 0 provides specific discrimination values for different sample sizes and methods, focusing on the two-phase framework (MSG) and DI with and without classifier tweaking. Text 3 discusses the effectiveness of discrimination removal and highlights the issue of residual discrimination in prediction, even after data modification.', 'Answer': 'For a sample size of 2000, with classifier tweaking, the MSG framework has a prediction discrimination (DE_{M,h^*}) of 0.067 while DI has 0.095. Without classifier tweaking, MSG has 0.068 while DI has 0.107. MSG consistently shows lower discrimination.'}", "all_figures_names": ["1703.00060v2-Table2-1.png", "1703.00060v2-Table1-1.png"], "referred_figures_names": ["1703.00060v2-Table2-1.png"], "answer": "When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.\n\nWith classifier tweaking: MSG achieves a discrimination level of 0.016 \u00b1 5.3E-4, while DI shows a significantly higher level of 0.095 \u00b1 1.6E-3.\nWithout classifier tweaking: MSG still demonstrates lower discrimination with 0.067 \u00b1 4.3E-3 compared to DI's 0.095 \u00b1 1.6E-3.\n\nThis indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Based on the underlying distribution of \\mathcal{M, we generate a number of training data sets with different sample sizes. When constructing discrimination-free classifiers using the two-phase framework, we select one representative data modifying algorithm that only modifies L, the Massaging (MSG) algorithm . For other algorithms, we will evaluate their performance in preserving data utility in the future work.", "For comparison, the same process is also performed for DI. The results are shown in Table . By using the two-phase framework, discrimination is removed from the training data as shown by \\mathrm{DE_{\\mathcal{D^{*, and more importantly, removed from the prediction as shown by \\mathrm{DE_{\\mathcal{M_{h^{*.", "To show the effectiveness of the two-phase framework, we first apply MSG to completely remove the discrimination in the above training data, obtaining the modified training data \\mathcal{D^{*. Then, a decision tree h^{* is built on \\mathcal{D^{*, and the RandomFlip algorithm is executed to tweak the classifier so that the error bias is less than 0.05, i.e., \\left| \\varepsilon_{h^{*,\\mathcal{D^{* \\right| \\leq 0.05. Finally, we measure the discrimination in \\mathcal{M_{h^{*.", "We also see that, if the classifier tweaking is not performed, the prediction still contains discrimination. However, for DI, even when the discrimination is removed from the training data, and the error bias in the classifier is also removed, there still exists discrimination in prediction. These results are consistent with our theoretical conclusions.", "We show that to guarantee non-discrimination in prediction, the pre-process methods should only modify the label. Based on the results, we develop a two-phase framework for constructing a discrimination-free classifier with a theoretical guarantee, which provides a guideline for employing existing pre-process methods or designing new ones. The experiments demonstrate the theoretical results and show the effectiveness of our two-phase framework.", "Conclusions In this paper, we addressed the limitation of the pre-process methods that there is no guarantee about the discrimination in prediction. Our theoretical results show that: (1) only removing discrimination from the training data cannot ensure non-discrimination in prediction for any classifier; and (2) when removing discrimination from the training data, one should only modify the labels in order to obtain a non-discrimination guarantee. Based on the results, we developed a two-phase framework for constructing a discrimination-free classifier with a theoretical guarantee.", "For comparison, we also include an algorithm that modifies \\mathbf{Z, the Disparate Impact Removal (DI) algorithm . The proposed RandomFlip algorithm is used for tweaking the classifier. We assume a discrimination threshold \\tau = 0.05, i.e., we want to ensure that the discrimination in prediction is not larger than 0.05.", "Due to the sparse data issue, we binarize each attribute's domain values into two classes to reduce the domain sizes. We treat \\texttt{sex as C and \\texttt{income as L. The discrimination is measured as 0.13 in \\mathcal{M, i.e., \\mathrm{DE_{\\mathcal{M = 0.13."], "referred_text_chunks": ["Based on the underlying distribution of \\mathcal{M, we generate a number of training data sets with different sample sizes. When constructing discrimination-free classifiers using the two-phase framework, we select one representative data modifying algorithm that only modifies L, the Massaging (MSG) algorithm . For other algorithms, we will evaluate their performance in preserving data utility in the future work."]}}