{"0": {"question": "What is the main difference between the Multilinear Conditioning architecture and the Randomized Multilinear Conditioning architecture?", "referred_figures_indices": [7], "response": "{'Image': 7, 'Text': 3, 'Rationale': 'Image 7 directly compares Multilinear and Randomized Multilinear Conditioning architectures. Text 3 discusses how the multilinear map captures multimodal structures effectively.', 'Answer': 'The main difference is that Multilinear Conditioning uses a standard multilinear map for conditioning, suitable for lower-dimensional scenarios. In contrast, Randomized Multilinear Conditioning utilizes a randomized multilinear map, adapting it for higher-dimensional scenarios.'}", "all_figures_names": ["1705.10667v4-Table5-1.png", "1705.10667v4-Figure2-1.png", "1705.10667v4-Figure3-1.png", "1705.10667v4-Table4-1.png", "1705.10667v4-Table3-1.png", "1705.10667v4-Table2-1.png", "1705.10667v4-Table1-1.png", "1705.10667v4-Figure1-1.png"], "referred_figures_names": ["1705.10667v4-Figure1-1.png"], "answer": "The main difference is that the Multilinear Conditioning architecture uses a multilinear map to condition the domain discriminator on the classifier prediction, while the Randomized Multilinear Conditioning architecture uses a randomized multilinear map.", "figure_type": "Schematic", "content_type": "figure", "text_chunks": ["Multilinear Conditioning The multilinear map is defined as the outer product of multiple random vectors. And the multilinear map of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint distribution or conditional distribution into reproducing kernel Hilbert spaces . Given two random vectors \\mathbf{x and \\mathbf{y, the joint distribution P(\\mathbf{x,\\mathbf{y) can be modeled by the cross-covariance \\mathbb{E_{\\mathbf{{xy[\\phi(\\mathbf{x)", "As such, the conditional domain discriminator successfully models the multimodal information and joint distributions of {\\bf f and {\\bf g. Also, the multi-linearity can accommodate random vectors {\\bf f and {\\bf g with different cardinalities and magnitudes. A disadvantage of the multilinear map is dimension explosion. Denoting by d_f", "This conditioning strategy is widely adopted by existing conditional GANs . However, with the concatenation strategy, {\\bf f and {\\bf g are independent on each other, thus failing to fully capture multiplicative interactions between feature representation and classifier prediction, which are crucial to domain adaptation. As a result, the multimodal information conveyed in classifier prediction cannot be fully exploited to match the multimodal distributions of complex domains .", "Superior than concatenation, the multilinear map \\mathbf{x \\otimes \\mathbf{y can fully capture the multimodal structures behind complex data distributions. Taking the advantage of multilinear map, in this paper, we condition D on {\\bf g with the multilinear map where T_\\otimes is a multilinear map and D({\\bf f,{\\bf g) = D({\\bf f \\otimes{\\bf g).", "Table~\\sim shows that CDAN+E outperforms CDAN, proving that entropy conditioning can prioritize easy-to-transfer examples and encourage certain predictions. Conditioning Strategies\\quad Besides multilinear conditioning, we investigate DANN-[f,g] with the domain discriminator imposed on the concatenation of {\\bf f and {\\bf g, DANN-f and DANN-g with the domain discriminator plugged in feature layer {\\bf f and classifier layer {\\bf g. Figure~ shows accuracies on A \\rightarrow W and A \\rightarrow D based on ResNet-50.", "Recent advances in Conditional Generative Adversarial Networks (CGANs) discover that different distributions can be matched better by conditioning the generator and discriminator on relevant information, such as associated labels and affiliated modality. Conditional GANs generate globally coherent images from datasets with high variability and multimodal distributions. Motivated by conditional GANs, we observe that in adversarial domain adaptation, the classifier prediction {\\bf g conveys discriminative information potentially revealing the multimodal structures, which can be conditioned on when adapting feature representation {\\bf f. By conditioning, domain variances in both feature representation {\\bf f and classifier prediction {\\bf g can be modeled simultaneously.", "These methods do not explore the dependency between the features and classes in a unified conditional domain discriminator, which is important to capture the multimodal structures underlying data distributions. This paper extends the conditional adversarial mechanism to enable discriminative and transferable domain adaptation, by defining the domain discriminator on the features while conditioning it on the class information. Two novel conditioning strategies are designed to capture the cross-covariance dependency between the feature representations and class predictions while controlling the uncertainty of classifier predictions.", "This is different from aligning the features and classes separately . Conditional Adversarial Domain Adaptation In unsupervised domain adaptation, we are given a source domain \\mathcal{D_s = \\{(\\mathbf{x_i^s,{\\bf y^s_i)\\_{i=1^{n_s of n_s labeled examples and a target domain {{\\cal D_t = \\{ {\\bf{x_j^t\\ _{j = 1^{{n_t of n_t unlabeled examples."], "referred_text_chunks": ["Multilinear Conditioning The multilinear map is defined as the outer product of multiple random vectors. And the multilinear map of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint distribution or conditional distribution into reproducing kernel Hilbert spaces . Given two random vectors \\mathbf{x and \\mathbf{y, the joint distribution P(\\mathbf{x,\\mathbf{y) can be modeled by the cross-covariance \\mathbb{E_{\\mathbf{{xy[\\phi(\\mathbf{x)"]}, "1": {"question": "Which of the four methods (ResNet, DANN, CDAN-f, CDAN-fg) is most effective at separating the two classes of data points?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Text': 0, 'Rationale': 'Image 2 shows a clear t-SNE visualization of how different methods separate data points, directly illustrating the separation of classes. Text 0 describes how CDAN-fg outperforms other methods in aligning domains and discriminating categories, indicating its effectiveness at separating classes.', 'Answer': 'CDAN-fg is most effective at separating the two classes of data points.'}", "all_figures_names": ["1705.10667v4-Table5-1.png", "1705.10667v4-Figure2-1.png", "1705.10667v4-Figure3-1.png", "1705.10667v4-Table4-1.png", "1705.10667v4-Table3-1.png", "1705.10667v4-Table2-1.png", "1705.10667v4-Table1-1.png", "1705.10667v4-Figure1-1.png"], "referred_figures_names": ["1705.10667v4-Figure3-1.png"], "answer": "CDAN-fg", "figure_type": "plot", "content_type": "figure", "text_chunks": ["The source and target are not aligned well with ResNet, better aligned with DANN but categories are not discriminated well. They are aligned better and categories are discriminated better by CDAN-f, while CDAN-fg is evidently better than CDAN-f. This shows the benefit of conditioning adversarial adaptation on discriminative predictions.", "We observe that {\\mathrm{dist_{\\cal A on CDAN features is smaller than {\\mathrm{dist_{\\cal A on both ResNet and DANN features, implying that CDAN features can reduce the domain gap more effectively. As domains W and D are similar, {\\mathrm{dist_{\\cal A of task W \\rightarrow D is smaller than that of A \\rightarrow W, implying higher accuracies. Convergence\\quad We testify the convergence of ResNet, DANN, and CDANs, with the test errors on task A \\rightarrow W shown in Figure~. CDAN enjoys faster convergence than DANN, while CDAN (M) converges faster than CDAN (RM).", "Note that CDAN (M) constitutes high-dimensional multilinear map, which is slightly more costly than CDAN (RM), while CDAN (RM) has similar cost as DANN. \\paragraph{Visualization We visualize by t-SNE in Figures~-- the representations of task A \\rightarrow W (31 classes) by ResNet, DANN, CDAN-f, and CDAN-fg.", "Table~\\sim shows that CDAN+E outperforms CDAN, proving that entropy conditioning can prioritize easy-to-transfer examples and encourage certain predictions. Conditioning Strategies\\quad Besides multilinear conditioning, we investigate DANN-[f,g] with the domain discriminator imposed on the concatenation of {\\bf f and {\\bf g, DANN-f and DANN-g with the domain discriminator plugged in feature layer {\\bf f and classifier layer {\\bf g. Figure~ shows accuracies on A \\rightarrow W and A \\rightarrow D based on ResNet-50.", "The results on the ImageCLEF-DA dataset are reported in Table . The CDAN models outperform the comparison methods on most transfer tasks, but with smaller rooms of improvement. This is reasonable since the three domains in ImageCLEF-DA are of equal size and balanced in each category, and are visually more similar than Office-31, making the former dataset easier for domain adaptation.", "We compare Conditional Domain Adversarial Network (CDAN) with state-of-art domain adaptation methods: Deep Adaptation Network (DAN) , Residual Transfer Network (RTN) , Domain Adversarial Neural Network (DANN) , Adversarial Discriminative Domain Adaptation (ADDA) , Joint Adaptation Network (JAN) , Unsupervised Image-to-Image Translation (UNIT) , Generate to Adapt (GTA) , Cycle-Consistent Adversarial Domain Adaptation (CyCADA) . We follow the standard protocols for unsupervised domain adaptation . We use all labeled source examples and all unlabeled target examples and compare the average classification accuracy based on three random experiments.", "Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model.", "We formulate Conditional Domain Adversarial Network (CDAN) as a minimax optimization problem with two competitive error terms: (a) \\mathcal{E(G) on the source classifier G, which is minimized to guarantee lower source risk; (b) \\mathcal{E({D,G) on the source classifier G and the domain discriminator D across the source and target domains, which is minimized over D but maximized over \\mathbf{f = F(\\mathbf{x) and \\mathbf{g = G(\\mathbf{x): where L(\\cdot, \\cdot) is the cross-entropy loss, and {\\bf h = ({\\bf f, {\\bf g) is the joint variable of feature representation {\\bf f and classifier prediction {\\bf g. The minimax game of conditional domain adversarial network (CDAN) is \\end{equation where \\lambda is a hyper-parameter between the two objectives to tradeoff source risk and domain adversary. We condition domain discriminator D on the classifier prediction {\\bf g through joint variable {\\bf h = ({\\bf f, {\\bf g)."], "referred_text_chunks": ["The source and target are not aligned well with ResNet, better aligned with DANN but categories are not discriminated well. They are aligned better and categories are discriminated better by CDAN-f, while CDAN-fg is evidently better than CDAN-f. This shows the benefit of conditioning adversarial adaptation on discriminative predictions."]}, "2": {"question": "Why might CDAN+E be considered a more versatile method for unsupervised domain adaptation compared to UNIT, CyCADA, and GTA?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Text': 1, 'Rationale': \"Image 3 shows performance comparisons of CDAN+E with other methods, highlighting its versatility across different tasks, while Text 1 highlights CDAN+E's advantages over complex methods like GTA, emphasizing its efficacy on diverse datasets.\", 'Answer': \"CDAN+E is considered more versatile because it outperforms other methods like UNIT, CyCADA, and GTA across various transfer tasks. It achieves high accuracy even when the source and target domains are significantly different, without the complex design that other methods require.\"}", "all_figures_names": ["1705.10667v4-Table5-1.png", "1705.10667v4-Figure2-1.png", "1705.10667v4-Figure3-1.png", "1705.10667v4-Table4-1.png", "1705.10667v4-Table3-1.png", "1705.10667v4-Table2-1.png", "1705.10667v4-Table1-1.png", "1705.10667v4-Figure1-1.png"], "referred_figures_names": ["1705.10667v4-Table4-1.png"], "answer": "CDAN+E performs well across all five datasets listed in the table, including both digit and synthetic-to-real datasets, while UNIT, CyCADA, and GTA show strong results only on the digits and synthetic-to-real datasets.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model.", "The CDAN models significantly outperform all comparison methods on most transfer tasks, where CDAN+E is a top-performing variant and CDAN performs slightly worse. It is desirable that CDAN promotes the classification accuracies substantially on hard transfer tasks, e.g. A \\rightarrow W and A \\rightarrow D, where the source and target domains are substantially different . Note that, CDAN+E even outperforms generative pixel-level domain adaptation method GTA, which has a very complex design in both architecture and objectives.", "= 1+e^{-H(\\mathbf{g). The entropy conditioning variant of CDAN (CDAN+E) for improved transferability is formulated as \\end{equation The domain discriminator empowers the entropy minimization principle and encourages certain predictions, enabling CDAN+E to further perform semi-supervised learning on unlabeled target data. \\vspace{-5pt Generalization Error Analysis \\vspace{-5pt We give an analysis of the CDAN method taking similar formalism of the domain adaptation theory .", "We compare Conditional Domain Adversarial Network (CDAN) with state-of-art domain adaptation methods: Deep Adaptation Network (DAN) , Residual Transfer Network (RTN) , Domain Adversarial Neural Network (DANN) , Adversarial Discriminative Domain Adaptation (ADDA) , Joint Adaptation Network (JAN) , Unsupervised Image-to-Image Translation (UNIT) , Generate to Adapt (GTA) , Cycle-Consistent Adversarial Domain Adaptation (CyCADA) . We follow the standard protocols for unsupervised domain adaptation . We use all labeled source examples and all unlabeled target examples and compare the average classification accuracy based on three random experiments.", "\\vspace{-5pt Analysis \\vspace{-5pt Ablation Study\\quad We examine the sampling strategies of the random matrices in Equation~\\eqref{eqn:R. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. Table~ shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants.", "\\vspace{-5pt Conclusion \\vspace{-5pt This paper presented conditional domain adversarial networks (CDANs), novel approaches to domain adaptation with multimodal distributions. Unlike previous adversarial adaptation methods that solely match the feature representation across domains which is prone to under-matching, the proposed approach further conditions the adversarial domain adaptation on discriminative information to enable alignment of multimodal distributions. Experiments validated the efficacy of the proposed approach.", "Table~\\sim shows that CDAN+E outperforms CDAN, proving that entropy conditioning can prioritize easy-to-transfer examples and encourage certain predictions. Conditioning Strategies\\quad Besides multilinear conditioning, we investigate DANN-[f,g] with the domain discriminator imposed on the concatenation of {\\bf f and {\\bf g, DANN-f and DANN-g with the domain discriminator plugged in feature layer {\\bf f and classifier layer {\\bf g. Figure~ shows accuracies on A \\rightarrow W and A \\rightarrow D based on ResNet-50.", "This is different from aligning the features and classes separately . Conditional Adversarial Domain Adaptation In unsupervised domain adaptation, we are given a source domain \\mathcal{D_s = \\{(\\mathbf{x_i^s,{\\bf y^s_i)\\_{i=1^{n_s of n_s labeled examples and a target domain {{\\cal D_t = \\{ {\\bf{x_j^t\\ _{j = 1^{{n_t of n_t unlabeled examples."], "referred_text_chunks": ["Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model."]}, "3": {"question": "Which sampling strategy for random matrices in CDAN+E leads to the highest average accuracy across all domain adaptation tasks on Office-31? How does this compare to the performance of CDAN+E variants that use random sampling?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Text': 0, 'Rationale': \"Image 0 directly compares the performance of CDAN+E with different sampling strategies, relevant to the question. Text 0 references the performance comparison of CDAN+E sampling strategies, aligning with the image data.\", 'Answer': \"CDAN+E without random sampling leads to the highest average accuracy (87.7%) across all domain adaptation tasks on Office-31, outperforming the variants with Gaussian (86.4%) and Uniform (87.0%) random sampling.\"}", "all_figures_names": ["1705.10667v4-Table5-1.png", "1705.10667v4-Figure2-1.png", "1705.10667v4-Figure3-1.png", "1705.10667v4-Table4-1.png", "1705.10667v4-Table3-1.png", "1705.10667v4-Table2-1.png", "1705.10667v4-Table1-1.png", "1705.10667v4-Figure1-1.png"], "referred_figures_names": ["1705.10667v4-Table5-1.png"], "answer": "The table shows that CDAN+E (w/o random sampling) achieves the highest average accuracy of 87.7% across all domain adaptation tasks. This is slightly higher than the performance of CDAN+E with uniform sampling (87.0%) and Gaussian sampling (86.4%).", "figure_type": "N/A", "content_type": "table", "text_chunks": ["\\vspace{-5pt Analysis \\vspace{-5pt Ablation Study\\quad We examine the sampling strategies of the random matrices in Equation~\\eqref{eqn:R. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. Table~ shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants.", "The CDAN models significantly outperform all comparison methods on most transfer tasks, where CDAN+E is a top-performing variant and CDAN performs slightly worse. It is desirable that CDAN promotes the classification accuracies substantially on hard transfer tasks, e.g. A \\rightarrow W and A \\rightarrow D, where the source and target domains are substantially different . Note that, CDAN+E even outperforms generative pixel-level domain adaptation method GTA, which has a very complex design in both architecture and objectives.", "= 1+e^{-H(\\mathbf{g). The entropy conditioning variant of CDAN (CDAN+E) for improved transferability is formulated as \\end{equation The domain discriminator empowers the entropy minimization principle and encourages certain predictions, enabling CDAN+E to further perform semi-supervised learning on unlabeled target data. \\vspace{-5pt Generalization Error Analysis \\vspace{-5pt We give an analysis of the CDAN method taking similar formalism of the domain adaptation theory .", "The results on the ImageCLEF-DA dataset are reported in Table . The CDAN models outperform the comparison methods on most transfer tasks, but with smaller rooms of improvement. This is reasonable since the three domains in ImageCLEF-DA are of equal size and balanced in each category, and are visually more similar than Office-31, making the former dataset easier for domain adaptation.", "We compare Conditional Domain Adversarial Network (CDAN) with state-of-art domain adaptation methods: Deep Adaptation Network (DAN) , Residual Transfer Network (RTN) , Domain Adversarial Neural Network (DANN) , Adversarial Discriminative Domain Adaptation (ADDA) , Joint Adaptation Network (JAN) , Unsupervised Image-to-Image Translation (UNIT) , Generate to Adapt (GTA) , Cycle-Consistent Adversarial Domain Adaptation (CyCADA) . We follow the standard protocols for unsupervised domain adaptation . We use all labeled source examples and all unlabeled target examples and compare the average classification accuracy based on three random experiments.", "The results on Office-Home are reported in Table . The CDAN models substantially outperform the comparison methods on most transfer tasks, and with larger rooms of improvement. An interpretation is that the four domains in Office-Home are with more categories, are visually more dissimilar with each other, and are difficult in each domain with much lower in-domain classification accuracy .", "Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model.", "\\vspace{-5pt Experiments \\vspace{-5pt We evaluate the proposed conditional domain adversarial networks with many state-of-the-art transfer learning and deep learning methods. Codes will be available at \\url{http://github.com/thuml/CDAN. \\vspace{-5pt Setup \\vspace{-5pt Office-31 is the most widely used dataset for visual domain adaptation, with 4,652 images and 31 categories collected from three distinct domains: Amazon (A), Webcam (W) and DSLR (D)."], "referred_text_chunks": ["\\vspace{-5pt Analysis \\vspace{-5pt Ablation Study\\quad We examine the sampling strategies of the random matrices in Equation~\\eqref{eqn:R. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. Table~ shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants."]}, "4": {"question": "Which model performs the best in terms of test error?", "referred_figures_indices": [1], "response": "{'Image': 0, 'Text': 1, 'Rationale': 'Image 0 provides detailed accuracy data for different CDAN variants, showing test performance. Text 1 discusses the performance of CDAN models, highlighting CDAN+E as a top performer.', 'Answer': 'CDAN+E (w/o random sampling) performs the best in terms of test error.'}", "all_figures_names": ["1705.10667v4-Table5-1.png", "1705.10667v4-Figure2-1.png", "1705.10667v4-Figure3-1.png", "1705.10667v4-Table4-1.png", "1705.10667v4-Table3-1.png", "1705.10667v4-Table2-1.png", "1705.10667v4-Table1-1.png", "1705.10667v4-Figure1-1.png"], "referred_figures_names": ["1705.10667v4-Figure2-1.png"], "answer": "CDAN (M)", "figure_type": "plot", "content_type": "figure", "text_chunks": ["\\vspace{-5pt Analysis \\vspace{-5pt Ablation Study\\quad We examine the sampling strategies of the random matrices in Equation~\\eqref{eqn:R. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. Table~ shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants.", "The CDAN models significantly outperform all comparison methods on most transfer tasks, where CDAN+E is a top-performing variant and CDAN performs slightly worse. It is desirable that CDAN promotes the classification accuracies substantially on hard transfer tasks, e.g. A \\rightarrow W and A \\rightarrow D, where the source and target domains are substantially different . Note that, CDAN+E even outperforms generative pixel-level domain adaptation method GTA, which has a very complex design in both architecture and objectives.", "We observe that {\\mathrm{dist_{\\cal A on CDAN features is smaller than {\\mathrm{dist_{\\cal A on both ResNet and DANN features, implying that CDAN features can reduce the domain gap more effectively. As domains W and D are similar, {\\mathrm{dist_{\\cal A of task W \\rightarrow D is smaller than that of A \\rightarrow W, implying higher accuracies. Convergence\\quad We testify the convergence of ResNet, DANN, and CDANs, with the test errors on task A \\rightarrow W shown in Figure~. CDAN enjoys faster convergence than DANN, while CDAN (M) converges faster than CDAN (RM).", "Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model.", "We conduct importance-weighted cross-validation (IWCV) to select hyper-parameters for all methods. As CDAN performs stably under different parameters, we fix \\lambda = 1 for all experiments. For MMD-based methods (TCA, DAN, RTN, and JAN), we use Gaussian kernel with bandwidth set to median pairwise distances on training data .", "The concatenation strategy is not successful, as it cannot capture the cross-covariance between features and classes, which are crucial to domain adaptation . Figure shows that the entropy weight e^{-H(\\mathbf{g) corresponds well with the prediction correctness: entropy weight \\approx 1 if the prediction is correct, and much smaller than 1 when prediction is incorrect (uncertain). This reveals the power of the entropy conditioning to guarantee example transferability.", "Table~\\sim shows that CDAN+E outperforms CDAN, proving that entropy conditioning can prioritize easy-to-transfer examples and encourage certain predictions. Conditioning Strategies\\quad Besides multilinear conditioning, we investigate DANN-[f,g] with the domain discriminator imposed on the concatenation of {\\bf f and {\\bf g, DANN-f and DANN-g with the domain discriminator plugged in feature layer {\\bf f and classifier layer {\\bf g. Figure~ shows accuracies on A \\rightarrow W and A \\rightarrow D based on ResNet-50.", "We first consider the source and target domains over the fixed representation space \\mathbf{f = F(\\mathbf{x), and a family of source classifiers G in hypothesis space \\mathcal{H . Denote by {\\epsilon _P\\left( G \\right) = {\\mathbb{E_{({\\mathbf{f,{\\mathbf{y)\\sim P\\left[{G\\left({\\mathbf{f \\right) \\ne{\\mathbf{y\\right] the risk of a hypothesis G\\in \\mathcal{H w.r.t. distribution P, and {\\epsilon _ P\\left({G_1,G_2 \\right) = {\\mathbb{E_{({\\mathbf{f,{\\mathbf{y)\\sim P\\left[{G_1\\left({\\mathbf{f \\right) \\ne G_2\\left({\\mathbf{f \\right) \\right] the disagreement between hypotheses G_1, G_2 \\in \\mathcal{H. Let {G^ * = \\mathop{\\arg \\min \\nolimits_G {\\epsilon _P\\left( G \\right) + {\\epsilon _Q\\left( G \\right) be the ideal hypothesis that explicitly embodies the notion of adaptability."], "referred_text_chunks": ["\\vspace{-5pt Analysis \\vspace{-5pt Ablation Study\\quad We examine the sampling strategies of the random matrices in Equation~\\eqref{eqn:R. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. Table~ shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants."]}}