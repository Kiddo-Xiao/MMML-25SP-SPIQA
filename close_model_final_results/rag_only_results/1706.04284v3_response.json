{"0": {"question": "What is the difference between the conventional semantic segmentation pipeline and the proposed framework for joint image denoising and semantic segmentation?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Text': 2, 'Rationale': 'Image 0 effectively illustrates the comparison between the conventional pipeline and the proposed framework. Text 2 explains the joint minimization of image reconstruction loss and high-level vision loss, enhancing the output quality.', 'Answer': 'The conventional semantic segmentation pipeline processes images directly and separately from denoising, while the proposed framework integrates denoising with semantic segmentation via a joint loss, improving visual quality by leveraging high-level semantic information.'}", "all_figures_names": ["1706.04284v3-Figure1-1.png", "1706.04284v3-Figure5-1.png", "1706.04284v3-Figure2-1.png", "1706.04284v3-Figure3-1.png", "1706.04284v3-Table1-1.png", "1706.04284v3-Figure4-1.png", "1706.04284v3-Table3-1.png", "1706.04284v3-Table2-1.png"], "referred_figures_names": ["1706.04284v3-Figure1-1.png"], "answer": "The conventional semantic segmentation pipeline performs semantic segmentation directly on the noisy input image, while the proposed framework first denoises the image before performing semantic segmentation.", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["Therefore, we emphasize that the goal of our following experiments is not to pursue the highest PSNR, but to demonstrate the qualitative difference between the model trained with our proposed joint loss and the model trained with MSE on the image domain. Fig.~ displays two image denoising examples from Kodak dataset. A visual comparison is illustrated for a zoom-in region: (II) and (III) are the denoising results using CBM3D~, and DnCNN~, respectively; (IV) is the proposed denoiser trained separately without the guidance of high-level vision information; (V) is the denoising result using the proposed denoising network trained jointly with a segmentation network.", "We can find that the results using CBM3D, DnCNN and our separately trained denoiser generate oversmoothing regions, while the jointly trained denoising network is able to reconstruct the denoised image which preserves more details and textures with better visual quality. \\subsubsection{Generality of the Denoiser for High-Level Vision Tasks \\vspace{-4mm \\caption{Two semantic segmentation examples from Pascal VOC 2012 validation set. From left to right: (a) the ground truth image, the denoised image using (b) the separately trained denoiser, (c) the denoiser trained with the reconstruction and segmentation joint loss, and (d) the denoiser trained with the classification network and evaluated for semantic segmentation.", "To this end, we propose a cascade architecture connecting image denoising to a high-level vision network. We jointly minimize the image reconstruction loss and the high-level vision loss. With the guidance of image semantic information, the denoising network is able to further improve visual quality and generate more visually appealing outputs, which demonstrates the importance of semantic information for image denoising.", "In addition, we use the denoising network jointly trained with the classification network, to connect the segmentation network. Its mean IoU is much better than Separate+VGG in Table~. These two experiments show the high-level semantics of different tasks are universal in terms of low-level vision tasks, which is in line with intuition, and the denoiser trained in our method has the generality for various high-level tasks. Fig.~ displays two visual examples of how the data-driven denoising can enhance the semantic segmentation performance.", "It is observed that the segmentation result of the denoised image from the separately trained denoising network has lower accuracy compared to those using the joint loss and the joint loss (cross-task), while the zoom-in region of its denoised image for inaccurate segmentation in Fig.~~(b) contains oversmoothing artifacts. On the contrary, both the Joint Training and Joint Training (Cross-Task) approaches achieve finer segmentation result and produce more visually pleasing denoised outputs simultaneously. Conclusion Exploring the connection between low-level vision and high-level semantic tasks is of great practical value in various applications of computer vision.", "Introduction A common approach in computer vision is to separate low-level vision problems, such as image restoration and enhancement, from high-level vision problems, and solve them independently. In this paper, we make their connection by showing the mutual influence between the two, i.e., visual perception and semantics, and propose a new perspective of solving both the low-level and high-level computer vision problems in a single unified framework, as shown in Fig.~(a). Image denoising, as one representative of low-level vision problems, is dedicated to recovering the underlying image signal from its noisy measurement.", "We propose a convolutional neural network for image denoising, which takes a noisy image as input and outputs the reconstructed image. This network conducts feature contraction and expansion through downsampling and upsampling operations, respectively. Each pair of downsampling and upsampling operations brings the feature representation into a new spatial scale, so that the whole network can process information on different scales.", "Classical image denoising methods take advantage of local or non-local structures presented in the image . More recently, a number of deep learning models have been developed for image denoising which demonstrated superior performance~. Inspired by U-Net~, we propose a convolutional neural network for image denoising, which achieves the state-of-the-art performance. While popular image denoising algorithms reconstruct images by minimizing the mean square error (MSE), important image details are usually lost which leads to image quality degradation, e.g., over-smoothing artifacts in some texture-rich regions are commonly observed in the denoised output from conventional methods, as shown in Fig.~(b)."], "referred_text_chunks": ["Therefore, we emphasize that the goal of our following experiments is not to pursue the highest PSNR, but to demonstrate the qualitative difference between the model trained with our proposed joint loss and the model trained with MSE on the image domain. Fig.~ displays two image denoising examples from Kodak dataset. A visual comparison is illustrated for a zoom-in region: (II) and (III) are the denoising results using CBM3D~, and DnCNN~, respectively; (IV) is the proposed denoiser trained separately without the guidance of high-level vision information; (V) is the denoising result using the proposed denoising network trained jointly with a segmentation network."]}, "1": {"question": " Which denoiser performs the best on the sheep image, and how can you tell?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Text': 0, 'Rationale': \"Image 1 directly shows the visual results of different denoisers, including their effect on a sheep image relevant to the question. It compares semantic segmentation results, which directly relate to performance evaluation. Text 0 discusses the visual quality and detail preservation of jointly trained denoisers, which connects directly to the visual observations in Image 1.\", 'Answer': 'The denoiser trained with the reconstruction and segmentation joint loss performs the best on the sheep image, as it preserves more details and achieves a better segmentation result, unlike the separately trained denoiser that results in inaccurate segmentation.'}", "all_figures_names": ["1706.04284v3-Figure1-1.png", "1706.04284v3-Figure5-1.png", "1706.04284v3-Figure2-1.png", "1706.04284v3-Figure3-1.png", "1706.04284v3-Table1-1.png", "1706.04284v3-Figure4-1.png", "1706.04284v3-Table3-1.png", "1706.04284v3-Table2-1.png"], "referred_figures_names": ["1706.04284v3-Figure5-1.png"], "answer": " The denoiser trained with the classification network and evaluated for semantic segmentation performs the best on the sheep image. This is because the segmentation label map for this denoiser is the most accurate, and it correctly identifies the sheep's body and legs. ", "figure_type": "** photograph(s)", "content_type": "figure", "text_chunks": ["We can find that the results using CBM3D, DnCNN and our separately trained denoiser generate oversmoothing regions, while the jointly trained denoising network is able to reconstruct the denoised image which preserves more details and textures with better visual quality. \\subsubsection{Generality of the Denoiser for High-Level Vision Tasks \\vspace{-4mm \\caption{Two semantic segmentation examples from Pascal VOC 2012 validation set. From left to right: (a) the ground truth image, the denoised image using (b) the separately trained denoiser, (c) the denoiser trained with the reconstruction and segmentation joint loss, and (d) the denoiser trained with the classification network and evaluated for semantic segmentation.", "We now investigate how the image denoising can enhance the high-level vision applications, including image classification and semantic segmentation, over the ILSVRC2012 and Pascal VOC 2012 datasets, respectively. The noisy images (\\sigma = 15, 30, 45, 60) are denoised and then fed into the VGG-based networks for high-level vision tasks. To evaluate how different denoising schemes contribute to the performance of high-level vision tasks, we experiment with the following cases: \\vspace{-1mm \\vspace{-1mm Note that the weights in the high-level vision network are initialized from a well-trained network under the noiseless setting and not updated during training in our experiments.", "Therefore, we emphasize that the goal of our following experiments is not to pursue the highest PSNR, but to demonstrate the qualitative difference between the model trained with our proposed joint loss and the model trained with MSE on the image domain. Fig.~ displays two image denoising examples from Kodak dataset. A visual comparison is illustrated for a zoom-in region: (II) and (III) are the denoising results using CBM3D~, and DnCNN~, respectively; (IV) is the proposed denoiser trained separately without the guidance of high-level vision information; (V) is the denoising result using the proposed denoising network trained jointly with a segmentation network.", "\\sigma = 25, 35 and 50. We evaluate their denoising performance over the widely used Kodak dataset, which consists of 24 color images. Table~ shows the peak signal-to-noise ratio (PSNR) results for CBM3D , TNRD~, MCWNNM~, DnCNN~, and our proposed method.", "Classical image denoising methods take advantage of local or non-local structures presented in the image . More recently, a number of deep learning models have been developed for image denoising which demonstrated superior performance~. Inspired by U-Net~, we propose a convolutional neural network for image denoising, which achieves the state-of-the-art performance. While popular image denoising algorithms reconstruct images by minimizing the mean square error (MSE), important image details are usually lost which leads to image quality degradation, e.g., over-smoothing artifacts in some texture-rich regions are commonly observed in the denoised output from conventional methods, as shown in Fig.~(b).", "It achieves the highest PSNR in almost every image of Kodak dataset. When Image Denoising Meets High-Level Vision Tasks We choose two high-level vision tasks as representatives in our study: image classification and semantic segmentation, which have been dominated by deep network based models. We utilize two popular VGG-based deep networks in our system for each task, respectively.", "Both of them achieve similar denoisng performance in practice, so we use the second scheme in the rest experiments for computation efficiency. Upsampling operations are implemented by deconvolution with 4 \\times 4 kernels, which aim to expand the feature map to the same spatial size as the previous scale. Since all the operations in our proposed denoising network are spatially invariant, it has the merit of handling input images of arbitrary size.", "Table~ and Table~ list the performance of high-level vision tasks, i.e., top-1 and top5 accuracy for classification and mean intersection-over-union (IoU) without conditional random field (CRF) postprocessing for semantic segmentation. We notice that the baseline VGG approach obtains much lower accuracy than all the other cases, which shows the necessity of image denoising as a preprocessing step for high-level vision tasks on noisy data. When we only apply denoising without considering high-level semantics (e.g., in CBM3D+VGG and Separate+VGG), it also fails to achieve high accuracy due to the artifacts introduced by the denoisers."], "referred_text_chunks": ["We can find that the results using CBM3D, DnCNN and our separately trained denoiser generate oversmoothing regions, while the jointly trained denoising network is able to reconstruct the denoised image which preserves more details and textures with better visual quality. \\subsubsection{Generality of the Denoiser for High-Level Vision Tasks \\vspace{-4mm \\caption{Two semantic segmentation examples from Pascal VOC 2012 validation set. From left to right: (a) the ground truth image, the denoised image using (b) the separately trained denoiser, (c) the denoiser trained with the reconstruction and segmentation joint loss, and (d) the denoiser trained with the classification network and evaluated for semantic segmentation."]}, "2": {"question": "What is the purpose of the skip connections in the proposed denoising network?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Text': 0, 'Rationale': 'Image 2 directly illustrates the architecture of the denoising network, including the skip connections, making it the most relevant visual representation. Text 0 explains the purpose of skip connections in enhancing detail recovery by learning the residual.', 'Answer': 'The purpose of the skip connections in the proposed denoising network is to learn the residual between the input and the target output and recover as many details as possible by summing the output of these operations with the input image, generating the reconstructed image.'}", "all_figures_names": ["1706.04284v3-Figure1-1.png", "1706.04284v3-Figure5-1.png", "1706.04284v3-Figure2-1.png", "1706.04284v3-Figure3-1.png", "1706.04284v3-Table1-1.png", "1706.04284v3-Figure4-1.png", "1706.04284v3-Table3-1.png", "1706.04284v3-Table2-1.png"], "referred_figures_names": ["1706.04284v3-Figure2-1.png"], "answer": "The skip connections are used to combine the features from the encoding and decoding modules at each scale. This helps to preserve the spatial information that is lost during the downsampling and upsampling operations.", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["Considering the tradeoff between computation cost and restoration accuracy, we choose three scales for the denoising network in our experiments, while this framework can be easily extended for more scales. These operations together are designed to learn the residual between the input and the target output and recover as many details as possible, so we use a long-distance skip connection to sum the output of these operations and the input image, in order to generate the reconstructed image. The overview is in Fig.", "To this end, we propose a cascade architecture connecting image denoising to a high-level vision network. We jointly minimize the image reconstruction loss and the high-level vision loss. With the guidance of image semantic information, the denoising network is able to further improve visual quality and generate more visually appealing outputs, which demonstrates the importance of semantic information for image denoising.", "When Image Denoising Meets High-Level Vision Tasks We propose a robust deep architecture processing a noisy image input, via cascading a network for denoising and the other for high-level vision task, aiming to simultaneously: \\vspace{-1mm \\vspace{-1mm The overview of the proposed cascaded network is displayed in Fig. . Specifically, given a noisy input image, the denosing network is first applied, and the denoised result is then fed into the following network for high-level vision task, which generates the high-level vision task output. Training Strategy:", "Therefore, we emphasize that the goal of our following experiments is not to pursue the highest PSNR, but to demonstrate the qualitative difference between the model trained with our proposed joint loss and the model trained with MSE on the image domain. Fig.~ displays two image denoising examples from Kodak dataset. A visual comparison is illustrated for a zoom-in region: (II) and (III) are the denoising results using CBM3D~, and DnCNN~, respectively; (IV) is the proposed denoiser trained separately without the guidance of high-level vision information; (V) is the denoising result using the proposed denoising network trained jointly with a segmentation network.", "Under the proposed architecture, we systematically investigate the mutual influence between the low-level and high-level vision networks. We show that the cascaded network trained with the joint loss not only boosts the denoising network performance via image semantic guidance, but also substantially improves the accuracy of high-level vision tasks. Moreover, our proposed training strategy makes the trained denoising network robust enough to different high-level vision tasks.", "Both of them achieve similar denoisng performance in practice, so we use the second scheme in the rest experiments for computation efficiency. Upsampling operations are implemented by deconvolution with 4 \\times 4 kernels, which aim to expand the feature map to the same spatial size as the previous scale. Since all the operations in our proposed denoising network are spatially invariant, it has the merit of handling input images of arbitrary size.", "F_D, F_H and F denote the denoising network, the network of high-level vision task and the whole cascaded network, respectively. L_D, L_H represent the losses of the denoising network and the high-level vision task network, respectively, while L is the joint loss, as illustrated in Fig.~. \\lambda is the weight for balancing the losses L_D and L_H. Experiments Image Denoising Our proposed denoising network takes RGB images as input, % and outputs the reconstructed images directly. We add independent and identically distributed Gaussian noise with zero mean to the original image as the noisy input image during training.", "We propose a convolutional neural network for image denoising, which takes a noisy image as input and outputs the reconstructed image. This network conducts feature contraction and expansion through downsampling and upsampling operations, respectively. Each pair of downsampling and upsampling operations brings the feature representation into a new spatial scale, so that the whole network can process information on different scales."], "referred_text_chunks": ["Considering the tradeoff between computation cost and restoration accuracy, we choose three scales for the denoising network in our experiments, while this framework can be easily extended for more scales. These operations together are designed to learn the residual between the input and the target output and recover as many details as possible, so we use a long-distance skip connection to sum the output of these operations and the input image, in order to generate the reconstructed image. The overview is in Fig."]}, "3": {"question": "Which denoising method performs the best on average across all noise levels tested on the Kodak dataset?", "referred_figures_indices": [4], "response": "{'Image': 4, 'Text': 5, 'Rationale': 'Image 4 contains the PSNR table showing average results across methods on the Kodak dataset, directly relevant for comparison purposes. Text 5 emphasizes that the proposed method performs best quantitatively across noise levels, providing clear information on average performance.', 'Answer': 'The proposed method performs the best on average across all noise levels tested on the Kodak dataset.'}", "all_figures_names": ["1706.04284v3-Figure1-1.png", "1706.04284v3-Figure5-1.png", "1706.04284v3-Figure2-1.png", "1706.04284v3-Figure3-1.png", "1706.04284v3-Table1-1.png", "1706.04284v3-Figure4-1.png", "1706.04284v3-Table3-1.png", "1706.04284v3-Table2-1.png"], "referred_figures_names": ["1706.04284v3-Table1-1.png"], "answer": "The proposed method performs the best on average across all noise levels tested on the Kodak dataset.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["\\sigma = 25, 35 and 50. We evaluate their denoising performance over the widely used Kodak dataset, which consists of 24 color images. Table~ shows the peak signal-to-noise ratio (PSNR) results for CBM3D , TNRD~, MCWNNM~, DnCNN~, and our proposed method.", "Therefore, we emphasize that the goal of our following experiments is not to pursue the highest PSNR, but to demonstrate the qualitative difference between the model trained with our proposed joint loss and the model trained with MSE on the image domain. Fig.~ displays two image denoising examples from Kodak dataset. A visual comparison is illustrated for a zoom-in region: (II) and (III) are the denoising results using CBM3D~, and DnCNN~, respectively; (IV) is the proposed denoiser trained separately without the guidance of high-level vision information; (V) is the denoising result using the proposed denoising network trained jointly with a segmentation network.", "It achieves the highest PSNR in almost every image of Kodak dataset. When Image Denoising Meets High-Level Vision Tasks We choose two high-level vision tasks as representatives in our study: image classification and semantic segmentation, which have been dominated by deep network based models. We utilize two popular VGG-based deep networks in our system for each task, respectively.", "The training is terminated after 1,500,000 iterations. We train a different denoising network for each noise level in our experiment. We compare our denoisnig network with several state-of-the-art color image denoising approaches on various noise levels:", "We now investigate how the image denoising can enhance the high-level vision applications, including image classification and semantic segmentation, over the ILSVRC2012 and Pascal VOC 2012 datasets, respectively. The noisy images (\\sigma = 15, 30, 45, 60) are denoised and then fed into the VGG-based networks for high-level vision tasks. To evaluate how different denoising schemes contribute to the performance of high-level vision tasks, we experiment with the following cases: \\vspace{-1mm \\vspace{-1mm Note that the weights in the high-level vision network are initialized from a well-trained network under the noiseless setting and not updated during training in our experiments.", "We do not list other methods whose average performance is wore than DnCNN. The implementation codes used are from the authors\u2019 websites and the default parameter settings are adopted in our experiments. It is clear that our proposed method outperforms all the competing approaches quantitatively across different noise levels.", "\\lambda is empirically set as 0.5. \\subsubsection{High-Level Vision Information Guided Image Denoising The typical metric used for image denoising is PSNR, which has been shown to sometimes correlate poorly with human assessment of visual quality~. Since PSNR depends on the reconstruction error between the denoised output and the reference image, a model trained by minimizing MSE on the image domain should always outperform a model trained by minimizing our proposed joint loss (with the guidance of high-level vision semantics) in the metric of PSNR.", "We can find that the results using CBM3D, DnCNN and our separately trained denoiser generate oversmoothing regions, while the jointly trained denoising network is able to reconstruct the denoised image which preserves more details and textures with better visual quality. \\subsubsection{Generality of the Denoiser for High-Level Vision Tasks \\vspace{-4mm \\caption{Two semantic segmentation examples from Pascal VOC 2012 validation set. From left to right: (a) the ground truth image, the denoised image using (b) the separately trained denoiser, (c) the denoiser trained with the reconstruction and segmentation joint loss, and (d) the denoiser trained with the classification network and evaluated for semantic segmentation."], "referred_text_chunks": ["\\sigma = 25, 35 and 50. We evaluate their denoising performance over the widely used Kodak dataset, which consists of 24 color images. Table~ shows the peak signal-to-noise ratio (PSNR) results for CBM3D , TNRD~, MCWNNM~, DnCNN~, and our proposed method."]}}