{"0": {"question": "What is the purpose of the residual connection in the decoding module?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Text': 0, 'Rationale': 'Image 1 directly illustrates the decoding module and shows the implementation of residual connections. Text chunk 0 explains the use of residual connections within the U-Net structure of the decoding module.', 'Answer': 'The residual connection in the decoding module helps in maintaining information flow across layers, preventing the vanishing gradient problem and improving training efficiency.'}", "all_figures_names": ["1802.07351v2-Table3-1.png", "1802.07351v2-Figure7-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Table1-1.png", "1802.07351v2-Table4-1.png", "1802.07351v2-Figure5-1.png", "1802.07351v2-Figure8-1.png"], "referred_figures_names": ["1802.07351v2-Figure7-1.png"], "answer": "The residual connection allows the output of a layer to be added to the output of another layer, which helps to improve the flow of information through the network.", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["Decoding Module In the decoding module, we again use the U-Net structure with residual connections. The whole module structure is illustrated in Figure . Each stage has its own decoder.", "Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion.", "Therefore, the artifacts discussed in \\textsection can be avoided. (3) The decoding module only receives inputs from the relation module. Therefore, neural networks infer the optical flow solely from the relations between two images, rather than memorize the optical flow pattern of a single image as a short-cut.", "We remove the normalization in the relation modules. (5) Shared decoder. We let all stages share one decoder and set the hyparameters of the relation modules in second and third stage the same as the first stage.", "We replace the deformable cost volumes with warping and standard cost volumes (with dilation). (2) With shortcut. We additionally concatenate the relation module with the feature maps of the first image and feed them into the decoder.", "When the module does not receive an optical flow as one of the inputs (in the first stage), it is set to receive a zero-valued optical flow field. \\newpage Since the relation module captures multi-scale motion without reducing the resolution, the presence and precise location of small objects which move fast are retained. This allows Devon to have better chance in solving the ``small objects move fast\" problem.", "Each stage is a neural network with an identical Siamese architecture, which consists of an encoding module, a relation module and a decoding module. Each stage outputs the optical flow field of 1/4 resolution and then the flow from last stage is bilinearly upsampled to obtain the final prediction. The optical flow estimated from a previous stage is propagated to the current one through the deformable cost volume and residual connections.", "(6) Simple encoder. We replace the U-Net structure encoding module with a simpler one: 4 convolutional layers of 32 units receptive field size 3\\times3. The first two layers have stride 2 and the last two have stride 1."], "referred_text_chunks": ["Decoding Module In the decoding module, we again use the U-Net structure with residual connections. The whole module structure is illustrated in Figure . Each stage has its own decoder."]}, "1": {"question": "What are the differences between the results of the three methods, LiteFlowNet, PWC-Net, and Devon, compared to the ground truth?", "referred_figures_indices": [6], "response": "{'Image': 3, 'Text': 5, 'Rationale': 'Image 3 directly compares the results of LiteFlowNet, PWC-Net, and Devon with ground truth, highlighting differences in estimation. Text 5 discusses Devon\\'s performance in comparison to these methods, providing context on why Devon performs differently on KITTI and Sintel datasets.', 'Answer': 'Devon is more accurate in estimating small fast-moving objects compared to LiteFlowNet and PWC-Net. However, it does not perform as well as multi-resolution based methods like PWC-Net on datasets with larger objects, such as KITTI.'}", "all_figures_names": ["1802.07351v2-Table4-1.png", "1802.07351v2-Table6-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Figure8-1.png", "1802.07351v2-Table2-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Figure9-1.png", "1802.07351v2-Figure5-1.png"], "referred_figures_names": ["1802.07351v2-Figure9-1.png"], "answer": "LiteFlowNet, PWC-Net, and Devon all produce results that are similar to the ground truth, but there are some subtle differences. For example, LiteFlowNet tends to overestimate the motion of the small object, while PWC-Net and Devon tend to underestimate it. Additionally, all three methods produce some artifacts around the edges of the moving object.", "figure_type": "photograph(s)", "content_type": "figure", "text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "PWC-Net and LiteFlowNet follow the same strategy except that they use strided convolutions instead of downsampling to reduce the resolution and use cost volumes as a more explicit representation of motion. As a result, a decoder in lower resolution has effectively a larger receptive size to cover large displacements. However, as pointed out in , the multi-resolution estimation of optical flow faces the ``small objects move fast\" problem as small objects disappear in lower resolution and cannot be recovered in higher resolution due to their large motion .", "Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "The short-cut issue has appeared when applying neural networks to learn monocular stereo . On the contrary, in FlowNetC, PWC-Net and LiteFlowNet, the decoding module also receives inputs from the encoding module of the first image. (4) The encoding module is shared in all stages.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "Training Our training procedure largely follows from . We first train our network on FlyingChairs. We use the l_2 loss function where F_{\\text{GT denotes the ground-truth optical flow and \\hat{F_t denotes the bilinear upsampled network output at stage t. For Devon with three stages, we choose \\gamma_1 = 0.2, \\gamma_2 = 0.3 and \\gamma_3 = 0.5.", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection ."], "referred_text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI."]}, "2": {"question": "What is the difference between a standard cost volume and a deformable cost volume?", "referred_figures_indices": [7], "response": "{'Image': 7, 'Text': 3, 'Rationale': 'Image 7 directly illustrates the difference between standard and deformable cost volumes using feature maps, and Text 3 explains the key concept of deforming the cost volume instead of the images.', 'Answer': 'A standard cost volume computes matching costs for a neighborhood at the same location, while a deformable cost volume offsets the neighborhood using a flow vector and dilation, allowing for better handling of large displacements.'}", "all_figures_names": ["1802.07351v2-Table5-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Table1-1.png", "1802.07351v2-Figure5-1.png", "1802.07351v2-Table2-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Table6-1.png", "1802.07351v2-Figure2-1.png"], "referred_figures_names": ["1802.07351v2-Figure2-1.png"], "answer": "A standard cost volume computes the matching costs for a neighborhood of the same location on the feature maps of the first and second images. A deformable cost volume computes the matching costs for a dilated neighborhood of the same location on the feature maps of the first and second images, offset by a flow vector.", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["Along with Table , the result suggests that the deformable cost volume is a suitable replacement of warping and standard cost volume in Devon and potentially other models. The deformation in deformable cost volume is different from the one in deformable convolutional networks . In deformable cost volume, the cost volume is offset by an external optical flow and dilation.", "The standard cost volume () with warping () gives That C(\\mathbf{p_1,\\mathbf{0) = C(\\mathbf{p_1,\\mathbf{p_2-\\mathbf{p_1) implies f_I(\\mathbf{p_1) has the same matching cost for f_J(\\mathbf{p_1) and f_J(\\mathbf{p_2), which does not hold in general and makes the matching ambiguous. On the other hand, with deformable cost volume () of dilation rate one, we have As C(\\mathbf{p_1,\\mathbf{0) \\neq C(\\mathbf{p_1,\\mathbf{p_2-\\mathbf{p_1) in general, the artifact is avoided.", "An interesting extension of our work is to combine multi-resolution approach and Devon to handle objects of diverse sizes and speed. From Table , we can see using deformable cost volume achieves shorter runtime than using warping and standard cost volumes. This is because the deformation and the cost volume construction are merged into one process in deformable cost volume and therefore reduces the runtime.", "The key idea is: instead of deforming images or their feature maps, we deform the cost volume and leave the images and the feature maps unchanged. The proposed deformable cost volume is defined as where r is the dilation rate and F(\\cdot) is an external flow field. The dilation rate r is introduced to enlarge the size of the neighborhood to handle large displacements without reducing the resolution.", "Although neural networks as universal approximators might be able to learn the self-corrected correspondences if trained with ground-truth optical flow, one should be aware of the issue which might cause problems in designing non-learning-based methods or more interpretable neural network models. Deformable Cost Volume Let I denote the first image, J denote the second image and f_I: \\mathbb{R^2 \\rightarrow \\mathbb{R^d and f_J: \\mathbb{R^2 \\rightarrow \\mathbb{R^d denote their feature maps of dimensionality d, respectively. The standard cost volume is defined as for image location \\mathbf{p \\in \\mathbb{R^2, neighbor \\mathbf{v", "This is inspired by the dilated convolution which enlarges its receptive field in a similar way. F(\\cdot) can be obtained from the optical flow estimated from a previous stage or an external algorithm. If F(\\mathbf{p)=0 for all \\mathbf{p and r=1, then the deformable cost volume is reduced to the standard cost volume.", "The use of dilation in standard cost volume has been proposed in and used in , though it has not been used in a multi-scale fashion in each stage as ours to handle the small objects moving fast problem. Conclusions In this paper, we proposed a new neural network module, Deformable Cost Volume, which allows the representation of multi-scale motion in a single high resolution and avoids the drawback of warping. Based on it, we designed the Deformable Volume Network, which is demonstrated to be effective in estimating optical flow, especially in situations where small objects move fast.", "(3) Without dilation. We replace the concatenated deformable cost volumes with one deformable cost volume of neighorhood size 13\\times 13 and dilation rate one. (4) Without norm."], "referred_text_chunks": ["Along with Table , the result suggests that the deformable cost volume is a suitable replacement of warping and standard cost volume in Devon and potentially other models. The deformation in deformable cost volume is different from the one in deformable convolutional networks . In deformable cost volume, the cost volume is offset by an external optical flow and dilation."]}, "3": {"question": "Based on the ablation study, which modification to the Devon model architecture had the most significant negative impact on performance for the KITTI 2015 dataset?", "referred_figures_indices": [5], "response": "{'Image': 5, 'Text': 2, 'Rationale': 'Image 5 shows the specific end-point error for various modifications in the ablation study, particularly on the KITTI 2015 dataset. Text 2 discusses Devon\\'s challenges with KITTI, hinting at the impact of different architectures.', 'Answer': 'The modification \"Without norm\" had the most significant negative impact on performance for the KITTI 2015 dataset, with an increase in end-point error to 15.64.'}", "all_figures_names": ["1802.07351v2-Table2-1.png", "1802.07351v2-Table1-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Table5-1.png", "1802.07351v2-Figure7-1.png", "1802.07351v2-Table6-1.png"], "referred_figures_names": ["1802.07351v2-Table5-1.png"], "answer": "Removing the normalization in the relation modules had the most significant negative impact on performance for the KITTI 2015 dataset.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Ablation Analysis We perform an ablation analysis of Devon trained on FlyingChairs. There are six ablation cases: (1) With warping.", "Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "We also experimented with sharing decoder in all three stages. The result is reported in \\textsection . Experiments We evaluate Devon on two challenging benchmarks which contain large motions: Sintel and KITTI , as in .", "The training set is mixed with KITTI 2012 and KITTI 2015. Invalid pixels are excluded in computing the loss. All the experiments are conducted with PyTorch.", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection .", "Along with Table , the result suggests that the deformable cost volume is a suitable replacement of warping and standard cost volume in Devon and potentially other models. The deformation in deformable cost volume is different from the one in deformable convolutional networks . In deformable cost volume, the cost volume is offset by an external optical flow and dilation."], "referred_text_chunks": ["Ablation Analysis We perform an ablation analysis of Devon trained on FlyingChairs. There are six ablation cases: (1) With warping."]}, "4": {"question": "Which modification to the Devon model resulted in the fastest processing time for both forward and backward passes, and how much faster was it compared to the full model in terms of the backward pass? ", "referred_figures_indices": [1], "response": "{'Image': 1, 'Text': 3, 'Rationale': 'Image 1 provides specific runtime data for different model configurations, clearly showing performance differences. Text 3 mentions runtime improvements due to modifications in Devon, relevant for determining the fastest configuration.', 'Answer': 'The modification \"without dilation\" resulted in the fastest processing time, with a backward pass time of 147.74 ms, making it 29.43 ms faster than the full model.'}", "all_figures_names": ["1802.07351v2-Figure8-1.png", "1802.07351v2-Table6-1.png", "1802.07351v2-Figure5-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Figure10-1.png", "1802.07351v2-Table4-1.png", "1802.07351v2-Table5-1.png", "1802.07351v2-Figure1-1.png"], "referred_figures_names": ["1802.07351v2-Table6-1.png"], "answer": "The \"Without dilation\" configuration resulted in the fastest processing time for both forward and backward passes. It was approximately 29.43 ms faster than the full model in terms of the backward pass (147.74 ms vs. 177.17 ms).", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "An interesting extension of our work is to combine multi-resolution approach and Devon to handle objects of diverse sizes and speed. From Table , we can see using deformable cost volume achieves shorter runtime than using warping and standard cost volumes. This is because the deformation and the cost volume construction are merged into one process in deformable cost volume and therefore reduces the runtime.", "For (1)\\sim(5), the changes are applied to all stages in Devon. The results are listed in Table , from which we can see the architecture of Devon is robust to various changes. Runtime We report the runtime of Devon and its variants in Table .", "We also experimented with sharing decoder in all three stages. The result is reported in \\textsection . Experiments We evaluate Devon on two challenging benchmarks which contain large motions: Sintel and KITTI , as in .", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection ."], "referred_text_chunks": ["Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem."]}, "5": {"question": "What is the purpose of the residual connection in the encoding module?", "referred_figures_indices": [6], "response": "{'Image': 6, 'Text': 2, 'Rationale': \"Image 6 directly shows the encoding module with residual connections, illustrating their role in passing layer outputs. Text 2 describes the structure, including encoding, relation, and decoding modules, making it relevant to understanding residual connections' purpose in the network architecture.\", 'Answer': 'The residual connection in the encoding module facilitates the transfer of layer outputs, allowing deeper feature learning and preventing degradation of information during processing.'}", "all_figures_names": ["1802.07351v2-Figure9-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Figure5-1.png", "1802.07351v2-Table4-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Table1-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Figure2-1.png"], "referred_figures_names": ["1802.07351v2-Figure4-1.png"], "answer": "The residual connection adds the output of a layer to the output of another layer, which helps to prevent the vanishing gradient problem.", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["Decoding Module In the decoding module, we again use the U-Net structure with residual connections. The whole module structure is illustrated in Figure . Each stage has its own decoder.", "(6) Simple encoder. We replace the U-Net structure encoding module with a simpler one: 4 convolutional layers of 32 units receptive field size 3\\times3. The first two layers have stride 2 and the last two have stride 1.", "Each stage is a neural network with an identical Siamese architecture, which consists of an encoding module, a relation module and a decoding module. Each stage outputs the optical flow field of 1/4 resolution and then the flow from last stage is bilinearly upsampled to obtain the final prediction. The optical flow estimated from a previous stage is propagated to the current one through the deformable cost volume and residual connections.", "Therefore, the artifacts discussed in \\textsection can be avoided. (3) The decoding module only receives inputs from the relation module. Therefore, neural networks infer the optical flow solely from the relations between two images, rather than memorize the optical flow pattern of a single image as a short-cut.", "Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion.", "We remove the normalization in the relation modules. (5) Shared decoder. We let all stages share one decoder and set the hyparameters of the relation modules in second and third stage the same as the first stage.", "When the module does not receive an optical flow as one of the inputs (in the first stage), it is set to receive a zero-valued optical flow field. \\newpage Since the relation module captures multi-scale motion without reducing the resolution, the presence and precise location of small objects which move fast are retained. This allows Devon to have better chance in solving the ``small objects move fast\" problem.", "The output of this module has size (k_1^2+k_2 ^2+k_3 ^2+k_4^2+k_5^2)\\times m\\times n, where m is the height and n is the width of the feature maps."], "referred_text_chunks": ["Decoding Module In the decoding module, we again use the U-Net structure with residual connections. The whole module structure is illustrated in Figure . Each stage has its own decoder."]}, "6": {"question": "What is the role of the relation module (Rt) in the Deformable Volume Network (Devon)?", "referred_figures_indices": [2], "response": "{'Image': 5, 'Text': 4, 'Rationale': 'Image 5 illustrates the relation module by displaying its structure, showing how it processes deformable cost volumes with varying neighborhood sizes and dilation rates. Text 4 describes the relation module\u2019s function in capturing multi-scale motion, which aligns with the image\u2019s content.', 'Answer': 'The role of the relation module (Rt) in the Deformable Volume Network (Devon) is to capture multi-scale motion without reducing the resolution. This ensures that small and fast-moving objects are retained, thereby improving the estimation of optical flow for such challenging scenarios.'}", "all_figures_names": ["1802.07351v2-Figure2-1.png", "1802.07351v2-Figure9-1.png", "1802.07351v2-Figure3-1.png", "1802.07351v2-Figure8-1.png", "1802.07351v2-Table6-1.png", "1802.07351v2-Figure5-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Table3-1.png"], "referred_figures_names": ["1802.07351v2-Figure3-1.png"], "answer": "The relation module (Rt) is responsible for capturing the spatial relationships between the features extracted from the first and second images.", "figure_type": "** schematic", "content_type": "figure", "text_chunks": ["Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion.", "\\newpage Deformable Volume Network Our proposed model is the Deformable Volume Network (Devon), as illustrated in Figure . Devon has multiple stages.", "However, warping often creates distortions and artifacts. This issue will be discussed in details in \\textsection . In this paper, we introduce the Deformable Volume Network (Devon), which avoids the drawbacks of multi-resolution estimation and warping.", "Along with Table , the result suggests that the deformable cost volume is a suitable replacement of warping and standard cost volume in Devon and potentially other models. The deformation in deformable cost volume is different from the one in deformable convolutional networks . In deformable cost volume, the cost volume is offset by an external optical flow and dilation.", "When the module does not receive an optical flow as one of the inputs (in the first stage), it is set to receive a zero-valued optical flow field. \\newpage Since the relation module captures multi-scale motion without reducing the resolution, the presence and precise location of small objects which move fast are retained. This allows Devon to have better chance in solving the ``small objects move fast\" problem.", "We replace the deformable cost volumes with warping and standard cost volumes (with dilation). (2) With shortcut. We additionally concatenate the relation module with the feature maps of the first image and feed them into the decoder.", "The use of dilation in standard cost volume has been proposed in and used in , though it has not been used in a multi-scale fashion in each stage as ours to handle the small objects moving fast problem. Conclusions In this paper, we proposed a new neural network module, Deformable Cost Volume, which allows the representation of multi-scale motion in a single high resolution and avoids the drawback of warping. Based on it, we designed the Deformable Volume Network, which is demonstrated to be effective in estimating optical flow, especially in situations where small objects move fast.", "The key idea is: instead of deforming images or their feature maps, we deform the cost volume and leave the images and the feature maps unchanged. The proposed deformable cost volume is defined as where r is the dilation rate and F(\\cdot) is an external flow field. The dilation rate r is introduced to enlarge the size of the neighborhood to handle large displacements without reducing the resolution."], "referred_text_chunks": ["Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion."]}, "7": {"question": "Explain the rationale behind using five deformable cost volumes with different hyperparameter settings in Devon's relation module.", "referred_figures_indices": [7], "response": "{'Image': 5, 'Text': 0, 'Rationale': 'Image 5 visually demonstrates the concept of combining deformable cost volumes with different neighborhood sizes and dilation rates, which is central to understanding the rationale for Devon\u2019s relation module. Text 0 discusses the concatenation of deformable cost volumes with different hyperparameters, explaining their purpose in capturing multi-scale motion.', 'Answer': 'The use of five deformable cost volumes with different hyperparameter settings in Devon\\'s relation module enables capturing a range of multi-scale motions by creating dense correspondences near the center of an image and sparse correspondences peripherally.'}", "all_figures_names": ["1802.07351v2-Figure7-1.png", "1802.07351v2-Figure2-1.png", "1802.07351v2-Figure8-1.png", "1802.07351v2-Figure10-1.png", "1802.07351v2-Table5-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Figure9-1.png", "1802.07351v2-Table1-1.png"], "referred_figures_names": ["1802.07351v2-Table1-1.png"], "answer": "The five deformable cost volumes in Devon's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery. This is achieved by using different neighborhood sizes (k) and dilation rates (r) for each cost volume, as shown in Table 1. Smaller neighborhood sizes and dilation rates result in denser correspondences, focusing on finer details and small displacements, while larger values capture broader context and larger motions.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion.", "An interesting extension of our work is to combine multi-resolution approach and Devon to handle objects of diverse sizes and speed. From Table , we can see using deformable cost volume achieves shorter runtime than using warping and standard cost volumes. This is because the deformation and the cost volume construction are merged into one process in deformable cost volume and therefore reduces the runtime.", "We replace the deformable cost volumes with warping and standard cost volumes (with dilation). (2) With shortcut. We additionally concatenate the relation module with the feature maps of the first image and feed them into the decoder.", "Along with Table , the result suggests that the deformable cost volume is a suitable replacement of warping and standard cost volume in Devon and potentially other models. The deformation in deformable cost volume is different from the one in deformable convolutional networks . In deformable cost volume, the cost volume is offset by an external optical flow and dilation.", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "\\newpage Deformable Volume Network Our proposed model is the Deformable Volume Network (Devon), as illustrated in Figure . Devon has multiple stages.", "The key idea is: instead of deforming images or their feature maps, we deform the cost volume and leave the images and the feature maps unchanged. The proposed deformable cost volume is defined as where r is the dilation rate and F(\\cdot) is an external flow field. The dilation rate r is introduced to enlarge the size of the neighborhood to handle large displacements without reducing the resolution.", "The use of dilation in standard cost volume has been proposed in and used in , though it has not been used in a multi-scale fashion in each stage as ours to handle the small objects moving fast problem. Conclusions In this paper, we proposed a new neural network module, Deformable Cost Volume, which allows the representation of multi-scale motion in a single high resolution and avoids the drawback of warping. Based on it, we designed the Deformable Volume Network, which is demonstrated to be effective in estimating optical flow, especially in situations where small objects move fast."], "referred_text_chunks": ["Relation Module The relation module is illustrated in Figure . It concatenates the outputs of five deformable cost volumes, which have different neighborhood size k or dilation rate r, as shown in Table . Such combination enables dense correspondences nearby the center of an image location and sparse correspondences in peripheral to capture multi-scale motion."]}, "8": {"question": "Based on the table, which model achieved the best performance on the KITTI 2015 test set in terms of F1-all score, and how does its performance compare to Devon (ft) on the same dataset?", "referred_figures_indices": [4], "response": "{'Image': 4, 'Text': 1, 'Rationale': 'Image 4 provides performance results for KITTI, and Text 1 discusses KITTI dataset performance, which directly relates to the question.', 'Answer': 'LiteFlowNet (ft) achieved the best performance on the KITTI 2015 test set with an F1-all score of 9.38%. Devon (ft) achieved an F1-all score of 14.31%.'}", "all_figures_names": ["1802.07351v2-Table1-1.png", "1802.07351v2-Table3-1.png", "1802.07351v2-Figure10-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Table4-1.png", "1802.07351v2-Table2-1.png", "1802.07351v2-Figure2-1.png", "1802.07351v2-Figure6-1.png"], "referred_figures_names": ["1802.07351v2-Table4-1.png"], "answer": "PWC-Net (ft) achieved the best performance on the KITTI 2015 test set with an F1-all score of 9.16%. This is significantly better than Devon (ft), which achieved an F1-all score of 14.31% on the same dataset. ", "figure_type": "N/A", "content_type": "table", "text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "We also experimented with sharing decoder in all three stages. The result is reported in \\textsection . Experiments We evaluate Devon on two challenging benchmarks which contain large motions: Sintel and KITTI , as in .", "The training set is mixed with KITTI 2012 and KITTI 2015. Invalid pixels are excluded in computing the loss. All the experiments are conducted with PyTorch.", "Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "For (1)\\sim(5), the changes are applied to all stages in Devon. The results are listed in Table , from which we can see the architecture of Devon is robust to various changes. Runtime We report the runtime of Devon and its variants in Table .", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection ."], "referred_text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI."]}, "9": {"question": "Based on the table, which method performs best on the Sintel \"Final\" test set, and how does its performance compare to Devon (ft) on the same set? ", "referred_figures_indices": [4], "response": "{'Image': 4, 'Text': 1, 'Rationale': 'Image 4 directly provides the performance on the Sintel \"Final\" test set, showing the End-Point Error (EPE) for each method. Text chunk 1 discusses the methods\\' performance on datasets including Sintel, providing context about why some methods may perform better.', 'Answer': 'PWC-Net (ft) performs best on the Sintel \"Final\" test set with an EPE of 5.04. Devon (ft) has a higher EPE of 6.35 on the same set.'}", "all_figures_names": ["1802.07351v2-Figure7-1.png", "1802.07351v2-Table3-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Figure10-1.png", "1802.07351v2-Table2-1.png", "1802.07351v2-Figure4-1.png", "1802.07351v2-Figure9-1.png", "1802.07351v2-Table6-1.png"], "referred_figures_names": ["1802.07351v2-Table2-1.png"], "answer": "PWC-Net (ft) performs best on the Sintel \"Final\" test set with an error of 5.04. Devon (ft) has a higher error of 6.35 on the same set. ", "figure_type": "N/A", "content_type": "table", "text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "We also experimented with sharing decoder in all three stages. The result is reported in \\textsection . Experiments We evaluate Devon on two challenging benchmarks which contain large motions: Sintel and KITTI , as in .", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection .", "Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "An interesting extension of our work is to combine multi-resolution approach and Devon to handle objects of diverse sizes and speed. From Table , we can see using deformable cost volume achieves shorter runtime than using warping and standard cost volumes. This is because the deformation and the cost volume construction are merged into one process in deformable cost volume and therefore reduces the runtime.", "For (1)\\sim(5), the changes are applied to all stages in Devon. The results are listed in Table , from which we can see the architecture of Devon is robust to various changes. Runtime We report the runtime of Devon and its variants in Table ."], "referred_text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI."]}, "10": {"question": "Which of the three methods, LiteFlowNet, PWC-Net, or Devon, most accurately predicts the motion of the small object in the scene?", "referred_figures_indices": [7], "response": "{'Image': 0, 'Text': 6, 'Rationale': 'The image and caption from Image 0 explicitly show side-by-side comparisons of LiteFlowNet, PWC-Net, and Devon in handling small objects. Text 6 highlights Devon\\'s ability to retain and accurately predict fast-moving small objects.', 'Answer': 'Devon most accurately predicts the motion of the small object.'}", "all_figures_names": ["1802.07351v2-Figure9-1.png", "1802.07351v2-Figure3-1.png", "1802.07351v2-Table2-1.png", "1802.07351v2-Table5-1.png", "1802.07351v2-Figure1-1.png", "1802.07351v2-Figure6-1.png", "1802.07351v2-Figure7-1.png", "1802.07351v2-Figure8-1.png"], "referred_figures_names": ["1802.07351v2-Figure8-1.png"], "answer": "Devon.", "figure_type": "photograph(s)", "content_type": "figure", "text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI.", "PWC-Net and LiteFlowNet follow the same strategy except that they use strided convolutions instead of downsampling to reduce the resolution and use cost volumes as a more explicit representation of motion. As a result, a decoder in lower resolution has effectively a larger receptive size to cover large displacements. However, as pointed out in , the multi-resolution estimation of optical flow faces the ``small objects move fast\" problem as small objects disappear in lower resolution and cannot be recovered in higher resolution due to their large motion .", "We compare Devon with the previous neural network models: FlowNetS , FlowNetC , FlowNet2 , SpyNet , PWC-Net and LiteFlowNet . We use Devon with three stages. We use l_1 norm for the deformable cost volumes.", "The timing was recorded on a NVIDIA TITAN Xp graphics card for processing a pair of RGB images of size 1024\\times 448. Discussions While Devon achieves better results in handling small objects moving fast in the visualization results, it does not outperform multi-resolution based methods such as PWC-Net on Sintel final pass and KITTI. We conjecture that this is due to the fact that Sintel and KITTI mostly contain large objects (e.g. human bodies, cars and buildings), for which the multi-resolution approach might be more suitable.", "This is consistent with the fact that small displacements are more frequent in natural videos and resembles the structure of retina, as illustrated in Figure . \\newpage Since Devon is a multi-stage model which performs coarse-to-fine estimation of optical flow, we gradually decrease the dilation rates as the optical flow is expected to get finer in later stages. We also experimented with using the cost volumes of the same neighbor sizes and dilation rates for all three stages, the result of which is reported in \\textsection .", "Compared to previous neural network models~, Devon is different in the following major ways: (1) All stages in Devon output optical flow of the same resolution. While Devon handles multi-scale motion by the deformable cost volume, it does not use the multi-resolution representation of motion. Extensive downsampling leads to the loss of information and deficiency in handling the ``small objects move fast\" problem.", "When the module does not receive an optical flow as one of the inputs (in the first stage), it is set to receive a zero-valued optical flow field. \\newpage Since the relation module captures multi-scale motion without reducing the resolution, the presence and precise location of small objects which move fast are retained. This allows Devon to have better chance in solving the ``small objects move fast\" problem.", "The short-cut issue has appeared when applying neural networks to learn monocular stereo . On the contrary, in FlowNetC, PWC-Net and LiteFlowNet, the decoding module also receives inputs from the encoding module of the first image. (4) The encoding module is shared in all stages."], "referred_text_chunks": ["No additional fine-tuning is applied. From Figure , and , we can see Devon gives much more accurate estimation of the small objects. The results on Sintel and KITTI are listed in Table , and , from which we can see Devon outperforms PWC-Net and LiteFlowNet on Sintel clean pass, though not on Sintel final pass and KITTI."]}}