{"0": {"question": "What are the top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Text': 2, 'Rationale': 'Image 1 provides the specific top 5 section recommendations for Lausanne using the category-section counts method. Text 2 explains how these recommendations are generated for each category in Wikipedia and sorted by relevance.', 'Answer': 'According to the category-section counts method, the top 5 section recommendations for the Wikipedia article on Lausanne are History, Demographics, Economy, Education, and Politics.'}", "all_figures_names": ["1804.05995v2-Figure3-1.png", "1804.05995v2-Table1-1.png", "1804.05995v2-Figure5-1.png", "1804.05995v2-Figure4-1.png"], "referred_figures_names": ["1804.05995v2-Table1-1.png"], "answer": "The top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method are HISTORY, DEMOGRAPHICS, ECONOMY, EDUCATION, and POLITICS.", "figure_type": "table", "content_type": "table", "text_chunks": ["These methods differ in their source of signal (articles' topical content \\vs\\ Wikipedia's category network) as well as the technology used to model the recommendations (simple counting \\vs\\ collaborative filtering). We show that using Wikipedia's category network along with the proposed count-based approach provides the best recommendations, achieving precision@10 close to 80\\% when evaluated by human editors. \\xhdr{Contributions Our main contributions are as follows.", "As such, considering that a Wikipedia article contains 3.48 sections on average, the low precision and recall figures for this method are not unexpected. Evaluation: Category-based recommendation We now proceed to evaluating the category\\hyp based methods of \\Secref{sec:Category-based recommendation. As in the previous evaluation, we report the precision and recall for different values of k to show how the system behaves with different lengths of the recommendations list.% Using category--section counts Using the training set and the cleaned category network, we compute the probability P(S|C) of each section S in each category C, as described in \\Secref{sec:Using category--section counts.", "This step generates scores for more than 191M category--section pairs, from which we extract a mapping between each category in Wikipedia and a set of sections sorted by their relevance. Using an 80/15/5 train\\slash test\\slash validation split, we compute P(S|C) for all (S,C) based on the training set. To make recommendations for a given article A, rather than category C, we combine the recommendations from all of A's categories via a simple, unweighted sum of all the category\\hyp specific scores.", "Conclusion In the present paper, we have introduced the task of recommending sections for Wikipedia articles. Sections are the basic building blocks of articles and are crucial for structuring content in ways that make it easy to digest for humans. We have explored several methods, some that are based on features derived immediately from the input article that is to be enriched with sections (\\eg, content and pre-existing sections), and others that instead generate recommendations by leveraging Wikipedia's category system.", "On Wikipedia, most articles are members of one or more so-called categories; \\eg \\cpt{Stanford, California, belongs to the category \\cpt{University towns in the United States, among others. Our second broad paradigm, category\\hyp based recommendation (\\Secref{sec:Category-based recommendation), makes use of this rich source of structured information by sourcing section recommendations for the input article A from other articles belonging to the same categories as A. In particular, for a given article A and each category C that A belongs to", "The methods of \\Secref{sec:Category-based recommendation can easily be adapted to this use case, as they already rely on the categories the input article belongs to. \\xhdr{Improving section recommendations There are several ways in which section recommendations can be improved in practice: \\xhdr{Human-centered recommendation approach Wikipedia is a human\\hyp centered project, where the editors' judgment, deliberation, and curiosity play key roles in how the project is shaped and content is created. This human-centric approach creates an enormous opportunity for automatic recommendations in the sense that striving for perfect precision does not need to become the center-piece of the research, while high recall will allow us to not miss out on the most important recommendations that we would miss otherwise.", "= \\tilde M and such that U and V have a low rank of at most k. The rows of U (V) represent articles (sections) in k latent dimensions, so \\tilde M = UV^T captures the similarity of each article--section pair with respect to the latent dimensions and can thus be used to recommend new sections: \\eg, to suggest sections for article A=A_i, we sort the i-th row of \\tilde M in descending order and keep only the sections that are not already included in A. Category-based recommendation Wikipedia articles are organized in a vast, user\\hyp generated network of so-called categories. Ideally, links in this network would represent IS-A relationships and the network would be a taxonomical network, \\ie, a tree\\hyp structured, hierarchical grouping of articles into a coherent ontology by subject.", "This is especially important for the smaller categories, such as \\cpt{Nauruan scientists, which may contain patterns similar to other categories but do not have enough content to contribute to the generation of recommendations on their own. To understand the impact of category size on the maximum number of recommendations we can generate, consider \\Figref{fig:recommendations_length, which shows, on the y-axis, the fraction of categories large enough to generate at least x section recommendations when following the count\\hyp based approach of \\Secref{sec:Using category--section counts. As shown by the plot, \\eg, only 44\\% of the categories have enough information to produce a recommendation list of 20 sections or more."], "referred_text_chunks": ["These methods differ in their source of signal (articles' topical content \\vs\\ Wikipedia's category network) as well as the technology used to model the recommendations (simple counting \\vs\\ collaborative filtering). We show that using Wikipedia's category network along with the proposed count-based approach provides the best recommendations, achieving precision@10 close to 80\\% when evaluated by human editors. \\xhdr{Contributions Our main contributions are as follows."]}, "1": {"question": "What is the trend in precision and recall as the number of recommended sections k increases?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Text': 0, 'Rationale': 'Image 2 directly shows precision and recall as functions of the number of recommended sections k, illustrating how both metrics change with increasing k. Text 0 provides relevant details about how precision and recall are calculated and their behaviors when k varies.', 'Answer': 'As the number of recommended sections k increases, precision generally decreases while recall increases. This is because including more sections tends to add less relevant ones, reducing precision, but capturing more relevant sections increases recall.'}", "all_figures_names": ["1804.05995v2-Figure3-1.png", "1804.05995v2-Table1-1.png", "1804.05995v2-Figure5-1.png", "1804.05995v2-Figure4-1.png"], "referred_figures_names": ["1804.05995v2-Figure5-1.png"], "answer": "Precision generally decreases and recall generally increases as k increases.", "figure_type": "plot", "content_type": "figure", "text_chunks": ["For each article, we obtain its precision@k as the fraction of the top k recommended sections that are also contained in the testing article, and recall@k as the fraction of sections from the testing article that also appear among the top k recommendations. Taking the average of all article\\hyp specific precision@k (recall@k) values yields the global precision@k (recall@k), which we plot as a function of k, for k=1,\\dots,20 (as 20 seems a reasonable number of recommended sections to show to a user in an editing tool). While precision and recall trivially lie between 0 and 1, not the entire range is feasible: if the number of sections in the testing article is n, then recall@k is upper\\hyp bounded by k/n, which is less than 1 if k<n (\\ie, if we are allowed to make only few recommendations); and precision@k is upper\\hyp bounded by n/k, which is less than 1 if n<k (\\ie, if the testing article has only few sections).", "Each article in the evaluation sample was assigned the top 10 recommendations from our best performing methods: count-based and collaborative filtering with learning\\hyp to\\hyp rank merging (as described in \\Secref{sec:Combining recommendations from multiple categories). Computing recall would require the ground truth set of all relative sections for all test articles, which we do not have, so we focus only on the precision of our recommendations as perceived by the human evaluators. As evident from \\Figref{fig:human_eval, precision@k is substantially higher in the human, compared to the automatic, evaluation, from the point of view of both expert editors and crowd workers, with a precision@1 of 89\\% and 96\\%, respectively, and precision@10 of 81\\% and 72\\%.", "As such, considering that a Wikipedia article contains 3.48 sections on average, the low precision and recall figures for this method are not unexpected. Evaluation: Category-based recommendation We now proceed to evaluating the category\\hyp based methods of \\Secref{sec:Category-based recommendation. As in the previous evaluation, we report the precision and recall for different values of k to show how the system behaves with different lengths of the recommendations list.% Using category--section counts Using the training set and the cleaned category network, we compute the probability P(S|C) of each section S in each category C, as described in \\Secref{sec:Using category--section counts.", "\\Figref{fig:count_based shows that, with this method, precision for the unweighted sum reaches 57\\% for the first recommended section; at k=20 recommendations, recall reaches 80\\%. We consider this performance sufficient for deploying the method in practice. Generalizing via collaborative filtering To model the relevance of a section in a category with collaborative filtering (CF), it is important to choose an adequate ``rating'' representation.", "It seems that the aforementioned propagation of noise outweighs the advantage of generalization. Combining recommendations from multiple categories \\Figref{fig:count_based and \\Figref{fig:cf_based showcase also the precision--recall curves (in green) for the learning\\hyp to\\hyp rank (L2R) merging strategy described in \\Secref{sec:Combining recommendations from multiple categories. For both the count\\hyp based and the collaborative\\hyp filtering method, L2R provides a performance boost both in terms of precision (3\\%) and recall (4\\%).", "In particular, precision is always below 0.2\\%, and recall at k=20 recommended titles stays below 1.5\\%. Although these values are significantly better than a random baseline, where precision is below 0.002\\% for all k, and recall for k=20 is 0.008\\%, this method is not suitable to be used in a real-world scenario. It is well known that matrix factorization techniques perform poorly in the face of highly sparse data (a problem commonly referred to as ``cold start''~).", "The methods of \\Secref{sec:Category-based recommendation can easily be adapted to this use case, as they already rely on the categories the input article belongs to. \\xhdr{Improving section recommendations There are several ways in which section recommendations can be improved in practice: \\xhdr{Human-centered recommendation approach Wikipedia is a human\\hyp centered project, where the editors' judgment, deliberation, and curiosity play key roles in how the project is shaped and content is created. This human-centric approach creates an enormous opportunity for automatic recommendations in the sense that striving for perfect precision does not need to become the center-piece of the research, while high recall will allow us to not miss out on the most important recommendations that we would miss otherwise.", "Using topic modeling \\Figref{fig:baseline_topic summarizes the performance achieved by the topic\\hyp modeling approach (\\Secref{sec:Using topic modeling). Precision and recall are plotted in blue, the theoretical upper bounds (\\cf \\Secref{sec:Evaluation dataset) in red. The method achieves a maximum recall (at k=20) of 30\\%."], "referred_text_chunks": ["For each article, we obtain its precision@k as the fraction of the top k recommended sections that are also contained in the testing article, and recall@k as the fraction of sections from the testing article that also appear among the top k recommendations. Taking the average of all article\\hyp specific precision@k (recall@k) values yields the global precision@k (recall@k), which we plot as a function of k, for k=1,\\dots,20 (as 20 seems a reasonable number of recommended sections to show to a user in an editing tool). While precision and recall trivially lie between 0 and 1, not the entire range is feasible: if the number of sections in the testing article is n, then recall@k is upper\\hyp bounded by k/n, which is less than 1 if k<n (\\ie, if we are allowed to make only few recommendations); and precision@k is upper\\hyp bounded by n/k, which is less than 1 if n<k (\\ie, if the testing article has only few sections)."]}, "2": {"question": "What is the percentage of categories that can generate at least 10 recommendations using the section-count-based method?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Text': 0, 'Rationale': 'Image 3 directly displays the percentage of categories capable of generating at least a certain number of recommendations, showing the relevant information needed. Text 0 supports this by discussing the limitations of category sizes in generating recommendations, which ties directly to the content shown in the image.', 'Answer': 'About 62% of categories can generate at least 10 recommendations using the section-count-based method.'}", "all_figures_names": ["1804.05995v2-Figure3-1.png", "1804.05995v2-Table1-1.png", "1804.05995v2-Figure5-1.png", "1804.05995v2-Figure4-1.png"], "referred_figures_names": ["1804.05995v2-Figure4-1.png"], "answer": "Around 68%.", "figure_type": "plot", "content_type": "figure", "text_chunks": ["This is especially important for the smaller categories, such as \\cpt{Nauruan scientists, which may contain patterns similar to other categories but do not have enough content to contribute to the generation of recommendations on their own. To understand the impact of category size on the maximum number of recommendations we can generate, consider \\Figref{fig:recommendations_length, which shows, on the y-axis, the fraction of categories large enough to generate at least x section recommendations when following the count\\hyp based approach of \\Secref{sec:Using category--section counts. As shown by the plot, \\eg, only 44\\% of the categories have enough information to produce a recommendation list of 20 sections or more.", "As such, considering that a Wikipedia article contains 3.48 sections on average, the low precision and recall figures for this method are not unexpected. Evaluation: Category-based recommendation We now proceed to evaluating the category\\hyp based methods of \\Secref{sec:Category-based recommendation. As in the previous evaluation, we report the precision and recall for different values of k to show how the system behaves with different lengths of the recommendations list.% Using category--section counts Using the training set and the cleaned category network, we compute the probability P(S|C) of each section S in each category C, as described in \\Secref{sec:Using category--section counts.", "These methods differ in their source of signal (articles' topical content \\vs\\ Wikipedia's category network) as well as the technology used to model the recommendations (simple counting \\vs\\ collaborative filtering). We show that using Wikipedia's category network along with the proposed count-based approach provides the best recommendations, achieving precision@10 close to 80\\% when evaluated by human editors. \\xhdr{Contributions Our main contributions are as follows.", ", our count-based method (\\Secref{sec:Using category--section counts) computes a score for each section S, capturing what fraction of articles in C contains S, and it then ranks sections by their scores. This method yields one section ranking for each category C that A is a member of. If A belongs to several categories, we merge the rankings via learning\\hyp to\\hyp rank (\\Secref{sec:Combining recommendations from multiple categories).", "\\Figref{fig:count_based shows that, with this method, precision for the unweighted sum reaches 57\\% for the first recommended section; at k=20 recommendations, recall reaches 80\\%. We consider this performance sufficient for deploying the method in practice. Generalizing via collaborative filtering To model the relevance of a section in a category with collaborative filtering (CF), it is important to choose an adequate ``rating'' representation.", "Using category--section counts Given a category C as the entry point for generating recommendations, a simple and effective way to measure the relevance of a section S is to count the number of times S appears in all the articles in C. Concretely, we proceed as follows: This procedure requires a clean, ontological category network, which is not given off the shelf (\\Figref{fig:category_network). We address this issue in \\Secref{sec:Cleaning the category network, where we provide a method for cleaning the category network before passing it to the above\\hyp described procedure.", "This step generates scores for more than 191M category--section pairs, from which we extract a mapping between each category in Wikipedia and a set of sections sorted by their relevance. Using an 80/15/5 train\\slash test\\slash validation split, we compute P(S|C) for all (S,C) based on the training set. To make recommendations for a given article A, rather than category C, we combine the recommendations from all of A's categories via a simple, unweighted sum of all the category\\hyp specific scores.", "The number of possible recommendations is upper\\hyp bounded by the total number of sections contained in articles in C, which may result in a small number of recommendations for very small categories. We alleviate this problem by applying collaborative filtering (\\Secref{sec:Generalizing via collaborative filtering), which pools information between categories and allows us to make a large number of recommendations even for categories with only few member articles. It is important to note that Wikipedia categories are organized in a network, with links representing the subcategory relation."], "referred_text_chunks": ["This is especially important for the smaller categories, such as \\cpt{Nauruan scientists, which may contain patterns similar to other categories but do not have enough content to contribute to the generation of recommendations on their own. To understand the impact of category size on the maximum number of recommendations we can generate, consider \\Figref{fig:recommendations_length, which shows, on the y-axis, the fraction of categories large enough to generate at least x section recommendations when following the count\\hyp based approach of \\Secref{sec:Using category--section counts. As shown by the plot, \\eg, only 44\\% of the categories have enough information to produce a recommendation list of 20 sections or more."]}}