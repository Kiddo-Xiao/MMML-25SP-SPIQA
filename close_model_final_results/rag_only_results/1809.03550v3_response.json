{"0": {"question": "Why is the optimal threshold chosen to be at the right margin of the region around the mode of the histogram?", "referred_figures_indices": [4], "response": "{'Image': 4, 'Text': 0, 'Rationale': 'Image 4 shows the histogram of thresholds with highlighted regions, including the optimal threshold at the right margin. Text chunk 0 discusses the process of selecting the optimal threshold starting from the right margin, as the region around the mode is mostly noise.', 'Answer': 'The optimal threshold is chosen at the right margin of the region around the mode of the histogram because this area mostly contains noise, and starting the search from here minimizes the noise influence, leading to a more precise threshold.'}", "all_figures_names": ["1809.03550v3-Table2-1.png", "1809.03550v3-Table1-1.png", "1809.03550v3-Figure2-1.png", "1809.03550v3-Table3-1.png", "1809.03550v3-Figure3-1.png", "1809.03550v3-Figure1-1.png", "1809.03550v3-Table5-1.png", "1809.03550v3-Table4-1.png"], "referred_figures_names": ["1809.03550v3-Figure3-1.png"], "answer": "The region around the mode of the histogram mostly contains noise. Therefore, the optimal threshold is chosen to be at the right margin of this region to avoid including too much noise in the thresholded image.", "figure_type": "plot", "content_type": "figure", "text_chunks": ["Repeating the process for all the points, we arrive to the histogram of thresholds as shown in Figure~. The region around the mode of the histogram (50\\% of its area), outlined by yellow margins on Figure~, mostly contains noise. We start search for the optimum threshold from the right margin to the right until the value of histogram bin is less then 0.0025{\\cdotN, where N is the number of pixels. We found experimentally that the fraction 0.0025 works the best, although its value can be varied without drastic effect.", "Although locally adapted threshold may work best, it is quite common to choose a single threshold for each frame. We follow the same practice: As often in Computer Vision, we seek a threshold of the highest sensitivity, when isolated points ``just'' show up. In particular, we seek a threshold such that a certain fraction (0.0025) of 3{\\times3 contiguous patches have 1 or 2 pixels exceeding the threshold, as suggested in Figure .", "Suppose, the central value in the largest one v_1 and we pick up the second v_2 and the third v_3 largest ones from the 3 \\times 3 vicinity, v_3 \\le v_2 \\le v_1, and all the values are integral as usual for images. If a threshold happens in the interval [v_3+1 \\ldots v_1] then one of the patterns depicted on Figure~ will show up after thresholding. As such, this particular point ``votes'' for the range [v_3+1 \\ldots v_1] in the histogram of thresholds, which means we increment counters in the bins v_3+1 to v_1.", "We accumulate so called histogram of thresholds by analysing 3 \\times 3 neighbourhood of each point in the residual map. There are several how residual value at the central point of relates to its neighbour. Let us consider one example.", "where \\eta_0<1 is a constant. In the limit, \\end{theorem In other words, as time passes, our on-line algorithm generates a sequence of approximately optimal costs that eventually reaches the optimal cost trajectory, up to an asymptotic bound.", "We bound from above the maximum discrepancy between the approximate optimum and the true one at instant k, as k goes to infinity. The convergence to the bound is linear and the rate is \\eta_0, and depends on the properties of the cost function, while the asymptotic bound depends on how fast the problem is changing over time. This is a tracking result: we are pursuing a time-varying optimum by a finite number of iterations \\tau per time-step.", "The optimisation in each of the two alternating least-squares problems is based on parallel block-coordinate descent, as reinterpreted by . Notice that in Nesterov's optimal variant, one requires the the modulus of Lipschitz continuity restricted to the sampled coordinates to compute the step \\delta. Considering that the modulus is not known a priori, we maintain an estimate W_{i\\hat{r^{T,\\tau of the modulus of Lipschitz continuity restricted to the \\L_{k,i \\hat r^{T,\\tau sampled, and estimate V_{\\hat{r j^{T,\\tau of the modulus of Lipschitz continuity restricted to the \\R_{k, \\hat r j^{T,\\tau sampled.", "Here, we need to show the rate of convergence to the bistable point and a distance of the bi-stable point to an optimum f^*: The proof is available on-line the appendix and should not be surprising, in light of . Building upon this, we can prove a bound on the error in the on-line regime. In particular, we will show that Algorithm~ generates a sequence of matrices \\{(\\L_k, \\R_k)\\ that in the large limit of k \\to \\infty guarantees a bounded tracking error, i.e., f(\\L_k, \\R_k; \\M_k)"], "referred_text_chunks": ["Repeating the process for all the points, we arrive to the histogram of thresholds as shown in Figure~. The region around the mode of the histogram (50\\% of its area), outlined by yellow margins on Figure~, mostly contains noise. We start search for the optimum threshold from the right margin to the right until the value of histogram bin is less then 0.0025{\\cdotN, where N is the number of pixels. We found experimentally that the fraction 0.0025 works the best, although its value can be varied without drastic effect."]}, "1": {"question": "Which method achieves the best overall F1 score across all categories? Is this method consistently the best across all individual categories?", "referred_figures_indices": [5], "response": "{'Image': 5, 'Text': 0, 'Rationale': 'Image 5 summarizes the F1 scores across different categories, allowing comparison of methods overall and per category. Text 0 discusses improvements in F1 scores, which is relevant to determining the best-performing method.', 'Answer': 'Algorithm 2 with the Geman-McLure function achieves the best overall F1 score of 0.56514. However, it is not consistently the best across all individual categories.'}", "all_figures_names": ["1809.03550v3-Table4-1.png", "1809.03550v3-Table1-1.png", "1809.03550v3-Figure2-1.png", "1809.03550v3-Figure4-1.png", "1809.03550v3-Table2-1.png", "1809.03550v3-Table5-1.png", "1809.03550v3-Table3-1.png", "1809.03550v3-Table6-1.png"], "referred_figures_names": ["1809.03550v3-Table5-1.png"], "answer": "According to the table, Algorithm 2 w/ Geman-McLure) achieves the best overall F1 score of 0.56514. However, this method is not consistently the best across all individual categories. For example, OMoGMF has a higher F1 score for the \"badWeather\" category.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Out of these, OMoGMF is the most recent and considered to be the most robust. Still, we can improve upon the results of OMoGMF by a considerable margin: the F1 score across the 6 categories is improved by 28\\% from 0.44643 to 0.57099, for example. Further details and results are available in the appendix.", "We should like to stress that the F1 score depends on thresholding method, which is quite simple in our current implementation and could be improved. Finally, a number of modern methods including the top three in the CDnet ranking as of May 2018 are ``supervised'', in the sense that they derive megabytes of a model from the test set and then apply the model to the test set, which constitutes ``double dipping''. % With these caveats in mind, the performance seems rather respectable.", "In Tables~ and ~, we summarise the results. In particular, we present the false positive rate (FPR), false negative rate (FNR), specificity, precision, recall, and the geometric mean of the latter two (F1) of our method and 6 other low-rank approaches, which have been used as reference methods recently . These reference methods are implemented in \\texttt{LRSLibrary and by the original authors of \\texttt{OMoGMF , and have been used with their default settings.", "First, we present MS-SSIM of , a well-known measure of similarity of the background of each frame to our rank-4 estimate thereof, which is also known as the multiscale structural similarity for image quality. There, our estimates perform rather well, with the exception of videos featuring dynamic backgrounds such as waves and reflections of sun light on water, where the low-rank model is not updated often enough to capture all of the rapid changes. Next, we present the F1 score, which is the harmonic mean of precision and recall and which we used the code provided by CDnet to evaluate against the ground truth.", "For each input, we consider factors \\L and \\R as the optimisation variable alternatingly, with counter T. For each factor, we take a number of block-coordinate descent steps, with the blocks sampled randomly; the counter for the block-coordinate steps is \\tau. In particular, in Steps 3--8 of the algorithm, we fix \\R_k^{T,\\tau, choose a random \\hat{r and a random set \\hatSr of rows of \\L_k, and, in parallel for i \\in \\hatSr, update \\L_{k,i\\hat{r^{T,\\tau+1 to \\L_{k,i\\hat{r^{T,\\tau + \\delta_{i\\hat{r, where the step is: and \\P_{i\\hat{r is the n \\times r matrix with 1 in entry (i\\hat{r) and zeros elsewhere. The computation of \\langle \\nabla_{\\L_k f(\\L_k^{T,\\tau,\\R_k^{T,\\tau; \\M_k), \\P_{\\hat{rj\\rangle can be simplified considerably, as explained in % in Section ``A Derivation of the Step Size'' % of the appendix.", "In Table , we present a comparison similar to Table , except that results of Algorithm~ are obtained by using the smooth Geman-McLure loss function instead of subsampling with the non-smooth L1 norm. \\end{table* In Table , we present a comparison of the mean run-time per frame of the methods discussed in the paper.", "The Overall Schema Overall, we interleave the updates to the low-rank model via the inequality-constrained matrix completion, detection of sparse noise, and updating of the inputs to the inequality-constrained matrix completion, which disregards the sparse noise. At each time step, we acquire new measurements \\x_d and compute their projection coefficients onto the low-rank subspace as where p can be the 1,2,\\infty norm, or the 0 pseudo-norm. Since for a very large number of sensors, even solving~\\eqref{proj can be challenging, we subsample \\x_d", "By introducing the additional variables m_i: |({\\bf c{\\bf R)_i - {\\bf f_i| \\le m_i, for all i=\\overline{1,N, the optimization problem can be reformulated as a linear program: \\end{equation Alternatively, one can consider the robust Geman-McLure function \\rho(r,\\sigma) = {r^2/(r^2 + \\sigma^2) as featured in , where parameter \\sigma is estimated from the distribution of residuals over the course of optimization In practice, both () and () produce results of similar quality, with a slightly better statistical performance of () at a minor additional expense in terms of run-time, compared to the use of gradient methods in minimisation of (). After the optimal linear combination {\\bf c_{opt has been obtained in (), the next step is to compute residuals r_i = |({\\bf c{\\bf R)_i - {\\bf f_i|"], "referred_text_chunks": ["Out of these, OMoGMF is the most recent and considered to be the most robust. Still, we can improve upon the results of OMoGMF by a considerable margin: the F1 score across the 6 categories is improved by 28\\% from 0.44643 to 0.57099, for example. Further details and results are available in the appendix."]}, "2": {"question": "Which algorithm achieves the fastest processing time per frame and how much faster is it compared to the slowest algorithm listed?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Text': 2, 'Rationale': 'Image 3 directly compares the mean processing times of different algorithms, which is essential for answering the question about the fastest processing time per frame. Text 2 refers to a comparison of methods and their run-time, aligning with the image data about processing speed.', 'Answer': 'Algorithm 2 (with Geman-McLure) achieves the fastest processing time per frame at 0.103 seconds. It is 102.18 times faster than the slowest algorithm, MC_GROUSE, which has a processing time of 10.621 seconds per frame.'}", "all_figures_names": ["1809.03550v3-Figure3-1.png", "1809.03550v3-Figure4-1.png", "1809.03550v3-Table2-1.png", "1809.03550v3-Table6-1.png", "1809.03550v3-Table1-1.png", "1809.03550v3-Table5-1.png", "1809.03550v3-Table4-1.png", "1809.03550v3-Figure1-1.png"], "referred_figures_names": ["1809.03550v3-Table6-1.png"], "answer": "Algorithm 12(SCDM with Geman-McLure) achieves the fastest processing time per frame at 0.103 seconds. This is approximately 100 times faster than the slowest algorithm, TTD_3WD, which takes 10.343 seconds per frame.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["On the other hand, there is a linear increase in per-iteration run-time with the number of epochs of coordinate descent per update. This motivated our choice of 1 epoch per update, which allows for real-time processing at 10 frames per second without parallelisation, which can further improve performance as suggested in Algorithm . \\end{table* \\end{table*", "Based on limited experimentation, we have decided on the use of a time window of T = 35, rank r = 4, and half-width of the uniform noise \\Delta = 5. We have used dual simplex from IBM ILOG CPLEX 12.8 as a linear-programming solver for solving solving \\eqref{sampledproj in Algorithm . To initialise the \\L_0 and \\R_0 in Algorithm , we have used the matrix completion of Algorithms with 1 epoch per frame for 3 passes on each video (4,000 to 32,000 frames), starting from all-zero matrices.", "In Table , we present a comparison similar to Table , except that results of Algorithm~ are obtained by using the smooth Geman-McLure loss function instead of subsampling with the non-smooth L1 norm. \\end{table* In Table , we present a comparison of the mean run-time per frame of the methods discussed in the paper.", "We have also conducted a number of experiments on instances from changedetection.net , a benchmark often used to test low-rank approaches. There, short videos (1,000 to 9,000 frames) are supplemented with ground-truth information of what is foreground and what is background. These experiments have been run on a single 4-core workstation (Intel Core i7-4800MQ CPU, 16~GB of RAM, RedHat~7.6/64) and results have been deposited in FigShare.", "Clearly, solving the non-convex problem \\eqref{eq:Specific for non-trivial dimensions of matrix \\M_k to a non-trivial accuracy at high-frequency requires careful algorithm design. We propose an algorithm that tracks the low-rank \\R_k over time, increasing the accuracy of the solution of~\\eqref{eq:Specific while new observations are brought in, and old ones are discarded. In particular, we propose the on-line alternating parallel randomised block-coordinate descent method summarized in Algorithm~. For each input k, the previously-found approximate solutions (\\L_{k-1, \\R_{k-1), are updated based on the new observation matrix \\M_k, the correspondingly-derived element-wise lower and upper bounds \\underline{M_{k,ij, \\overline{M_{k,ij, and the desired rank r. The update is computed using the alternatig least squares (ALS) method, which is based on the observation that while f \\eqref{eq:Specific is not convex jointly in (\\L_k,\\R_k), it is convex in \\L_k for fixed \\R_k and in \\R_k for fixed \\L_k.", "We note that in real-world deployments, such an initialisation may be unnecessary, as the the number of frames processed will render the initial error irrelevant. First, let us highlight two aspects of the performance of the algorithm. In particular, on the top in Figure~, we illustrate the effects of the subsampling on the projection \\eqref{sampledproj.", "We present the pursuit of time-varying low-rank models of time-varying matrices, which is robust to both dense uniformly-distributed measurement noise and sparse arbitrarily-distributed noise. Consider, for example, background subtraction problem in Computer Vision, where one wishes to distinguish fast-moving foreground objects from slowly-varying background in video data . There, a matrix represents a constant number of frames of the video data, flattened to one row-vector per frame.", "When the matrix \\M_k does not change quickly, performing a fixed number of iterations within an inexact step () upon arrival of a new sample makes it possible to spread the computational load over time, while still recovering a good background model. Also, our algorithm is easy to implement and optimize. It has very few hyper-parameters, and this simplifies tuning."], "referred_text_chunks": ["On the other hand, there is a linear increase in per-iteration run-time with the number of epochs of coordinate descent per update. This motivated our choice of 1 epoch per update, which allows for real-time processing at 10 frames per second without parallelisation, which can further improve performance as suggested in Algorithm . \\end{table* \\end{table*"]}, "3": {"question": "What is the relationship between the residuals prior to thresholding and the Boolean map?", "referred_figures_indices": [6], "response": "{'Image': 6, 'Text': 2, 'Rationale': 'Image 6 visually depicts the relationship between residuals prior to thresholding and their conversion to a Boolean map, directly linking to the question. Text 2 describes the thresholding process and formation of the Boolean map using residuals, relevant to understanding this transformation.', 'Answer': 'Residuals are used in a thresholding process, where each residual is evaluated against a threshold to create a binary (Boolean) map indicating whether the observation is likely from the model.'}", "all_figures_names": ["1809.03550v3-Table5-1.png", "1809.03550v3-Table6-1.png", "1809.03550v3-Table3-1.png", "1809.03550v3-Figure3-1.png", "1809.03550v3-Figure2-1.png", "1809.03550v3-Table4-1.png", "1809.03550v3-Figure4-1.png", "1809.03550v3-Table1-1.png"], "referred_figures_names": ["1809.03550v3-Figure4-1.png"], "answer": "The Boolean map is obtained by thresholding the residuals prior to thresholding.", "figure_type": "photograph(s)", "content_type": "figure", "text_chunks": ["We accumulate so called histogram of thresholds by analysing 3 \\times 3 neighbourhood of each point in the residual map. There are several how residual value at the central point of relates to its neighbour. Let us consider one example.", "Once the projection coefficients \\v have been computed, we can compute the discrepancy between the measurement (\\x_d)_i coming from sensor i and our projection \\eqref{sampledproj, \\|(\\x_d)_i - (\\v \\R_{k-1)_i\\|_p, also known as the residual for sensor i. We use the residuals in a two-step thresholding procedure inspired by . In the first step, we use residuals to compute a coefficient \\lambda > 0.", "In the second step, we consider the individual residuals as samples of an empirical distribution, and take the value at risk (VaR) at \\lambda as a threshold. We provide details in . The test as to whether residual at each sensor is below the threshold results in a binary map, suggesting whether the observation of each sensor is likely to have come from our model or not.", "To explain this in detail, consider the RGB colour images, where the point-wise 2D residual map is computed as follows: r_{i = \\left|R^{(f)_i - R^{(b)_i\\right| + \\left|G^{(f)_i - G^{(b)_i\\right| + \\left|B^{(f)_i - B^{(b)_i\\right|, where subscripts f and b stands for current frame and background respectively, and index i enumerates image pixels. Other metrics like Euclidean one are also possible.", "and threshold them into those generated by the low-rank model, r_i < T, and the remainder, r_i >= T, where T is some threshold. Thresholding for background subtraction is a vast area by itself. %", "Applying Lemma~, Using (a+b)^2 \\leq 2(a^2+b^2), Finally, by simple algebra, where \\end{proof Finally: By summing and subtracting \\eta_0 f(\\L_{k-1, \\R_{k-1; \\M_{k-1) to the right-hand-side and putting without loss of generality f(\\L_k^*, \\R_k^*; \\M_k) = f(\\L_k^*, \\R_k^*; \\M_{k-1), and by using Assumption~ By summation of geometric series, the claim is proven. \\end{proof Details of the Thresholding As suggested in the main body of the text, we start by looking for the best linear combination {\\bf c that minimizes difference in L_1: where {\\bf c is a 1{\\timesrank vector, {\\bf f is a 2D image flattened into 1{\\timesN vector, and ({\\bf c{\\bf R)_i is the scalar result of multiplication between vector {\\bf c and i-th column of matrix {\\bf R. Due to the robust property of L_1 norm, the formulation () provides a close approximation of the new frame at the majority of stationary (background) points, while leaving residuals at the ``moving'' (foreground) points relatively high.", "Repeating the process for all the points, we arrive to the histogram of thresholds as shown in Figure~. The region around the mode of the histogram (50\\% of its area), outlined by yellow margins on Figure~, mostly contains noise. We start search for the optimum threshold from the right margin to the right until the value of histogram bin is less then 0.0025{\\cdotN, where N is the number of pixels. We found experimentally that the fraction 0.0025 works the best, although its value can be varied without drastic effect.", "Suppose, the central value in the largest one v_1 and we pick up the second v_2 and the third v_3 largest ones from the 3 \\times 3 vicinity, v_3 \\le v_2 \\le v_1, and all the values are integral as usual for images. If a threshold happens in the interval [v_3+1 \\ldots v_1] then one of the patterns depicted on Figure~ will show up after thresholding. As such, this particular point ``votes'' for the range [v_3+1 \\ldots v_1] in the histogram of thresholds, which means we increment counters in the bins v_3+1 to v_1."], "referred_text_chunks": ["We accumulate so called histogram of thresholds by analysing 3 \\times 3 neighbourhood of each point in the residual map. There are several how residual value at the central point of relates to its neighbour. Let us consider one example."]}}