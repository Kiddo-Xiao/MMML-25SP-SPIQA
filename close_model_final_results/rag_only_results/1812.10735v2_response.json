{"0": {"question": "What is the difference between an overlapping case and an error case?", "referred_figures_indices": [7], "response": "{'Image': 7, 'Text': 1, 'Rationale': 'Image 7 directly illustrates examples of overlapping and error cases, while Text 1 provides context about overlapping sentences. Together, they clarify the question.', 'Answer': 'In the overlapping case, multiple aspects share the same opinion snippet. In the error case, an aspect fails to correctly associate with relevant words, missing negation or connections.'}", "all_figures_names": ["1812.10735v2-Table3-1.png", "1812.10735v2-Figure5-1.png", "1812.10735v2-Figure3-1.png", "1812.10735v2-Table4-1.png", "1812.10735v2-Figure2-1.png", "1812.10735v2-Figure4-1.png", "1812.10735v2-Table1-1.png", "1812.10735v2-Figure6-1.png"], "referred_figures_names": ["1812.10735v2-Figure6-1.png"], "answer": "An overlapping case is when multiple aspects share the same opinion snippet, while an error case is when the model incorrectly identifies an aspect or opinion.", "figure_type": "table", "content_type": "figure", "text_chunks": ["A multi-aspect sentence can be categorized as overlapping or non-overlapping. A sentence is annotated as non-overlapping if any two of its aspects have no overlap. Our study found that around 85\\% of the multi-aspect sentences are non-overlapping in the two public datasets.", "\\newline\\indent We plot the regularization loss curves in Figure , which shows that both R_s and R_o decrease during the training of AT-CAN-R_o. Case Studies{\\bf Overlapping Case We only add sparse regularization to overlapping sentences in which multiple aspects share the same opinion snippet.", "Figure shows a simple example. The non-overlapping sentence contains two aspects. The aspect food is on the left side of the aspect service.", "Detailed statistics are summarized in Table . Particularly, 85.23\\% and 83.73\\% of the multi-aspect sentences are non-overlapping in Rest14 and Rest15, respectively. % \\caption{ Results of the ALSC task in single-task settings in terms of accuracy (\\%) and Macro-F1 (\\%).", "{\\bf Note that this layer is only available in the training stage, in which the ground-truth aspects are known for calculating the regularization loss, and then influence parameter updating in back propagation. While in the testing/inference stage, the true aspects are unknown and the regularization loss is not calculated so that this layer is omitted from the architecture. In this paper, we introduce two types of regularizations: the sparse regularization on each single aspect; the orthogonal regularization on multiple non-overlapping aspects.", "As shown in Figure , for the first sentence in error case, the aspect food attends on the right word ``disappointing'', but fails to include the negation word ``never''. This may be caused by the inaccurate sentence representation or aspect embedding. We can not rebuild the connection between the aspect and the word by our regularizations.", "To apply orthogonal regularization, we manually annotate the multi-aspect sentences with overlapping or non-overlapping. We randomly split the original training set into training, validation sets in the ratio 5:1, where the validation set is used to select the best model. We count the sentences of single-aspect and multi-aspect separately.", "\\newcite{multi-aspect2-emnlp design an aspect alignment loss to enhance the difference of the attention weights towards the aspects which have the same context and different sentiment polarities. In this paper, we introduce orthogonal regularization to constrain the attention weights of multiple non-overlapping aspects, as well as sparse regularization on each single aspect. {\\bf Multi-task learning \\newcite{Caruana1997Multitask solves multiple learning tasks at the same time, achieving improved performance by exploiting commonalities and differences across tasks."], "referred_text_chunks": ["A multi-aspect sentence can be categorized as overlapping or non-overlapping. A sentence is annotated as non-overlapping if any two of its aspects have no overlap. Our study found that around 85\\% of the multi-aspect sentences are non-overlapping in the two public datasets."]}, "1": {"question": "Which dataset has a higher proportion of sentences containing multiple aspects: Rest14 or Rest15?", "referred_figures_indices": [7], "response": "{'Image': 7, 'Text': 1, 'Rationale': 'Image 7 directly shows the number of single and multi-aspect sentences in Rest14 and Rest15. Text 1 provides relevant statistics about non-overlapping multi-aspect sentences in the datasets.', 'Answer': 'Rest14 has a higher proportion of sentences containing multiple aspects.'}", "all_figures_names": ["1812.10735v2-Figure5-1.png", "1812.10735v2-Table4-1.png", "1812.10735v2-Figure6-1.png", "1812.10735v2-Table3-1.png", "1812.10735v2-Table2-1.png", "1812.10735v2-Figure4-1.png", "1812.10735v2-Figure3-1.png", "1812.10735v2-Table1-1.png"], "referred_figures_names": ["1812.10735v2-Table1-1.png"], "answer": "Rest14 has a higher proportion of sentences containing multiple aspects compared to Rest15.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Rest14 has 5 aspect categories while Rest15 has 13 ones. \\end{table* Implementation Details We set \\lambda=0.1 with the help of the validation set.", "Detailed statistics are summarized in Table . Particularly, 85.23\\% and 83.73\\% of the multi-aspect sentences are non-overlapping in Rest14 and Rest15, respectively. % \\caption{ Results of the ALSC task in single-task settings in terms of accuracy (\\%) and Macro-F1 (\\%).", "To avoid L_b overwhelming the overall loss, we divide it by the number of aspect categories. Experiments Datasets We conduct experiments on two public datasets from SemEval 2014 task 4 and SemEval 2015 task 12 (denoted by Rest14 and Rest15 respectively). These two datasets consist of restaurant customer reviews with annotations identifying the mentioned aspects and the sentiment polarity of each aspect.", "Second, in almost all cases, applying attention regularizations to both tasks gains more performance improvement than only to the ALSC task, which shows that our attention regularization approach can be extended to different tasks which involving aspect level attention weights, and works well in multi-task settings. For example, for the Binary classification in the Rest15 dataset, M-AT-LASTM outperforms AT-LSTM by 3.57\\% of accuracy and 4.96\\% of the F1 score, and M-CAN-2R_o further outperforms M-AT-LSTM by 3.28\\% of accuracy and 4.0\\% of the F1 score. % Table shows the results of the ACD task in multi-task settings.", "Firstly, we observe that by introducing attention regularizations (either R_s or R_o), most of our proposed methods outperform their counterparts. Particularly, AT-CAN-R_s and AT-CAN-R_o outperform AT-LSTM in all results; ATAE-CAN-R_s and ATAE-CAN-R_o also outperform ATAE-LSTM in 15 of 16 results. For example, in the Rest15 dataset, ATAE-CAN-R_o outperforms ATAE-LSTM by up to 5.39\\% of accuracy and 6.46\\% of the F1 score in the 3-way classification.", "Conclusions We propose constrained attention networks for multi-aspect sentiment analysis, which handles multiple aspects of a sentence simultaneously. Specifically, we introduce orthogonal and sparse regularizations on attention weights. Furthermore, we introduce an auxiliary task ACD for promoting the ALSC task, and apply CAN on both tasks.", "Secondly, regularization R_o achieves better performance improvement than R_s in all results. This is because R_o includes both orthogonal and sparse regularizations for non-overlapping multi-aspect sentences. Thirdly, our approaches, especially ATAE-CAN-R_o, outperform the state-of-the-art baseline model GCAE.", "Specifically, we introduce orthogonal regularization for attention weights among multiple non-overlapping aspects. The orthogonal regularization tends to make the attention weights of multiple aspects concentrate on different parts of the sentence with less overlap. We also introduce the sparse regularization, which tends to make the attention weights of each aspect concentrate only on a few words."], "referred_text_chunks": ["Rest14 has 5 aspect categories while Rest15 has 13 ones. \\end{table* Implementation Details We set \\lambda=0.1 with the help of the validation set."]}, "2": {"question": "Why do you think the performance of all models is generally lower on Rest15 compared to Rest14?", "referred_figures_indices": [5], "response": "{'Image': 5, 'Text': 0, 'Rationale': 'Image 5 provides a comparison of model performance on Rest14 and Rest15, showing differences in F1 scores which suggest more difficulty in Rest15. Text 0 mentions the difference in aspect categories, with Rest15 having more, adding to the complexity.', 'Answer': 'The performance is generally lower on Rest15 because it has 13 aspect categories compared to 5 in Rest14, making it more complex for models to perform well.'}", "all_figures_names": ["1812.10735v2-Figure6-1.png", "1812.10735v2-Figure4-1.png", "1812.10735v2-Figure5-1.png", "1812.10735v2-Figure1-1.png", "1812.10735v2-Table2-1.png", "1812.10735v2-Table4-1.png", "1812.10735v2-Table1-1.png", "1812.10735v2-Table3-1.png"], "referred_figures_names": ["1812.10735v2-Table4-1.png"], "answer": "The performance of all models is generally lower on Rest15 because it has a larger number of aspect categories (13) compared to Rest14 (5). This increased complexity makes it more challenging for the models to accurately identify and classify the aspects.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Rest14 has 5 aspect categories while Rest15 has 13 ones. \\end{table* Implementation Details We set \\lambda=0.1 with the help of the validation set.", "Firstly, we observe that by introducing attention regularizations (either R_s or R_o), most of our proposed methods outperform their counterparts. Particularly, AT-CAN-R_s and AT-CAN-R_o outperform AT-LSTM in all results; ATAE-CAN-R_s and ATAE-CAN-R_o also outperform ATAE-LSTM in 15 of 16 results. For example, in the Rest15 dataset, ATAE-CAN-R_o outperforms ATAE-LSTM by up to 5.39\\% of accuracy and 6.46\\% of the F1 score in the 3-way classification.", "Second, in almost all cases, applying attention regularizations to both tasks gains more performance improvement than only to the ALSC task, which shows that our attention regularization approach can be extended to different tasks which involving aspect level attention weights, and works well in multi-task settings. For example, for the Binary classification in the Rest15 dataset, M-AT-LASTM outperforms AT-LSTM by 3.57\\% of accuracy and 4.96\\% of the F1 score, and M-CAN-2R_o further outperforms M-AT-LSTM by 3.28\\% of accuracy and 4.0\\% of the F1 score. % Table shows the results of the ACD task in multi-task settings.", "To avoid L_b overwhelming the overall loss, we divide it by the number of aspect categories. Experiments Datasets We conduct experiments on two public datasets from SemEval 2014 task 4 and SemEval 2015 task 12 (denoted by Rest14 and Rest15 respectively). These two datasets consist of restaurant customer reviews with annotations identifying the mentioned aspects and the sentiment polarity of each aspect.", "The models are trained for 100 epochs, during which the model with the best performance on the validation set is saved. We also apply early stopping in training, which means that the training will stop if the performance on validation set does not improve in 10 epochs. % Results Table and show our experimental results on the two public datasets for single-task and multi-task settings respectively.", "Finally, the LSTM method outputs the worst results in all cases, because it can not distinguish different aspects. {\\bf Multi-task Settings Table shows experimental results of ALSC in multi-task settings. We first observe that the overall results in multi-task settings outperform the ones in single-task settings, which demonstrates the effectiveness of multi-task learning by introducing the auxiliary ACD task to help the ALSC task.", "Detailed statistics are summarized in Table . Particularly, 85.23\\% and 83.73\\% of the multi-aspect sentences are non-overlapping in Rest14 and Rest15, respectively. % \\caption{ Results of the ALSC task in single-task settings in terms of accuracy (\\%) and Macro-F1 (\\%).", "Secondly, regularization R_o achieves better performance improvement than R_s in all results. This is because R_o includes both orthogonal and sparse regularizations for non-overlapping multi-aspect sentences. Thirdly, our approaches, especially ATAE-CAN-R_o, outperform the state-of-the-art baseline model GCAE."], "referred_text_chunks": ["Rest14 has 5 aspect categories while Rest15 has 13 ones. \\end{table* Implementation Details We set \\lambda=0.1 with the help of the validation set."]}, "3": {"question": "Which model performed best on the Rest15 dataset for binary classification, and how does its performance compare to the best model for 3-way classification on the same dataset?", "referred_figures_indices": [5], "response": "{'Image': 5, 'Text': 1, 'Rationale': 'Image 5 shows performance results of various models in a multi-task setting, directly comparing binary and 3-way classifications. Text chunk 1 discusses performance improvements with attention regularizations and mentions specific model performance on the Rest15 dataset.', 'Answer': 'The best model on the Rest15 dataset for binary classification is M-CAN-2R_o with 82.14% accuracy and 81.58% F1 score. For 3-way classification, the best model is M-CAN-2R_o with 77.51% accuracy and 52.78% F1 score. The binary classification model outperforms the 3-way classification model significantly in both accuracy and F1 score.'}", "all_figures_names": ["1812.10735v2-Figure1-1.png", "1812.10735v2-Figure6-1.png", "1812.10735v2-Figure3-1.png", "1812.10735v2-Figure5-1.png", "1812.10735v2-Table2-1.png", "1812.10735v2-Table3-1.png", "1812.10735v2-Figure2-1.png", "1812.10735v2-Table4-1.png"], "referred_figures_names": ["1812.10735v2-Table3-1.png"], "answer": "For binary classification on the Rest15 dataset, M-CAN-2$R_o$ achieved the highest performance with an accuracy of 82.14% and Macro-F1 of 81.58%. In comparison, the best performing model for 3-way classification on Rest15 was M-CAN-2$R_s$, achieving an accuracy of 78.22% and Macro-F1 of 55.80%. This indicates that M-CAN-2$R_o$ performed better in both accuracy and Macro-F1 for binary classification compared to the best model for 3-way classification on the same dataset.", "figure_type": "N/A", "content_type": "table", "text_chunks": ["Firstly, we observe that by introducing attention regularizations (either R_s or R_o), most of our proposed methods outperform their counterparts. Particularly, AT-CAN-R_s and AT-CAN-R_o outperform AT-LSTM in all results; ATAE-CAN-R_s and ATAE-CAN-R_o also outperform ATAE-LSTM in 15 of 16 results. For example, in the Rest15 dataset, ATAE-CAN-R_o outperforms ATAE-LSTM by up to 5.39\\% of accuracy and 6.46\\% of the F1 score in the 3-way classification.", "Second, in almost all cases, applying attention regularizations to both tasks gains more performance improvement than only to the ALSC task, which shows that our attention regularization approach can be extended to different tasks which involving aspect level attention weights, and works well in multi-task settings. For example, for the Binary classification in the Rest15 dataset, M-AT-LASTM outperforms AT-LSTM by 3.57\\% of accuracy and 4.96\\% of the F1 score, and M-CAN-2R_o further outperforms M-AT-LSTM by 3.28\\% of accuracy and 4.0\\% of the F1 score. % Table shows the results of the ACD task in multi-task settings.", "In both tables, ``3-way'' stands for 3-class classification (positive, neutral, and negative), and ``Binary'' for binary classification (positive and negative). The best scores are marked in bold. {\\bf Single-task Settings Table shows our experimental results of ALSC in single-task settings.", "Rest14 has 5 aspect categories while Rest15 has 13 ones. \\end{table* Implementation Details We set \\lambda=0.1 with the help of the validation set.", "The models are trained for 100 epochs, during which the model with the best performance on the validation set is saved. We also apply early stopping in training, which means that the training will stop if the performance on validation set does not improve in 10 epochs. % Results Table and show our experimental results on the two public datasets for single-task and multi-task settings respectively.", "Secondly, regularization R_o achieves better performance improvement than R_s in all results. This is because R_o includes both orthogonal and sparse regularizations for non-overlapping multi-aspect sentences. Thirdly, our approaches, especially ATAE-CAN-R_o, outperform the state-of-the-art baseline model GCAE.", "Our proposed regularization terms can also improve the performance of ACD. Regularization R_o achieves the best performance in almost all metrics. % Attention Visualizations Figure depicts the attention weights from AT-LSTM, M-AT-LSTM and M-CAN-2R_o methods, which are used to predict the sentiment polarity in the ALSC task.", "To avoid L_b overwhelming the overall loss, we divide it by the number of aspect categories. Experiments Datasets We conduct experiments on two public datasets from SemEval 2014 task 4 and SemEval 2015 task 12 (denoted by Rest14 and Rest15 respectively). These two datasets consist of restaurant customer reviews with annotations identifying the mentioned aspects and the sentiment polarity of each aspect."], "referred_text_chunks": ["Firstly, we observe that by introducing attention regularizations (either R_s or R_o), most of our proposed methods outperform their counterparts. Particularly, AT-CAN-R_s and AT-CAN-R_o outperform AT-LSTM in all results; ATAE-CAN-R_s and ATAE-CAN-R_o also outperform ATAE-LSTM in 15 of 16 results. For example, in the Rest15 dataset, ATAE-CAN-R_o outperforms ATAE-LSTM by up to 5.39\\% of accuracy and 6.46\\% of the F1 score in the 3-way classification."]}, "4": {"question": "What are the two main tasks that the CAN network is designed to perform?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Text': 0, 'Rationale': 'Image 2 clearly illustrates the network architecture for ALSC and ACD tasks, showing how the model processes them. Text 0 explicitly mentions the CAN network supporting both ALSC and ACD tasks.', 'Answer': 'The CAN network is designed to perform Aspect-Level Sentiment Classification (ALSC) and Aspect Category Detection (ACD) tasks.'}", "all_figures_names": ["1812.10735v2-Table3-1.png", "1812.10735v2-Figure6-1.png", "1812.10735v2-Figure2-1.png", "1812.10735v2-Figure1-1.png", "1812.10735v2-Figure4-1.png", "1812.10735v2-Table2-1.png", "1812.10735v2-Figure5-1.png", "1812.10735v2-Figure3-1.png"], "referred_figures_names": ["1812.10735v2-Figure2-1.png"], "answer": "Aspect-level sentiment classification (ALSC) and aspect category detection (ACD).", "figure_type": "schematic", "content_type": "figure", "text_chunks": ["We propose CAN for multi-aspect sentiment analysis, supporting both ALSC and ACD tasks by a multi-task learning framework. The network architecture is shown in Figure . We will introduce all components sequentially from left to right.", "We call our networks with such regularizations constrained attention networks (CAN). There have been some works on introducing sparsity in attention weights in machine translation and orthogonal constraints in domain adaptation . In this paper, we add both sparse and orthogonal regularizations in a unified form inspired by the work .", "By applying attention weight constraints to both ALSC and ACD tasks in an end-to-end network, we can further evaluate the effectiveness of CAN in multi-task settings. In summary, the main contributions of our work are as follows: Related Work {\\bf Aspect level sentiment analysis is a fine-grained sentiment analysis task. Earlier methods are usually based on explicit features .", "Second, in almost all cases, applying attention regularizations to both tasks gains more performance improvement than only to the ALSC task, which shows that our attention regularization approach can be extended to different tasks which involving aspect level attention weights, and works well in multi-task settings. For example, for the Binary classification in the Rest15 dataset, M-AT-LASTM outperforms AT-LSTM by 3.57\\% of accuracy and 4.96\\% of the F1 score, and M-CAN-2R_o further outperforms M-AT-LSTM by 3.28\\% of accuracy and 4.0\\% of the F1 score. % Table shows the results of the ACD task in multi-task settings.", "Conclusions We propose constrained attention networks for multi-aspect sentiment analysis, which handles multiple aspects of a sentence simultaneously. Specifically, we introduce orthogonal and sparse regularizations on attention weights. Furthermore, we introduce an auxiliary task ACD for promoting the ALSC task, and apply CAN on both tasks.", "Our proposed regularization terms can also improve the performance of ACD. Regularization R_o achieves the best performance in almost all metrics. % Attention Visualizations Figure depicts the attention weights from AT-LSTM, M-AT-LSTM and M-CAN-2R_o methods, which are used to predict the sentiment polarity in the ALSC task.", "\\newline\\indent As shown in subfigure (c), M-CAN+2R_o generates the best attention weights. The attention weights of the aspect food are almost orthogonal to the weights of service. The aspect food concentrates on the first part of the sentence while service on the second part.", "Multi-task learning has been used successfully in many machine learning applications. \\newcite{Huang2018Multitask learn both main task and auxiliary task jointly with shared representations, achieving improved performance in question answering. \\newcite{Toshniwal2017Multitask use low-level auxiliary tasks for encoder-decoder based speech recognition, which suggests that the addition of auxiliary tasks can help in either optimization or generalization."], "referred_text_chunks": ["We propose CAN for multi-aspect sentiment analysis, supporting both ALSC and ACD tasks by a multi-task learning framework. The network architecture is shown in Figure . We will introduce all components sequentially from left to right."]}}