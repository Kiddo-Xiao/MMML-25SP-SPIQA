{
  "0": {
    "question": "How does the performance of the model with convolutional self-correction compare to the model with no self-correction as the number of images in set $\\mathcal{F}$ increases?",
    "ground_truth": "The model with convolutional self-correction consistently outperforms the model with no self-correction as the number of images in set $\\mathcal{F}$ increases.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The model with convolutional self-correction outperforms the model with no self-correction as the number of images in set $\\mathcal{F}$ increases. <s>"
  },
  "1": {
    "question": "Which method performed the best on the PASCAL VOC 2012 test set and how does it compare to the baseline model without self-correction?",
    "ground_truth": "The Conv. Self-Corr. method achieved the highest performance on the PASCAL VOC 2012 test set with a score of 82.72. This is approximately 1.11 points higher than the baseline model (\"No Self-Corr.\") which achieved a score of 81.61.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The Conv. Self-correction model performed the best on the PASCAL VOC 2012 test set, outperforming the baseline model without self-correction by a significant margin. <s>"
  },
  "2": {
    "question": "What is the input to the convolutional self-correction model?",
    "ground_truth": "The input to the convolutional self-correction model is the logits generated by the primary and ancillary models.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The input to the convolutional self-correction model is a feature map generated by a convolutional neural network (CNN). <s>"
  },
  "3": {
    "question": "How does the performance of the \"Conv. Self-Correction\" method compare to other methods when using 30% of the training examples as $\\F$ and the remaining as $\\W$ on the Cityscapes validation set?",
    "ground_truth": "The \"Conv. Self-Correction\" method achieves the highest mIOU score of 79.46 compared to other methods listed in the table under the same data split condition.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png"
    ],
    "answer": "The \"Conv. Self-Correction\" method outperforms other methods when using 30% of the training examples as $\\F$ and the remaining as $\\W$ on the Cityscapes validation set. <s>"
  },
  "4": {
    "question": "How does the bounding box encoder network influence the segmentation process?",
    "ground_truth": "The bounding box encoder network embeds bounding box information at different scales and outputs attention maps that are used to fuse with feature maps from the encoder before being passed to the decoder.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The bounding box encoder network influences the segmentation process by providing additional information about the location and shape of objects in the image. This information is used to refine the segmentation output of the existing encoder-decoder model, improving the accuracy and quality of the final segmentation result. <s>"
  },
  "5": {
    "question": "What is the role of the self-correction module in the segmentation framework?",
    "ground_truth": "The self-correction module refines the segmentations generated by the ancillary and current primary model for the weak set.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The self-correction module, also known as the Conv. Self-correction model, plays an important role in the segmentation framework by allowing the model to correct its own mistakes and improve its performance. This is achieved by introducing a bounding box encoder into the existing encoder-decoder segmentation model, which embeds the box information. The output of the bounding box encoder after passing through a sigmoid activation acts as an attention map. Feature maps at different scales from the encoder are fused (using element-wise-multiplication) with attention maps, then"
  },
  "6": {
    "question": "What is the purpose of the ancillary heatmap shown in this paper?",
    "ground_truth": "The ancillary heatmap is used to correct the labels for missing or oversegmented objects in the images.",
    "selected_figures": [
      "1811.07073v3-Table1-1.png",
      "1811.07073v3-Figure3-1.png",
      "1811.07073v3-Table4-1.png",
      "1811.07073v3-Table3-1.png",
      "1811.07073v3-Table2-1.png",
      "1811.07073v3-Figure4-1.png",
      "1811.07073v3-Figure5-1.png",
      "1811.07073v3-Figure2-1.png"
    ],
    "answer": "The purpose of the ancillary heatmap shown in this paper is to demonstrate the effectiveness of the proposed semi-supervised segmentation model in correcting the labels for missing or oversegmented objects in the PASCAL VOC 2012 auxiliary (the weak set). <s>"
  }
}