image_path,true_label,predicted_label,true_answer,predicted_answer,model_name
OverheatData/OverheatData\1901.00056v2\1901.00056v2-Figure2-1.png,511,489," The four steps involved in the synonym discovery process are: 

1. **Entity representation learning:** Learn entity representations from the corpus using WEMBED.
2. **NN search:** Perform a nearest neighbor search to find candidate entities for the query entity.
3. **Synonym score calculation:** Calculate the synonym score between the query entity and each candidate entity using SYNONYM NET.
4. **Synonym entity discovery:** Select the candidate entities with the highest synonym scores as the discovered synonym entities.","An overlapping case is when multiple aspects share the same opinion snippet, while an error case is when the model incorrectly identifies an aspect or opinion.",resnet50
OverheatData/OverheatData\1709.08294v3\1709.08294v3-Table3-1.png,626,417,The two-way AdaQA model significantly outperforms the one-way AdaQA model and all other CNN-based baseline models on the WikiQA dataset. This is evident from the higher MAP and MRR values achieved by the two-way model (0.7107 and 0.7304 respectively) compared to the one-way model (0.7005 and 0.7161) and the baseline models.,ChoiceNet.,resnet50
OverheatData/OverheatData\1803.01128v3\1803.01128v3-Table1-1.png,76,411,"Seq2Sick differs from existing attack methods in two key aspects:

1. Search Strategy: While previous methods primarily rely on greedy search, which becomes increasingly inefficient for longer sequences, Seq2Sick employs group lasso regularization and projected gradient descent with gradient regularization. This allows for simultaneous searching of all replacement positions, leading to improved efficiency.

2. Targeted Attack Type: Existing methods focus on targeting specific classes or binary classifications, while Seq2Sick introduces a novel ""keyword"" target type, allowing attacks to be directed towards specific keywords within the generated sequence.","Multi-X performed worse than PEARL in test case (6), with a misclassification error of 21.72% compared to PEARL's 17.35%. ",resnet50
OverheatData/OverheatData\1708.03797v1\1708.03797v1-Figure1-1.png,583,49,The code layer is responsible for generating a compressed representation of the input data. This compressed representation is then used by the decoder to reconstruct the original data.,RCV1,resnet50
OverheatData/OverheatData\1704.07854v4\1704.07854v4-Figure15-1.png,218,97,The corrected gradient method leads to a more stable and lower loss value during training.,Devon.,resnet50
OverheatData/OverheatData\1704.08615v2\1704.08615v2-Figure6-1.png,231,532,The CC score increases as the number of fixations increases.,The accuracy of the model increased from 66.7% to 100% as the iterations progressed.,resnet50
OverheatData/OverheatData\1706.00633v4\1706.00633v4-Table3-1.png,393,479,RCE,The DUT-OMRON dataset is likely the most challenging for a model trained on MSRA-B.,resnet50
OverheatData/OverheatData\1811.09393v4\1811.09393v4-Figure19-1.png,359,404,The user study is designed to test which of two images is closer to a reference video.,The quality of the reconstructed frames increases monotonically as the resolution increases.,resnet50
OverheatData/OverheatData\1809.03149v2\1809.03149v2-Figure2-1.png,597,139,The Higher Level Policy sets constraints for the next sub-trajectory and provides information about the previous stage to the Lower Level Policy.,The inputs to the image generation network are the observed images (x) and a random noise vector (z).,resnet50
OverheatData/OverheatData\1809.02731v3\1809.02731v3-Table1-1.png,593,473,"The UMBC News corpus has more sentences, by approximately 60.5 million.",ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.,resnet50
OverheatData/OverheatData\1811.08257v1\1811.08257v1-Figure1-1.png,296,552,The activation layer applies a non-linear function to the output of the convolution layer. This allows the network to learn more complex features from the data.,LSH-E,resnet50
OverheatData/OverheatData\1704.07854v4\1704.07854v4-Figure2-1.png,222,416,The parameter network is used to infer a weighting function.,The ChoiceNet model performs poorly on datasets with uniform corruptions.,resnet50
OverheatData/OverheatData\1703.07015v3\1703.07015v3-Figure3-1.png,124,67,The Traffic dataset.,ALOQ,resnet50
OverheatData/OverheatData\1804.00863v3\1804.00863v3-Figure1-1.png,189,467,The sphere in the re-synthesis using DAMs appears to have a more even and consistent surface texture than the reference image.," The Zhou \textit{et al.} method suffers from a ""zoom-in-and-out"" effect, while the Chen \textit{et al.} method produces lip shapes that differ from the real ones.",resnet50
OverheatData/OverheatData\1804.07931v2\1804.07931v2-Figure2-1.png,279,508,The two auxiliary tasks are CTR and CTCVR.,"The AUC and MAP values initially increase with increasing margin, but then decrease after a certain point.",resnet50
OverheatData/OverheatData\1809.00263v5\1809.00263v5-Figure4-1.png,544,618,The residual connections add the output of the previous layer to the input of the next layer. This helps to improve the flow of information through the network and can help to prevent vanishing gradients.,"The graph diameter generally decreases with increasing average degree for all methods and datasets. However, the rate of decrease and the final diameter value vary depending on the method and dataset.",resnet50
OverheatData/OverheatData\1708.01425v4\1708.01425v4-Table2-1.png,565,307,Intra-warrant attention with context.,"The Scholar + w.v. model achieves the best NPMI scores (both internal and external) in the unsupervised setting. However, this model also has the highest number of people parameters, indicating a trade-off between topic coherence and model complexity.",resnet50
OverheatData/OverheatData\1703.10730v2\1703.10730v2-Figure13-1.png,138,39,The input patches are used to generate the images. The generator network takes the input patches as input and generates new images that are similar to the input patches.,"The reconstructed faces in the ""Mean Reconstruction"" are smoother and less detailed than those in the ""Sampled Reconstruction"". This is because the mean reconstruction is based on the average of all the possible reconstructions, while the sampled reconstruction is based on a single sample from the distribution.",resnet50
OverheatData/OverheatData\1803.01128v3\1803.01128v3-Table4-1.png,78,185,The difficulty of performing a successful targeted keywords attack increases as the number of targeted keywords increases.,"The MLP-IQA model achieved the highest accuracy across all embedding methods, reaching 52.5% with GloVe, 51.4% with Translation embeddings, and 52.0% with word2vec. However, the passage notes that there was no significant difference in performance between the different embedding methods.",resnet50
OverheatData/OverheatData\1707.08608v3\1707.08608v3-Table4-1.png,535,478,Beam search with a width of 9 consistently leads to the highest F1 score on the failure set across all three networks.,F-DSS,resnet50
OverheatData/OverheatData\1710.05654v2\1710.05654v2-Figure5-1.png,614,223,The log model.,Only the full method with a deformation network is able to produce a perfect reconstruction.,resnet50
OverheatData/OverheatData\1804.05936v2\1804.05936v2-Figure1-1.png,248,520,The GRU is used to process the ranked list of documents provided by a global ranking function.,(a) ZDDA simulates the target-domain representation using the source-domain data.,resnet50
OverheatData/OverheatData\1704.08615v2\1704.08615v2-Figure5-1.png,232,2,The fixation density map predicts the probability of a person fixating on a particular location in the image. The ground truth fixations are the actual locations where people fixated on the image.,KEHNN,resnet50
OverheatData/OverheatData\1811.02721v3\1811.02721v3-Table9-1.png,214,304,"The TCP stack presented in this paper (TCPlp) provides the most complete implementation of core TCP features, including flow control, congestion control, RTT estimation, MSS option, OOO reassembly, and various advanced features like timestamps and selective ACKs. In contrast, BLIP lacks the most features, as it does not implement congestion control, RTT estimation, or several other functionalities present in other stacks.","The DR-SVM method achieved the lowest regret in Ex. 2, with a regret of 0.18.",resnet50
OverheatData/OverheatData\1809.02731v3\1809.02731v3-Table3-1.png,594,324,The Bijective model performs the best on the STS16 task with unsupervised training.,"Both TF-IDF and BM25 are features used to estimate the relevance of a document to a query. However, they differ in their underlying calculations.

TF-IDF: This feature represents the average product of term frequency (TF) and inverse document frequency (IDF) for each query term within different document sections (URL, title, content, and whole document). TF measures how often a term appears in a specific document section, while IDF measures how important that term is across the entire document collection.

BM25: This feature utilizes the BM25 ranking function, which is a probabilistic model that considers term frequency, document length, and average document length to estimate relevance. While it also considers term frequency like TF-IDF, it incorporates additional factors to improve the weighting scheme.",resnet50
OverheatData/OverheatData\1802.07459v2\1802.07459v2-Figure2-1.png,103,402,"The different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents are: (a) Representation, (b) Encoding, (c) Transformation, and (d) Aggregation.",The proposed model delivers significantly better visual quality at low bitrates than H.264.,resnet50
OverheatData/OverheatData\1812.00281v3\1812.00281v3-Table8-1.png,439,2,Training with UP-3D + HUMBI resulted in the lowest prediction error for both UP-3D and HUMBI test sets.,KEHNN,resnet50
OverheatData/OverheatData\1811.10673v1\1811.10673v1-Figure2-1.png,399,111,The second-stage decoder $D_2$ takes soft edges $x_G$ as input and produces reconstructed frames.,The RR optimization helps to reduce the number of messages that need to be exchanged between replicas.,resnet50
OverheatData/OverheatData\1809.01989v2\1809.01989v2-Table1-1.png,646,12,"The Ridge method achieved the lowest sum of absolute percentage errors (136.84), indicating the highest tracking accuracy in terms of minimizing absolute deviations from the index. However, this doesn't necessarily translate to the best overall performance.",DMRNet,resnet50
OverheatData/OverheatData\1809.01246v1\1809.01246v1-TableI-1.png,580,262,GSS (no sampling),The bounding box encoder network embeds bounding box information at different scales and outputs attention maps that are used to fuse with feature maps from the encoder before being passed to the decoder.,resnet50
OverheatData/OverheatData\1803.06506v3\1803.06506v3-Figure2-1.png,164,447,The Joint Attention Module takes the embedded image and phrase features as input and uses them to induce a parameterization for spatial attention. This spatial attention map is then used by the decoder to predict the common concept.,GRU4Rec has a slightly higher performance than the baseline in terms of watch time.,resnet50
OverheatData/OverheatData\1710.06177v2\1710.06177v2-Table1-1.png,634,536,"VAGER+Voting consistently outperforms all other VAGER variants in both 1-shot and 20-shot settings, achieving the highest AUC and F1 scores.","GBI is more effective than A* in reducing the disagreement rate on the SRL-100 network's failure set. After applying GBI, the average disagreement rate drops to 24.92%, while A* only reduces it to 33.91%. This represents an 19.93% greater reduction in disagreement rate when using GBI compared to A*.",resnet50
OverheatData/OverheatData\1812.10735v2\1812.10735v2-Table1-1.png,490,408,Rest14 has a higher proportion of sentences containing multiple aspects compared to Rest15.,Multi-X,resnet50
OverheatData/OverheatData\1605.07496v3\1605.07496v3-Figure3-1.png,66,121,ALOQ.,The hierarchical part dictionary learned with the bottom-up process is a set of parts that can be combined to create objects. The holistic object model learned with the top-down process is a single model that represents the entire object.,resnet50
OverheatData/OverheatData\1708.03797v1\1708.03797v1-Table2-1.png,584,322,HDMF achieved the best overall performance.,"The DNN trained with DLA achieved the best performance in terms of both nDCG@10 (0.421) and ERR@10 (0.582). Compared to not using any correction method (NoCorrect), DLA shows a significant improvement in both metrics, with nDCG@10 being higher by 0.063 and ERR@10 being higher by 0.082.",resnet50
OverheatData/OverheatData\1805.06431v4\1805.06431v4-Figure14-1.png,422,312,The WideResNet model has higher accuracy than the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle.,BoSsNet,resnet50
OverheatData/OverheatData\1704.05426v4\1704.05426v4-Table3-1.png,158,123,"The genre with the highest percentage of 'S' parses is **9/11**, with **99%** of its sentences receiving this parse. This is higher than the overall average for the MultiNLI corpus, which sits at **91%**.","When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",resnet50
OverheatData/OverheatData\1705.09966v2\1705.09966v2-Figure13-1.png,344,543,The input is a low-resolution frontal face image and a high-resolution side-face image. The output is a high-resolution frontal face image.,The sliding tendency of SepConv will cause motion errors and high LMS.,resnet50
OverheatData/OverheatData\1809.00263v5\1809.00263v5-Figure6-1.png,545,245,The sampled vector is element-wise multiplied by the feature map of $\sigma$ and added to the feature map of $\mu$.,The fusion modules are used to combine the outputs of the interactive alignment and self-alignment modules.,resnet50
OverheatData/OverheatData\1710.05654v2\1710.05654v2-Figure15-1.png,610,205,The time needed for learning a graph with a subset of allowed edges $\mathcal{E}^\text{allowed}$ increases linearly as the number of edges per node increases.,"Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point.",resnet50
OverheatData/OverheatData\1703.10730v2\1703.10730v2-Figure7-1.png,137,345,"The network initially focuses on predicting a good mask. As the epoch increases, the input parts become sharper. Finally, the network concentrates on generating realistic images.","The proposed method utilizes Light-CNN as both the source of the identity features and face verification loss. This allows the method to transfer the appearance of eyes, eyebrows, hairs, etc., while keeping other factors intact, e.g., head pose, shape of face, and facial expression.",resnet50
OverheatData/OverheatData\1702.03584v3\1702.03584v3-Figure2-1.png,99,508,SPIRAL-DTW-kMeans performs better than k-Shape and CLDS on most datasets.,"The AUC and MAP values initially increase with increasing margin, but then decrease after a certain point.",resnet50
OverheatData/OverheatData\1805.06431v4\1805.06431v4-Table15-1.png,421,596,"When there is no label corruption (p = 0%), Mixup achieves the highest test accuracy of 79.77%. However, as the corruption level increases, Mixup's performance deteriorates more rapidly compared to other methods. ChoiceNet, on the other hand, demonstrates a more stable performance across different corruption levels, maintaining the highest accuracy when p is 10%, 20%, 30%, and 40%.","The advertising rate for the ""Fix"" curve is lower than the ""Oracle"" curve at hour 14.",resnet50
OverheatData/OverheatData\1804.05936v2\1804.05936v2-Table4-1.png,252,638,"LambdaMART initial list, DLCM model, and AttRank loss function achieved the best overall performance on the Yahoo! set 1, with an nDCG@10 of 0.743 and an ERR@10 of 0.453.","The top-3 most similar base classes are the three classes that are most similar to the novel class, based on the embedding layer in a 5-shot setting.",resnet50
OverheatData/OverheatData\1809.00458v1\1809.00458v1-TableI-1.png,554,356,"The Jaccard similarity measures the overlap between two sets, while the containment similarity measures how much one set is contained within another set.",5.00E-05,resnet50
OverheatData/OverheatData\1804.07849v4\1804.07849v4-Table3-1.png,256,100,Variational J^var (7),The SPIRAL-MSM-kMeans method performs the best in terms of NMI with a score of 0.365. It outperforms the other methods on 89.4% of the datasets.,resnet50
OverheatData/OverheatData\1804.05936v2\1804.05936v2-Figure4-1.png,251,358,LambdaMART,The UVT cycle link is used to transfer knowledge between two recurrent generators.,resnet50
OverheatData/OverheatData\1805.04687v2\1805.04687v2-Table1-1.png,387,430,BDD100K,The Multi-DPP module increases diversity within the selected time-steps by using a determinantal point process (DPP) to select a subset of diverse time-steps from the input sequence.,resnet50
OverheatData/OverheatData\1805.07567v2\1805.07567v2-Table4-1.png,482,536,"The FLoss method performs better than the balanced cross-entropy loss because it can automatically adjust to data imbalance using the F-measure criterion, while the balanced cross-entropy loss relies on pre-defined weights for positive and negative samples.","GBI is more effective than A* in reducing the disagreement rate on the SRL-100 network's failure set. After applying GBI, the average disagreement rate drops to 24.92%, while A* only reduces it to 33.91%. This represents an 19.93% greater reduction in disagreement rate when using GBI compared to A*.",resnet50
OverheatData/OverheatData\1705.02946v3\1705.02946v3-Table1-1.png,267,443,O(n^3 / ε),The decoder is responsible for generating the final 3D mesh from the intermediate representations produced by the regression network.,resnet50
OverheatData/OverheatData\1706.03847v3\1706.03847v3-Table2-1.png,446,607,The highest Recall@20 score was achieved by the GRU4Rec with additional samples and BPR-max loss function on the RSC15 dataset. This score was 42.37% higher than the Recall@20 score of the original GRU4Rec model on the same dataset.,KAR,resnet50
OverheatData/OverheatData\1804.07849v4\1804.07849v4-Table4-1.png,255,420,"The Variational $\wh{J}^{\mathrm{var}}$ method achieved the highest average VM score (50.4). Its average score is 39.6 points higher than the Baum-Welch method, which achieved an average VM score of 10.8.",ChoiceNet appears to be the most robust to outliers in the training data.,resnet50
OverheatData/OverheatData\1803.04572v2\1803.04572v2-Figure8-1.png,151,581,"The temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients in terms of both shape and magnitude. For sickle cell anemia patients, the patterns are generally smoother and more periodic, with lower overall magnitude. For leukemia patients, the patterns are more erratic and have higher overall magnitude.",The average precision of TCM(256*memory) is lower than the other two algorithms in the email-EuAll dataset.,resnet50
OverheatData/OverheatData\1705.10667v4\1705.10667v4-Figure3-1.png,363,508,CDAN-fg,"The AUC and MAP values initially increase with increasing margin, but then decrease after a certain point.",resnet50
OverheatData/OverheatData\1705.09882v2\1705.09882v2-Figure5-1.png,331,636,The proposed RGB-to-Depth transfer performs slightly better than Yosinski et al. [90] in terms of top-1 accuracy on DPI-T when all layers are fine-tuned.,There is a positive linear relationship between the Similarity Ratio and AUC Increasing.,resnet50
OverheatData/OverheatData\1805.04687v2\1805.04687v2-Table8-1.png,379,194,"The **Sem-Seg + Det** approach achieved the highest mean IoU of 58.3, which is an improvement of 1.4 points compared to the baseline Sem-Seg model with a mean IoU of 56.9.",The representation error decreases as the gloss decreases.,resnet50
OverheatData/OverheatData\1706.00633v4\1706.00633v4-Figure1-1.png,395,153," The non-ME metric measures the entropy of the normalized non-maximal elements in the final hidden vector of the classifier. Adversarial examples often have low non-ME values, indicating that they are close to the decision boundary and have high confidence in the incorrect class.",COPA is faster than Helwig.,resnet50
OverheatData/OverheatData\1709.02755v5\1709.02755v5-Table2-1.png,587,419,The SRU model outperforms the LSTM model in both accuracy and training speed on the SQuAD dataset.,"As the corruption level increases, the performance of all models decreases. However, ChoiceNet consistently outperforms both ConvNet and ConvNet+Mixup across all corruption levels, maintaining high accuracy even when almost half of the labels are incorrect. This suggests that ChoiceNet is significantly more robust to label corruption compared to the other models.",resnet50
OverheatData/OverheatData\1809.04276v2\1809.04276v2-Table1-1.png,640,226,"The model is discouraged because it is trained using the Maximum Likelihood Estimation (MLE) objective, which prioritizes generating responses that are identical to the ground-truth (GT) response. Even though the RSP integrates relevant content from the candidates and seems appropriate in the context, it is penalized because it deviates from the exact wording of the GT.",The RL policy accesses fewer index blocks than the baseline.,resnet50
OverheatData/OverheatData\1803.04572v2\1803.04572v2-Table7-1.png,149,97,"According to the table, some common medications used to treat Sickle Cell Anemia include:

Beta-adrenergic agents
Analgesics (narcotics and non-narcotics)
NSAIDs (cyclooxygenase inhibitor - type)
Potassium replacement
Sodium/saline preparations
General inhalation agents
Laxatives and cathartics
IV solutions (dextrose-saline)
Antiemetic/antivertigo agents
Sedative-hypnotics (non-barbiturate)
Glucocorticoids (orally inhaled)
Folic acid preparations
Analgesic narcotic anesthetic adjunct agents",Devon.,resnet50
OverheatData/OverheatData\1701.06171v4\1701.06171v4-Figure2-1.png,120,635,The variables in the Compositional Active Basis Model are hierarchically dependent. The variables at each layer are dependent on the variables at the layer above it.,"VAGER leverages transfer learning, while LR does not. This means VAGER attempts to apply knowledge from other classes to improve its performance on new classes. For nine out of the ten novel classes, this strategy seems to be successful, as VAGER consistently outperforms LR. However, for the ""Bubble"" class, the transfer learning approach seems to have a negative impact, causing VAGER to perform worse than LR.",resnet50
OverheatData/OverheatData\1706.00827v2\1706.00827v2-Table1-1.png,407,249,Multi-X achieved the most accurate results for simultaneous line and circle fitting.,The NegPair reduction generally increases as the number of perfect results in a query increases.,resnet50
OverheatData/OverheatData\1705.09882v2\1705.09882v2-Table1-1.png,325,617,"The proposed method with RTA attention achieves the highest Top-1 Accuracy for multi-shot person re-identification on the BIWI dataset with a score of 50.0%. This is significantly higher than the best single-shot method on the same dataset, which is our method (CNN) with a score of 25.4%.",The learned graph assigns weights that correspond much better to the relevance of the terms compared to k-NN and A-NN graphs.,resnet50
OverheatData/OverheatData\1811.02721v3\1811.02721v3-Table8-1.png,211,315,"The protocol implementation module consumes the most memory in the active RAM on TinyOS, utilizing 488 bytes.","The multi-hop encoder performs better on bAbI tasks 3 and 5 because these tasks specifically require inferencing over multiple KB tuples. In other words, the model needs to ""hop"" between different pieces of information in the knowledge base to make the correct inferences and recommendations.

Task 3 involves sorting restaurants by rating, and task 5 requires recommending a restaurant based on user preferences. Both tasks necessitate the model to consider various restaurant attributes and their relationships, which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base.",resnet50
OverheatData/OverheatData\1812.06589v2\1812.06589v2-Table3-1.png,462,34,"Adding DA to the baseline method improves the PSNR and SSIM values, while slightly decreasing the LMD value.",Pre-training with the ordering task increases the ROUGE-L score for extractive summarization.,resnet50
OverheatData/OverheatData\1612.02803v5\1612.02803v5-Figure1-1.png,73,71,"The equation that describes the motion of a mass attached to a spring is:
```
m d^2 X / dt^2 + kX = 0
```
where:
* m is the mass of the object
* X is the displacement of the object from its equilibrium position
* k is the spring constant
* t is time","The ""True max"" curve is the true maximum of the function, while the ""ALOQ"" curve is an approximation of the maximum. The ""ALOQ"" curve is lower than the ""True max"" curve, indicating that it underestimates the maximum value of the function.",resnet50
OverheatData/OverheatData\1611.04684v1\1611.04684v1-Table1-1.png,0,226,"The Bonaparte school focuses on outdoor physical activities, maneuvers, and strategies, with a specialization in horse riding, lances, and swords. They aim to develop students into good leaders. The Voltaire school, on the other hand, encourages independent thinking and focuses on indoor activities. They aim to instill good moral values and develop students into philosophical thinkers.",The RL policy accesses fewer index blocks than the baseline.,resnet50
OverheatData/OverheatData\1812.00281v3\1812.00281v3-Figure15-1.png,436,345,The results of the monocular 3D body prediction network trained with different dataset combinations show that the Up3d+HUMBI dataset combination produces the most accurate results. This is evident in the images where the predicted 3D body poses are closer to the ground-truth poses than the other dataset combinations.,"The proposed method utilizes Light-CNN as both the source of the identity features and face verification loss. This allows the method to transfer the appearance of eyes, eyebrows, hairs, etc., while keeping other factors intact, e.g., head pose, shape of face, and facial expression.",resnet50
OverheatData/OverheatData\1707.06320v2\1707.06320v2-Table2-1.png,526,123,"GroundSent-Cap appears to be most beneficial for the MRPC task, achieving an accuracy of 72.9/82.2 compared to the baseline model ST-LN's 69.6/81.2.","When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",resnet50
OverheatData/OverheatData\1611.03780v2\1611.03780v2-Figure1-1.png,17,306,"The Hilbert space-filling curve is constructed recursively. The curve starts with a simple square, and then at each subsequent iteration, the curve is subdivided into four smaller squares. The curve is then drawn through each of these squares in a specific order.",The node labeled η represents the latent variable.,resnet50
OverheatData/OverheatData\1803.01128v3\1803.01128v3-Table6-1.png,80,538,"No, adversarial examples generated with the 2-keyword constraint deviate significantly from the original syntactic structure.",All features have the same dimensionality in the first two dimensions.,resnet50
OverheatData/OverheatData\1703.04887v4\1703.04887v4-Table2-1.png,133,473,"BR-CSGAN consistently outperforms MRT on both Chinese-English and English-German translation tasks, achieving higher BLEU scores.

While both methods optimize similar objectives, BR-CSGAN uses a reinforcement learning procedure with a dynamic discriminator to maximize rewards for the generator. This dynamic feedback seems to be more effective than the static objective and random sampling approach used by MRT, leading to better translation performance.",ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.,resnet50
OverheatData/OverheatData\1706.04269v2\1706.04269v2-Figure5-1.png,455,204,Action Search uses temporal context to reason about where to search next by looking at the frames before and after the current frame. This allows the model to learn the temporal patterns of actions and to predict where the action is most likely to occur in the next frame.,"Relying on fragmentation is effective because the TCP/IP headers are only included in the first fragment, not in subsequent fragments. This significantly reduces the overhead in later fragments.",resnet50
OverheatData/OverheatData\1901.00056v2\1901.00056v2-Table5-1.png,507,347,The range of values for the context number hyperparameter is from 1 to 20.,The attribute vector $z$ provides additional information about the desired attributes of the generated high-resolution face image $\hat{X}$. This information is used by the generator networks $G_{X \to Y}$ and $G_{Y \to X}$ to generate images that are more consistent with the desired attributes.,resnet50
OverheatData/OverheatData\1803.04383v2\1803.04383v2-Figure5-1.png,178,489,The maximum profit criteria ($\maxprof$) results in the highest loan approval rate for the Black group when the loss/profit ratio is -4.,"An overlapping case is when multiple aspects share the same opinion snippet, while an error case is when the model incorrectly identifies an aspect or opinion.",resnet50
OverheatData/OverheatData\1707.00524v2\1707.00524v2-Figure3-1.png,487,516,"The predicted frame is generated by the prediction model, while the reconstructed frame is generated by the autoencoder. The predicted frame is typically more accurate than the reconstructed frame, as the prediction model is trained to predict the future state of the environment, while the autoencoder is only trained to reconstruct the input image.",ZDDA3,resnet50
OverheatData/OverheatData\1701.03077v10\1701.03077v10-Figure8-1.png,45,450,"The authors chose to use a nonlinearity to curve α before fitting the cubic hermite spline because it allows for increased knot density near α = 2 and decreased knot density when α > 4. This helps to better approximate the log partition function, which is difficult to evaluate for arbitrary inputs.",The training time of all losses increases as the number of additional samples increases.,resnet50
OverheatData/OverheatData\1708.01425v4\1708.01425v4-Table1-1.png,567,96,"Step 4, Reason disambiguation.","PWC-Net (ft) performs best on the Sintel ""Final"" test set with an error of 5.04. Devon (ft) has a higher error of 6.35 on the same set. ",resnet50
OverheatData/OverheatData\1901.00056v2\1901.00056v2-Table4-1.png,513,536,The largest performance gap is observed in the PubMed + UMLS dataset using the F1@K metric with K=1.,"GBI is more effective than A* in reducing the disagreement rate on the SRL-100 network's failure set. After applying GBI, the average disagreement rate drops to 24.92%, while A* only reduces it to 33.91%. This represents an 19.93% greater reduction in disagreement rate when using GBI compared to A*.",resnet50
OverheatData/OverheatData\1705.07164v8\1705.07164v8-Table1-1.png,271,56,"The Euclidean Bregman cost function is simply the squared difference between two points, while the Mahalanobis Bregman cost function takes into account the covariance of the data.",The complexity of the cake shape generally leads to a higher minimum number of blanks required for a complete partition.,resnet50
OverheatData/OverheatData\1803.04572v2\1803.04572v2-Figure3-1.png,148,205,The smoothness constraint on $\M{U_k}$ has the most significant impact on the FIT values for the CMS data set when the target rank is 15.,"Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point.",resnet50
OverheatData/OverheatData\1811.09393v4\1811.09393v4-Figure2-1.png,354,30,"The Motion Compensation block estimates the motion between the previous frame and the current frame, and uses this information to warp the previous frame to the current frame. This helps the generator to produce more realistic images by taking into account the temporal information in the video sequence.",The input space and the output space are related by a cosine similarity measure.,resnet50
OverheatData/OverheatData\1701.03077v10\1701.03077v10-Figure13-1.png,46,225,The range of values for the shape parameter α is from 0 to 2.,"Documents are first matched using a pre-defined match plan. Then, they are passed through additional rank-and-prune stages, which are implemented as a cascade of machine learning models.",resnet50
OverheatData/OverheatData\1811.09393v4\1811.09393v4-Figure4-1.png,352,520," The warped triplets provide additional information about the motion and appearance of the scene, which helps the VSR Ds,t to generate more accurate and realistic results.",(a) ZDDA simulates the target-domain representation using the source-domain data.,resnet50
OverheatData/OverheatData\1809.01246v1\1809.01246v1-Figure11-1.png,577,579,"The ARE of node queries generally decreases as the width increases for all configurations of GSS and TCM. However, there are some fluctuations in the ARE for some configurations.",The graph for the Caida-networkflow dataset shows the largest improvement in accuracy for the TCM(8*memory) method compared to the GSS(fsize=12) method.,resnet50
OverheatData/OverheatData\1708.05239v3\1708.05239v3-Figure9-1.png,572,574,PE-HMC (N=5),"Square hashing is a process that uses two hash functions to map a source/destination pair to a bucket in a two-dimensional array. The first hash function, h_i(s), maps the source address to a row in the array, and the second hash function, h_i(d), maps the destination address to a column in the array. The intersection of the row and column is the bucket where the fingerprint is stored.",resnet50
OverheatData/OverheatData\1707.01922v5\1707.01922v5-Figure1-1.png,517,306,The task-irrelevant data is used to simulate the RGB representation using the gray scale image. This allows ZDDA to learn a joint network that can be used to classify digits in both the gray scale and RGB domains.,The node labeled η represents the latent variable.,resnet50
OverheatData/OverheatData\1809.00458v1\1809.00458v1-Figure19-1.png,559,175,The running time of GB-KM increases as the F-1 score increases.,"The outcome curve for the black group is generally lower than the outcome curve for the white group. This indicates that, for a given selection rate, the black group experiences a smaller change in credit score than the white group.",resnet50
OverheatData/OverheatData\1603.03833v4\1603.03833v4-Table1-1.png,60,369,"The passage mentions that additional trajectories were generated for the ""Pick and Place"" task by reducing the frequency of the recorded demonstrations. This process was not applied to the ""Push to Pose"" task, therefore no ""Demonstrations after shift"" are listed for it.",Cars have the largest total number of annotations.,resnet50
OverheatData/OverheatData\1805.01216v3\1805.01216v3-Figure1-1.png,312,98,BoSsNet,"The observed error is initially higher than the underlying true error, but it quickly decreases and converges to the true error as CPU time increases.",resnet50
OverheatData/OverheatData\1809.00458v1\1809.00458v1-Figure18-1.png,551,521,GB-KMV,The human evaluators were more accurate at identifying human-written reviews than machine-generated reviews.,resnet50
OverheatData/OverheatData\1701.03077v10\1701.03077v10-Figure17-1.png,51,467,The proposed method appears to be more accurate than the baseline method. The depth maps generated by the proposed method are more detailed and realistic than those generated by the baseline method.," The Zhou \textit{et al.} method suffers from a ""zoom-in-and-out"" effect, while the Chen \textit{et al.} method produces lip shapes that differ from the real ones.",resnet50
OverheatData/OverheatData\1901.00056v2\1901.00056v2-Figure1-1.png,512,262,The Leaky Unit helps to aggregate the context information from different sources and allows the model to learn the relationships between entities and their contexts.,The bounding box encoder network embeds bounding box information at different scales and outputs attention maps that are used to fuse with feature maps from the encoder before being passed to the decoder.,resnet50
OverheatData/OverheatData\1802.07351v2\1802.07351v2-Figure3-1.png,93,562,The relation module (Rt) is responsible for capturing the spatial relationships between the features extracted from the first and second images.,GB-KMV performs better than LSH-E in terms of F1 Score and Precision.,resnet50
OverheatData/OverheatData\1707.01917v2\1707.01917v2-Table5-1.png,499,203,TFBA,"TCP performs poorly on IEEE 802.15.4 networks because the Maximum Transmission Unit (MTU) for these networks is significantly smaller than other network types. This small MTU size results in a high percentage of overhead due to the TCP/IP headers, exceeding 50%. ",resnet50
OverheatData/OverheatData\1805.04687v2\1805.04687v2-Table10-1.png,375,412,"The proposed dataset contains non-city scenes like highways, which typically have fewer pedestrians per image compared to cityscapes.",The Mean-Shift algorithm is robust to outliers.,resnet50
OverheatData/OverheatData\1805.06431v4\1805.06431v4-Table7-1.png,414,527,"ChoiceNet appears to be the safest method for autonomous driving on straight lanes, regardless of the percentage of outlier vehicles present.","The GroundSent-Both model performs best on the SNLI dataset, achieving an accuracy of 72.0%. Grounding contributes to an improvement of 4.7% compared to the baseline STb-1024 model, which achieves 67.3%.",resnet50
OverheatData/OverheatData\1805.00912v4\1805.00912v4-Figure1-1.png,299,629,MTSA,"ACNN performs best on ""Who"" questions.",resnet50
OverheatData/OverheatData\1805.06447v3\1805.06447v3-Table5-1.png,471,570,ITN (ResNet-32) with data augmentation performs best on the CIFAR-10 dataset with a testing error of 5.82%.,"LIME appears to place the most emphasis on specific, localized features.",resnet50
OverheatData/OverheatData\1706.00633v4\1706.00633v4-Table2-1.png,389,24,RCE training combined with the K-density metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types.,"The WeakFG method achieved the highest P@1 score for the QA-Expert task with a score of 52.8. This is 23.2% higher than the average P@1 score of the D2V method, which was 29.6. ",resnet50
OverheatData/OverheatData\1701.06171v4\1701.06171v4-Figure4-1.png,119,57,22 iterations," 

In 2-D division, there may be unallocated cake even when there are geometric constraints on the pieces, as shown in Figure 1. This is not the case in 1-D division, where the entire cake can always be allocated.",resnet50
OverheatData/OverheatData\1706.04284v3\1706.04284v3-Figure5-1.png,458,21," The denoiser trained with the classification network and evaluated for semantic segmentation performs the best on the sheep image. This is because the segmentation label map for this denoiser is the most accurate, and it correctly identifies the sheep's body and legs. ","Paris, Bordeaux, and Lyon.",resnet50
OverheatData/OverheatData\1809.03149v2\1809.03149v2-Figure3-1.png,599,87,The percentage of ads displayed for each user is higher when CHER is used.,"The residual connection allows the output of a layer to be added to the output of another layer, which helps to improve the flow of information through the network.",resnet50
OverheatData/OverheatData\1707.08608v3\1707.08608v3-Table11-1.png,530,555,"The PT genre within the SRL-NW network has the lowest failure rate at 10.01%. Its inference time is also the lowest across all genres in the SRL-NW network for all three inference procedures (Viterbi, GBI, and A*).",REUTERS,resnet50
OverheatData/OverheatData\1811.07073v3\1811.07073v3-Figure3-1.png,260,430,The input to the convolutional self-correction model is the logits generated by the primary and ancillary models.,The Multi-DPP module increases diversity within the selected time-steps by using a determinantal point process (DPP) to select a subset of diverse time-steps from the input sequence.,resnet50
OverheatData/OverheatData\1809.01246v1\1809.01246v1-Figure13-1.png,575,486,The buffer percentage decreases as the width of the room increases.,Pacman,resnet50
OverheatData/OverheatData\1809.03449v3\1809.03449v3-Figure1-1.png,608,452,"The Knowledge Aided Similarity Matrix is used to compute the similarity between the question and passage context embeddings. This similarity score is then used to weight the passage context embeddings, giving more weight to those parts of the passage that are most relevant to the question.",The addition of negative samples increases the gradient of BPR and BPR-max with respect to the target score.,resnet50
OverheatData/OverheatData\1805.04687v2\1805.04687v2-Table9-1.png,380,365,"The training approach ""Det + T + I + S"" achieved the best balance between minimizing false negatives (FN) and false positives (FP) in object detection, while also maintaining a high MOTSA score.",The table shows that CDAN+E (w/o random sampling) achieves the highest average accuracy of 87.7% across all domain adaptation tasks. This is slightly higher than the performance of CDAN+E with uniform sampling (87.0%) and Gaussian sampling (86.4%).,resnet50
OverheatData/OverheatData\1803.02750v3\1803.02750v3-Figure8-1.png,115,451,Mesh,VIDXL has the highest Recall@20 and MRR@20.,resnet50
OverheatData/OverheatData\1811.02721v3\1811.02721v3-Figure11-1.png,209,205,TCP,"Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point.",resnet50
OverheatData/OverheatData\1603.00286v5\1603.00286v5-Figure2-1.png,58,397,Six.,Downsampling reduces the quality of reconstructed frames.,resnet50
OverheatData/OverheatData\1901.00056v2\1901.00056v2-Table2-1.png,509,90,"The SYNONYMNET(Pairwise) model with Leaky Unit performs best on the PubMed + UMLS dataset, achieving an AUC of 0.9838 and a MAP of 0.9872. This is a statistically significant improvement over the DPE baseline, which achieved an AUC of 0.9513 and a MAP of 0.9623.",Removing the normalization in the relation modules had the most significant negative impact on performance for the KITTI 2015 dataset.,resnet50
OverheatData/OverheatData\1805.00912v4\1805.00912v4-Table2-1.png,301,419,The Transfer + MTSA model performed best on the SNLI test set with an accuracy of 86.9%.,"As the corruption level increases, the performance of all models decreases. However, ChoiceNet consistently outperforms both ConvNet and ConvNet+Mixup across all corruption levels, maintaining high accuracy even when almost half of the labels are incorrect. This suggests that ChoiceNet is significantly more robust to label corruption compared to the other models.",resnet50
OverheatData/OverheatData\1812.00108v4\1812.00108v4-Table3-1.png,431,633,"The performance of the model generally improves as the number of views increases. For example, when the model is trained and tested on two-view data, the F1-score is 29.67. However, when the model is trained and tested on three-view data, the F1-score increases to 30.2. This suggests that the model is able to learn more effectively from data with more views.","The AdaQA (two-way) + att. model achieves the best performance on the SelQA dataset with a MAP score of 0.9021 and an MRR score of 0.9103. Compared to the baseline CNN model from Jurczyk et al. (2016) which has a MAP score of 0.8320 and an MRR score of 0.8420, the AdaQA (two-way) + att. model demonstrates a significant improvement in both metrics.",resnet50
OverheatData/OverheatData\1804.01429v3\1804.01429v3-Figure1-1.png,195,333,"An agent-in-place action is an action that is performed by an agent in a specific place, while a generic action category is a more general category of action that does not specify the place where the action is performed.",UnCoRd-VG-E,resnet50
OverheatData/OverheatData\1812.06589v2\1812.06589v2-Figure4-1.png,465,130,"The dynamic attention block decouples the lip-related and identity-related information, allowing the network to focus on the most important area for generating realistic talking faces.",The performance of LSTNet-attn generally improves as the horizon increases on the Solar-Energy dataset. This is evident from the fact that both the RMSE and correlation values improve with increasing horizon.,resnet50
OverheatData/OverheatData\1611.07718v2\1611.07718v2-Figure2-1.png,9,70,"Deep residual networks have skip connections that allow the gradient to flow directly from one layer to another, while networks built by stacking inception-like blocks do not.","The predicted return decreases as θ increases, with a minimum at around θ = 0.5.",resnet50
OverheatData/OverheatData\1707.01917v2\1707.01917v2-Table3-1.png,495,294,The NYT Sports dataset has the highest value for λa (0.9).,FALCON is faster for both setting up and running the FC layer.,resnet50
OverheatData/OverheatData\1805.06431v4\1805.06431v4-Figure8-1.png,415,378,ChoiceNet,Cars are the most common object in the dataset.,resnet50
OverheatData/OverheatData\1611.03780v2\1611.03780v2-Figure2-1.png,19,562," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",GB-KMV performs better than LSH-E in terms of F1 Score and Precision.,resnet50
OverheatData/OverheatData\1608.02784v2\1608.02784v2-Figure6-1.png,27,94,"The SMT outputs are literal translations of the images, while the CCA outputs take into account the context of the images and generate more natural-sounding descriptions.","The five deformable cost volumes in Devon's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery. This is achieved by using different neighborhood sizes (k) and dilation rates (r) for each cost volume, as shown in Table 1. Smaller neighborhood sizes and dilation rates result in denser correspondences, focusing on finer details and small displacements, while larger values capture broader context and larger motions.",resnet50
OverheatData/OverheatData\1701.03077v10\1701.03077v10-Figure5-1.png,47,97,The performance of gFGR generally improves as the shape parameter α increases.,Devon.,resnet50
OverheatData/OverheatData\1705.02798v6\1705.02798v6-Table3-1.png,242,404,R.M.-Reader.,The quality of the reconstructed frames increases monotonically as the resolution increases.,resnet50
OverheatData/OverheatData\1805.04609v3\1805.04609v3-Figure3-1.png,360,353,US-HC-MQ,The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence.,resnet50
OverheatData/OverheatData\1611.03780v2\1611.03780v2-Table1-1.png,23,473,Both GeoCUTS and DMA perform equally well for highly active users in the US.,ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.,resnet50
OverheatData/OverheatData\1901.00398v2\1901.00398v2-Figure8-1.png,523,225,The AMT workers are being asked to decide whether each of twenty one paragraphs extracted from product reviews is real (written by a person) or fake (written by a computer algorithm).,"Documents are first matched using a pre-defined match plan. Then, they are passed through additional rank-and-prune stages, which are implemented as a cascade of machine learning models.",resnet50
OverheatData/OverheatData\1906.06589v3\1906.06589v3-Figure2-1.png,605,300,The generalization gap increases as the average X_ref entropy increases.,"The model with the highest test accuracy is MTSA, with an accuracy of 86.3%. Its training time per epoch is 180s, which is faster than the training time of several other models with lower accuracy, such as Bi-LSTM (854s), Bi-GRU (850s), and DiSA (390s).",resnet50
OverheatData/OverheatData\1811.07073v3\1811.07073v3-Figure5-1.png,264,21,The ancillary heatmap is used to correct the labels for missing or oversegmented objects in the images.,"Paris, Bordeaux, and Lyon.",resnet50
OverheatData/OverheatData\1809.00458v1\1809.00458v1-Figure5-1.png,550,152,ENRON,SPARTan converged faster in both cases of target rank.,resnet50
OverheatData/OverheatData\1803.03467v4\1803.03467v4-Table3-1.png,143,527,RippleNet*,"The GroundSent-Both model performs best on the SNLI dataset, achieving an accuracy of 72.0%. Grounding contributes to an improvement of 4.7% compared to the baseline STb-1024 model, which achieves 67.3%.",resnet50
OverheatData/OverheatData\1809.00458v1\1809.00458v1-Figure1-1.png,560,430,0.67,The Multi-DPP module increases diversity within the selected time-steps by using a determinantal point process (DPP) to select a subset of diverse time-steps from the input sequence.,resnet50
OverheatData/OverheatData\1606.07384v2\1606.07384v2-Figure2-1.png,75,473,RANSAC,ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN.,resnet50
