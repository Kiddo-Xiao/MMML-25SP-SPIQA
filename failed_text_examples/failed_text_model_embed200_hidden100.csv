paper_id,question,true_label,predicted_label,true_answer,predicted_answer,model_name
1804.07931v2,What are the two auxiliary tasks that are used in the ESMM architecture for CVR modeling?,279,64,The two auxiliary tasks are CTR and CTCVR.,"Feedforward-MSE, LSTM-MSE, and Feedforward-MDN.",text_model_embed200_hidden100
1803.03467v4,Which dataset has the highest AUC for all ripple set sizes?,146,551,MovieLens-1M,GB-KMV,text_model_embed200_hidden100
1804.05938v2,"Explain the difference between the features ""TF-IDF"" and ""BM25"".",324,215,"Both TF-IDF and BM25 are features used to estimate the relevance of a document to a query. However, they differ in their underlying calculations.

TF-IDF: This feature represents the average product of term frequency (TF) and inverse document frequency (IDF) for each query term within different document sections (URL, title, content, and whole document). TF measures how often a term appears in a specific document section, while IDF measures how important that term is across the entire document collection.

BM25: This feature utilizes the BM25 ranking function, which is a probabilistic model that considers term frequency, document length, and average document length to estimate relevance. While it also considers term frequency like TF-IDF, it incorporates additional factors to improve the weighting scheme.",5 hops,text_model_embed200_hidden100
1805.01216v3,Which model performs best when the percentage of unseen entities in the response is low?,312,415,BoSsNet,ChoiceNet,text_model_embed200_hidden100
1701.06171v4,How many iterations did the greedy EM-type learning process take to learn the part models for the watch image?,119,353,22 iterations,The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence.,text_model_embed200_hidden100
1704.07121v2,"On the VQAv2-2017 validation set, which model performs best when considering all three sources of information (images, questions, and answers) and how does its performance compare to the model that only uses answers?",187,95,"The model that performs best on VQAv2-2017 val when considering all three sources of information is MLP-IQA. It achieves an accuracy of 61.1% on the \IU+\QU -decoys metric, significantly outperforming the model that only uses answers (MLP-A) which achieves only 27.7% on the same metric. This demonstrates the importance of incorporating all available information for accurate prediction.","PWC-Net (ft) achieved the best performance on the KITTI 2015 test set with an F1-all score of 9.16%. This is significantly better than Devon (ft), which achieved an F1-all score of 14.31% on the same dataset. ",text_model_embed200_hidden100
1809.03550v3,Why is the optimal threshold chosen to be at the right margin of the region around the mode of the histogram?,622,483,"The region around the mode of the histogram mostly contains noise. Therefore, the optimal threshold is chosen to be at the right margin of this region to avoid including too much noise in the thresholded image."," 

Increasing the value of β2 decreases the precision and increases the recall of the model.",text_model_embed200_hidden100
1707.00524v2,Which game has the highest code loss in phase 2?,486,308,Pacman,"The topic with the highest internal coherence value is ""turks armenian armenia turkish roads escape soviet muslim mountain soul"".",text_model_embed200_hidden100
1809.02731v3,Which model performed best on average across all tasks?,592,565,The Linear model performed best on average with a score of 70.0.,Intra-warrant attention with context.,text_model_embed200_hidden100
1706.00633v4,Which objective function resulted in a higher ratio of f2(x∗) > 0 for the MNIST dataset?,393,378,RCE,Cars are the most common object in the dataset.,text_model_embed200_hidden100
1809.00458v1,Which method is more efficient at utilizing space while maintaining high accuracy?,561,637,GB-KMV is more efficient at utilizing space while maintaining high accuracy.,VAGER + Voting,text_model_embed200_hidden100
1708.01425v4,Which step in the methodology resulted in the largest decrease in the size of the dataset?,567,60,"Step 4, Reason disambiguation.","The passage mentions that additional trajectories were generated for the ""Pick and Place"" task by reducing the frequency of the recorded demonstrations. This process was not applied to the ""Push to Pose"" task, therefore no ""Demonstrations after shift"" are listed for it.",text_model_embed200_hidden100
1804.05995v2,What are the top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method?,272,353,"The top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method are HISTORY, DEMOGRAPHICS, ECONOMY, EDUCATION, and POLITICS.",The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence.,text_model_embed200_hidden100
1803.03467v4,What is the role of the ripple sets in the RippleNet framework?,144,597,The ripple sets are used to propagate a user's preferences from his or her click history to his or her relevant entities.,The Higher Level Policy sets constraints for the next sub-trajectory and provides information about the previous stage to the Lower Level Policy.,text_model_embed200_hidden100
1803.04572v2,What are some common medications used to treat Sickle Cell Anemia?,149,198,"According to the table, some common medications used to treat Sickle Cell Anemia include:

Beta-adrenergic agents
Analgesics (narcotics and non-narcotics)
NSAIDs (cyclooxygenase inhibitor - type)
Potassium replacement
Sodium/saline preparations
General inhalation agents
Laxatives and cathartics
IV solutions (dextrose-saline)
Antiemetic/antivertigo agents
Sedative-hypnotics (non-barbiturate)
Glucocorticoids (orally inhaled)
Folic acid preparations
Analgesic narcotic anesthetic adjunct agents",The LIVR framework decomposes semantic features into different places by utilizing bitmaps encoded with the semantic labels of places. This decomposition encourages the network to learn features of generic place-based motion patterns that are independent of scene layouts.,text_model_embed200_hidden100
1809.00263v5,What is the value of the learning rate α for the BAIR dataset?,537,512,0.0002,The Leaky Unit helps to aggregate the context information from different sources and allows the model to learn the relationships between entities and their contexts.,text_model_embed200_hidden100
1803.02750v3,What is the difference between the `inc_i(p)` and `inc_i'(p)` operations in the Grow-only Counter data type?,114,363,"The `inc_i(p)` operation increments the value associated with the key `i` in the counter `p`, while the `inc_i'(p)` operation increments the value associated with the key `i` in the counter `p` only if the key `i` is not already present in the counter.",CDAN-fg,text_model_embed200_hidden100
1706.04269v2,What are the three main components of the Action Search model architecture?,453,378,"The three main components of the Action Search model architecture are the visual encoder, the LSTM, and the spotting target.",Cars are the most common object in the dataset.,text_model_embed200_hidden100
1706.00633v4,How does the accuracy of the model change as the value of c increases?,392,431,The accuracy of the model decreases as the value of c increases.,"The performance of the model generally improves as the number of views increases. For example, when the model is trained and tested on two-view data, the F1-score is 29.67. However, when the model is trained and tested on three-view data, the F1-score increases to 30.2. This suggests that the model is able to learn more effectively from data with more views.",text_model_embed200_hidden100
1812.00281v3,What are the different stages of HUMBI body and cloth reconstruction?,437,215,"The different stages of HUMBI body and cloth reconstruction are: 
1. Input image of the person (Ibody)
2. Keypoint estimation (Kbody)
3. Occupancy map generation (Obody)
4. Body model fitting (Mbody)
5. Cloth model fitting (Mcloth)",5 hops,text_model_embed200_hidden100
1706.00633v4,Which of the following algorithms performs the best when trained via the CE?,391,351,C&W-hc,DUF,text_model_embed200_hidden100
1705.09882v2,Which part of the model is responsible for deciding which frames are most important for the re-identification task?,330,415,The Reinforced Temporal Attention (RTA) unit.,ChoiceNet,text_model_embed200_hidden100
1706.03847v3,How does the training time of the different losses change as the number of additional samples increases?,450,236,The training time of all losses increases as the number of additional samples increases.,The landscape concentration increases with the number of state-action pairs.,text_model_embed200_hidden100
1611.02654v2,Which model performed the best on the SICK dataset according to the MSE metric?,33,549,The supervised model performed the best on the SICK dataset according to the MSE metric.,"The CoNLL model performed best on the WikiCoref dataset, with an F1 score of 53.40 when using the +linguistic evaluation metric.",text_model_embed200_hidden100
1811.08257v1,Which framework has the lowest total communication cost for MNIST?,292,542,FALCON,SDVI,text_model_embed200_hidden100
1611.03780v2,How is the Hilbert space-filling curve constructed?,17,355,"The Hilbert space-filling curve is constructed recursively. The curve starts with a simple square, and then at each subsequent iteration, the curve is subdivided into four smaller squares. The curve is then drawn through each of these squares in a specific order.",TecoGAN⊖.,text_model_embed200_hidden100
1707.00524v2,What is the difference between the encoder and decoder networks in the action-conditional prediction model?,488,605,The encoder network takes a one-hot action and the current state as input and outputs a latent representation of the state. The decoder network takes the latent representation and outputs a prediction of the next state.,The generalization gap increases as the average X_ref entropy increases.,text_model_embed200_hidden100
1804.07849v4,"According to the ablation experiments, which factor contributes the most to the best model's performance compared to the baseline model?",254,35,Morphological modeling with LSTMs contributes the most to the best model's performance compared to the baseline model.,"The proposed model in this paper achieves the best performance for the order discrimination task on the Accidents dataset with an accuracy of 0.944. It outperforms the other data-driven approaches, namely Window (Recurrent) with 0.840, Window (Recursive) with 0.864, and Seq2seq with 0.930.",text_model_embed200_hidden100
1811.09393v4,Which method has the best perceptual performance according to the tOF score?,349,256,TecoGAN.,Variational J^var (7),text_model_embed200_hidden100
1805.04687v2,"Why does the proposed dataset have a lower number of persons per image compared to the Cityscapes dataset, even though it has a much higher total number of pedestrians?",375,123,"The proposed dataset contains non-city scenes like highways, which typically have fewer pedestrians per image compared to cityscapes.","When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",text_model_embed200_hidden100
1812.00281v3,"What is the difference between the ""median appearance"" and the ""view-specific appearance""?",442,193,"The median appearance is the average of all the multiview images, while the view-specific appearance is a single image that is rendered from a specific viewpoint.","The representation task takes an appearance as input and outputs an RGB value, while the learning-to-learn task takes an image as input and outputs a DAM representation.",text_model_embed200_hidden100
1805.08465v3,Which steganography method achieves the best performance in terms of distortion for both cover and secret images when embedding 2 bits per channel?,514,350,The proposed method achieves the best performance for both cover and secret images when embedding 2 bits per channel.,TecoGAN,text_model_embed200_hidden100
1811.02553v4,How does the number of state-action pairs affect the optimization landscape for the PPO algorithm?,234,226,"As the number of state-action pairs increases, the optimization landscape becomes more complex and has more local optima. This makes it more difficult for the PPO algorithm to find the global optimum.",The RL policy accesses fewer index blocks than the baseline.,text_model_embed200_hidden100
1805.04687v2,How does the BDD100K dataset compare to the KITTI and MOT17 datasets in terms of size and complexity?,386,536,"The BDD100K dataset is significantly larger and more complex than both the KITTI and MOT17 datasets. It contains roughly 40 times more frames, 16 times more sequences, and 13 times more identities than KITTI. Compared to MOT17, BDD100K has about 10 times more frames, 80 times more sequences, and 8 times more identities. This increase in size and complexity makes BDD100K a more challenging and comprehensive benchmark for multiple object tracking algorithms. ","GBI is more effective than A* in reducing the disagreement rate on the SRL-100 network's failure set. After applying GBI, the average disagreement rate drops to 24.92%, while A* only reduces it to 33.91%. This represents an 19.93% greater reduction in disagreement rate when using GBI compared to A*.",text_model_embed200_hidden100
1707.08608v3,Which genre in the SRL-NW network has the lowest failure rate and how does its inference time compare to other genres within the same network?,530,631,"The PT genre within the SRL-NW network has the lowest failure rate at 10.01%. Its inference time is also the lowest across all genres in the SRL-NW network for all three inference procedures (Viterbi, GBI, and A*).","The Yelp P. dataset has the largest vocabulary size with 25,709 unique words. This is significantly larger than the average number of words per document in the dataset, which is 138.",text_model_embed200_hidden100
1804.05938v2,"Which correction method resulted in the best performance in terms of nDCG@10 and ERR@10, and how does it compare to not using any correction method?",322,446,"The DNN trained with DLA achieved the best performance in terms of both nDCG@10 (0.421) and ERR@10 (0.582). Compared to not using any correction method (NoCorrect), DLA shows a significant improvement in both metrics, with nDCG@10 being higher by 0.063 and ERR@10 being higher by 0.082.",The highest Recall@20 score was achieved by the GRU4Rec with additional samples and BPR-max loss function on the RSC15 dataset. This score was 42.37% higher than the Recall@20 score of the original GRU4Rec model on the same dataset.,text_model_embed200_hidden100
1704.07854v4,"Which of the two scenes, Drop or Staris, requires more computation time for rendering?",220,351,Staris,DUF,text_model_embed200_hidden100
1605.07496v3,How does the predicted return change as a function of θ for a fixed value of π = 1.5?,70,111,"The predicted return decreases as θ increases, with a minimum at around θ = 0.5.",The RR optimization helps to reduce the number of messages that need to be exchanged between replicas.,text_model_embed200_hidden100
1812.06589v2,What is the role of the frame discriminator in the proposed method?,464,62,The frame discriminator is used to detect whether the generated frame and audio are matched or not.,The virtual environment is used to collect demonstrations of the task from the user. This allows for safe and efficient data collection.,text_model_embed200_hidden100
1809.01989v2,Which method achieved the highest tracking accuracy in terms of minimizing the sum of absolute percentage errors? Does this necessarily mean it had the best overall performance?,646,422,"The Ridge method achieved the lowest sum of absolute percentage errors (136.84), indicating the highest tracking accuracy in terms of minimizing absolute deviations from the index. However, this doesn't necessarily translate to the best overall performance.",The WideResNet model has higher accuracy than the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle.,text_model_embed200_hidden100
1704.07854v4,Which of the methods is able to reconstruct the shape of the liquid properly?,223,100,Only the full method with a deformation network is able to produce a perfect reconstruction.,The SPIRAL-MSM-kMeans method performs the best in terms of NMI with a score of 0.365. It outperforms the other methods on 89.4% of the datasets.,text_model_embed200_hidden100
1705.09966v2,What is the difference between the input and output of the frontal face generation process?,344,59,The input is a low-resolution frontal face image and a high-resolution side-face image. The output is a high-resolution frontal face image.,"The LSTM-MDN network is used to learn the relationship between the gripper pose and status, the pose of relevant objects, and the joint angles of the robot arm.",text_model_embed200_hidden100
1805.06431v4,Which of the four methods has the best performance in terms of average error for the step function?,423,312,The proposed method.,BoSsNet,text_model_embed200_hidden100
1705.09882v2,How does the proposed split-rate RGB-to-Depth transfer scheme differ from the R3D [90] method of Yosinski et al.?,326,462,"The proposed split-rate RGB-to-Depth transfer scheme differs from the R3D [90] method in two ways. First, the proposed method uses a different learning rate for the bottom three layers of the network. Second, the proposed method uses a different initialization for the weights of the bottom three layers of the network.","Adding DA to the baseline method improves the PSNR and SSIM values, while slightly decreasing the LMD value.",text_model_embed200_hidden100
1812.06589v2,Which method performed the best according to the LMD metric?,463,256,AMIE (Ours),Variational J^var (7),text_model_embed200_hidden100
1706.08146v3,What is the effect of increasing the projection dimension d on the approximation error for sparse PCA and NMF?,505,575,Increasing the projection dimension d decreases the approximation error for both sparse PCA and NMF.,The buffer percentage decreases as the width of the room increases.,text_model_embed200_hidden100
1603.00286v5,What is the minimum number of sides that a rectilinear polygon with four reflex vertices must have?,58,296,Six.,The activation layer applies a non-linear function to the output of the convolution layer. This allows the network to learn more complex features from the data.,text_model_embed200_hidden100
1704.05426v4,Which type of word has the greatest difference in frequency of occurrence between MultiNLI and SNLI?,156,350,Negation (PTB),TecoGAN,text_model_embed200_hidden100
1811.02721v3,How does varying the buffer size affect TCP goodput?,205,198,"Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point.",The LIVR framework decomposes semantic features into different places by utilizing bitmaps encoded with the semantic labels of places. This decomposition encourages the network to learn features of generic place-based motion patterns that are independent of scene layouts.,text_model_embed200_hidden100
1805.04687v2,Which category of object is the least common in the dataset?,385,378,Train,Cars are the most common object in the dataset.,text_model_embed200_hidden100
1703.02507v3,Which dataset has the shortest average sentence length?,85,12,Headlines.,DMRNet,text_model_embed200_hidden100
1608.02784v2,What is the relationship between BLEU score and human ranking for CCA and SMT systems?,32,122,The correlation between BLEU scores and human ranking is not high for either CCA or SMT systems.,"The top-down compositional learning scheme starts with a holistic object model and decomposes it into smaller parts, while the bottom-up compositional learning scheme starts with basic parts and composes them into a holistic object model.",text_model_embed200_hidden100
1803.03467v4,How does the dimension of embedding affect the AUC of RippleNet on MovieLens-1M?,147,47,The AUC of RippleNet first increases and then decreases with the increase of the dimension of embedding.,The performance of gFGR generally improves as the shape parameter α increases.,text_model_embed200_hidden100
1611.07718v2,How does the classification error of a residual network change as the average path length increases?,15,92,The classification error of a residual network generally increases as the average path length increases.,"The residual connection adds the output of a layer to the output of another layer, which helps to prevent the vanishing gradient problem.",text_model_embed200_hidden100
1705.07164v8,Which method achieved the highest Inception Score (IS) at the end of training for both CIFAR10 and ImageNet datasets? Did this method also achieve the highest initial IS score?,270,645,"For CIFAR10, WGAN achieved the highest IS at the end of training (2.42). However, RWGAN had a higher initial IS score (1.86) compared to WGAN's 1.63. 

For ImageNet, WGAN again achieved the highest final IS (2.80), while RWGAN had a slightly higher initial IS (2.04 vs. 2.00). ","For all datasets presented, Incremental SVM achieved a slightly lower OFV compared to FISVDD. However, this does not necessarily mean that Incremental SVM is definitively better.",text_model_embed200_hidden100
1605.07496v3,Which of the algorithms performs the best on the robotic arm joint breakage task?,66,607,ALOQ.,KAR,text_model_embed200_hidden100
1805.01216v3,"Why might the authors claim that although BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, it still performs better in conveying necessary entity information?",318,482,"While BOSSNET has a lower BLEU score than Mem2Seq on SMD, it achieves the highest Entity F1 score on that dataset. This suggests that BOSSNET is better at capturing and including the relevant entities in its responses, even though it may not have as much lexical overlap with the gold responses as Mem2Seq.","The FLoss method performs better than the balanced cross-entropy loss because it can automatically adjust to data imbalance using the F-measure criterion, while the balanced cross-entropy loss relies on pre-defined weights for positive and negative samples.",text_model_embed200_hidden100
1812.00281v3,How does the number of cameras used affect the accuracy of the garment reconstruction?,440,284,The accuracy of the garment reconstruction increases as the number of cameras used increases.,The test accuracy of all models decreases as λ increases.,text_model_embed200_hidden100
1605.07496v3,Which algorithm performs the best in the Joint Breakage experiment?,67,351,ALOQ,DUF,text_model_embed200_hidden100
1603.00286v5,Which agent values the entire share $Z_j$?,54,124,Agent $j$.,The Traffic dataset.,text_model_embed200_hidden100
1701.03077v10,Why did the authors choose to use a nonlinearity to curve α before fitting the cubic hermite spline?,45,226,"The authors chose to use a nonlinearity to curve α before fitting the cubic hermite spline because it allows for increased knot density near α = 2 and decreased knot density when α > 4. This helps to better approximate the log partition function, which is difficult to evaluate for arbitrary inputs.",The RL policy accesses fewer index blocks than the baseline.,text_model_embed200_hidden100
1703.10730v2,What are the inputs to the image generation network?,139,523,The inputs to the image generation network are the observed images (x) and a random noise vector (z).,The AMT workers are being asked to decide whether each of twenty one paragraphs extracted from product reviews is real (written by a person) or fake (written by a computer algorithm).,text_model_embed200_hidden100
1809.00458v1,Which dataset has the highest average record length?,557,451,CaOpenData,VIDXL has the highest Recall@20 and MRR@20.,text_model_embed200_hidden100
1709.02418v2,What is the effect of performing a left-swap on a binary vector y at index j′?,647,358,The left-swap increases the number of misclassified pairs by one.,The UVT cycle link is used to transfer knowledge between two recurrent generators.,text_model_embed200_hidden100
1809.00458v1,What is the relationship between the element-hash value pairs and the signature size?,558,19,"The element-hash value pairs are the elements of the signature, and the signature size is the number of element-hash value pairs in the signature."," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed200_hidden100
1805.06431v4,What is the purpose of the Cholesky Block in this figure?,427,264,The Cholesky Block is used to distinguish abnormal patterns from normal patterns.,The ancillary heatmap is used to correct the labels for missing or oversegmented objects in the images.,text_model_embed200_hidden100
1809.03149v2,What is the effect of using CHER on the percentage of ads displayed for each user?,599,397,The percentage of ads displayed for each user is higher when CHER is used.,Downsampling reduces the quality of reconstructed frames.,text_model_embed200_hidden100
1809.03449v3,Which model performs the best when trained on 60% of the training data?,607,629,KAR,"ACNN performs best on ""Who"" questions.",text_model_embed200_hidden100
1707.00189v3,"Which model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, and how does its performance compare to the baselines?",500,96,"The Conv-KNRM model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, achieving an nDCG@20 score of 0.3215. This performance is significantly better than all the baselines: BM25 (B), WT10 (W), and AOL (A).","PWC-Net (ft) performs best on the Sintel ""Final"" test set with an error of 5.04. Devon (ft) has a higher error of 6.35 on the same set. ",text_model_embed200_hidden100
1811.02553v4,How does the number of state-action pairs affect the reward landscape for the surrogate and true reward functions?,233,512,"As the number of state-action pairs increases, the reward landscape for both the surrogate and true reward functions becomes smoother and more accurate.",The Leaky Unit helps to aggregate the context information from different sources and allows the model to learn the relationships between entities and their contexts.,text_model_embed200_hidden100
1805.08751v2,What is the role of the GDU and HFLU modules in the FAKEDETECTOR framework?,524,529,"The GDU (Gated Dilated Unit) modules are responsible for extracting features from the input data, while the HFLU (Hybrid Feature Learning Unit) modules are responsible for fusing the features extracted by the GDU modules.","The ""max"" function is used to select the most probable word at each time step in the decoding process.",text_model_embed200_hidden100
1803.04572v2,Which dataset has the largest number of clinical visits per patient?,154,287,CMS,SVHN,text_model_embed200_hidden100
1802.07459v2,What are the different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents?,103,426,"The different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents are: (a) Representation, (b) Encoding, (c) Transformation, and (d) Aggregation.","The Cholesky block is used to decompose the covariance matrix Σk into a lower triangular matrix and its transpose. This decomposition is used to ensure that the covariance matrix is positive definite, which is a requirement for the Gaussian distribution.",text_model_embed200_hidden100
1707.01917v2,"What does the induced schema Win <A4, B3, C2> represent?",494,399,"The induced schema Win <A4, B3, C2> represents the fact that player A4 won tournament C2, defeating player B3.",The second-stage decoder $D_2$ takes soft edges $x_G$ as input and produces reconstructed frames.,text_model_embed200_hidden100
1608.02784v2,What is the relationship between the input space and the output space in CCA inference?,30,19,The input space and the output space are related by a cosine similarity measure.," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed200_hidden100
1802.07351v2,Explain the rationale behind using five deformable cost volumes with different hyperparameter settings in Devon's relation module.,94,356,"The five deformable cost volumes in Devon's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery. This is achieved by using different neighborhood sizes (k) and dilation rates (r) for each cost volume, as shown in Table 1. Smaller neighborhood sizes and dilation rates result in denser correspondences, focusing on finer details and small displacements, while larger values capture broader context and larger motions.",5.00E-05,text_model_embed200_hidden100
1804.05936v2,Which relevance label category of documents received the most significant rank promotion according to the NegPair reduction metric?,247,350,The perfect results received the largest promotions in rank.,TecoGAN,text_model_embed200_hidden100
1811.08257v1,Which operation has the lowest online time?,298,124,ReLU,The Traffic dataset.,text_model_embed200_hidden100
1704.07854v4,How do the parameter network and the deformation network differ in terms of complexity and function?,217,415,"The parameter network is a simple structure with two fully connected layers, while the deformation network is more complex and contains two fully connected layers followed by two or more four-dimensional de-convolution layers. The parameter network learns how to apply multiple long-range, non-linear deformation fields, while the deformation network learns to generate dense deformation fields to refine the final surface.",ChoiceNet,text_model_embed200_hidden100
1811.10673v1,How does the quality of the reconstructed frames change as the quantization level of the soft edge detector increases?,405,50,The quality of the reconstructed frames increases as the quantization level of the soft edge detector increases.," As the value of α increases, the NLL functions become more peaked and the probability density functions become more concentrated around the mean.",text_model_embed200_hidden100
1812.10735v2,Why do you think the performance of all models is generally lower on Rest15 compared to Rest14?,491,353,The performance of all models is generally lower on Rest15 because it has a larger number of aspect categories (13) compared to Rest14 (5). This increased complexity makes it more challenging for the models to accurately identify and classify the aspects.,The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence.,text_model_embed200_hidden100
1809.01246v1,How does the average precision of TCM(256*memory) compare to the other two algorithms in the email-EuAll dataset?,581,361,The average precision of TCM(256*memory) is lower than the other two algorithms in the email-EuAll dataset.,The US-BS-MQ method achieves higher accuracy than the S-MQ method when adding SST examples.,text_model_embed200_hidden100
1809.01246v1,What is the relationship between the table and the graph sketch in the figure?,578,221,"The table provides the mapping between the nodes in the original graph and their corresponding hash values, which are used to create the graph sketch."," The higher the resolution of the simulation, the longer the training time. ",text_model_embed200_hidden100
1805.06447v3,Describe the relationship between the update threshold (Tu) and the performance of ITN (B-CNN) on the MNIST dataset.,475,609,The performance of ITN (B-CNN) on the MNIST dataset decreases as the update threshold (Tu) increases. This is evident from the increasing ITN error percentages as Tu goes from 1e-3 to 1e-1.,The performance of all three models decreases as the proportion of available training examples decreases.,text_model_embed200_hidden100
1803.04572v2,Which constraint has the most significant impact on the FIT values for the CMS data set when the target rank is 15?,148,570,The smoothness constraint on $\M{U_k}$ has the most significant impact on the FIT values for the CMS data set when the target rank is 15.,"LIME appears to place the most emphasis on specific, localized features.",text_model_embed200_hidden100
1803.06506v3,"How does the quality of the output heatmap change when the selected concept, predicted concept, and the real entity to be grounded are all aligned?",165,369,"When the selected concept, predicted concept, and the real entity to be grounded are all aligned, the generated heatmap produces a good localization of the phrase.",Cars have the largest total number of annotations.,text_model_embed200_hidden100
1704.05426v4,Which model performs better on the MultiNLI dataset when considering the percentage of individual labels that match the author's label?,157,390,"SNLI performs better than MultiNLI when considering the percentage of individual labels that match the author's label. SNLI has a score of 85.8%, while MultiNLI has a score of 85.2%.",The most effective attack method at reducing the accuracy of the Resnet-32 model on the MNIST dataset is BIM/CE.,text_model_embed200_hidden100
1809.00458v1,Which algorithm performs better in terms of F1 score and precision when the space used is 5%?,556,415,GB-KMV performs better in terms of F1 score and precision when the space used is 5%.,ChoiceNet,text_model_embed200_hidden100
1809.04276v2,How does the performance of the discriminator in the proposed approach compare to the conventional discriminator in AL? What evidence suggests this difference in performance?,641,589,The discriminator in the author's approach achieves higher accuracy (95.72%) compared to the conventional discriminator in AL (94.01%).,"According to the passage, the variance of the hidden state is approximately equal to the variance of the input in deep layers.",text_model_embed200_hidden100
1702.03584v3,How does the observed error compare to the underlying true error as CPU time increases?,98,235,"The observed error is initially higher than the underlying true error, but it quickly decreases and converges to the true error as CPU time increases.",TRPO generally converges faster to the true gradient than PPO.,text_model_embed200_hidden100
1705.02946v3,"What is the distance from equitability for the allocation that can be obtained by cutting at $x$ with the player order $(1,2)$?",266,363,The distance from equitability is $b-a$.,CDAN-fg,text_model_embed200_hidden100
1701.03077v10,"On which dataset did the gRCC* algorithm achieve the largest relative improvement over the RCC algorithm, and by approximately how much did it improve?",41,446,"The gRCC* algorithm achieved the largest relative improvement over the RCC algorithm on the YTF dataset, with a relative improvement of approximately 31.9%.",The highest Recall@20 score was achieved by the GRU4Rec with additional samples and BPR-max loss function on the RSC15 dataset. This score was 42.37% higher than the Recall@20 score of the original GRU4Rec model on the same dataset.,text_model_embed200_hidden100
1811.02721v3,"Which TCP stack provides the most complete implementation of core TCP features, and which stack lacks the most features?",214,126,"The TCP stack presented in this paper (TCPlp) provides the most complete implementation of core TCP features, including flow control, congestion control, RTT estimation, MSS option, OOO reassembly, and various advanced features like timestamps and selective ACKs. In contrast, BLIP lacks the most features, as it does not implement congestion control, RTT estimation, or several other functionalities present in other stacks.",LST-Skip seems to perform better in predicting electricity consumption.,text_model_embed200_hidden100
1707.01917v2,What is the shape of the tensor $x^1$ for the Shootings dataset?,496,371,The shape of the tensor $x^1$ for the Shootings dataset is 3365 x 1295 x 50.,City Street,text_model_embed200_hidden100
1811.08481v2,Which estimator achieves the highest accuracy on the CLEVR validation set?,336,337,Size estimator.,UnCoRd-None-B.,text_model_embed200_hidden100
1804.04410v2,How does the performance of the learned policy compare to the production baseline for CAT2 queries in terms of relevance and efficiency?,227,483,"For CAT2 queries, the learned policy shows a slight improvement in relevance (NCG) for the weighted set and a significant reduction in index blocks accessed for both weighted and unweighted sets."," 

Increasing the value of β2 decreases the precision and increases the recall of the model.",text_model_embed200_hidden100
1812.00281v3,What is the relationship between the camera yaw angle and the silhouette distance?,433,138,The silhouette distance generally increases as the camera yaw angle increases.,The input patches are used to generate the images. The generator network takes the input patches as input and generates new images that are similar to the input patches.,text_model_embed200_hidden100
1901.00398v2," Which type of review was more accurately identified by the human evaluators, human-written or machine-generated? ",521,620,The human evaluators were more accurate at identifying human-written reviews than machine-generated reviews.,Outcome Regression (OR),text_model_embed200_hidden100
1608.02784v2,What is the role of the temperature variable t in the CCA decoding algorithm?,31,544,"The temperature variable t controls the probability of accepting a new candidate solution y. As t decreases, the probability of accepting a worse solution decreases.",The residual connections add the output of the previous layer to the input of the next layer. This helps to improve the flow of information through the network and can help to prevent vanishing gradients.,text_model_embed200_hidden100
1707.06320v2,How do the word embeddings learned by the Cap2Img model compare to the original GloVe embeddings in terms of semantic similarity?,528,617,The word embeddings learned by the Cap2Img model outperform the original GloVe embeddings in terms of semantic similarity.,The learned graph assigns weights that correspond much better to the relevance of the terms compared to k-NN and A-NN graphs.,text_model_embed200_hidden100
1707.01917v2,Which method achieves the highest accuracy on the Shootings dataset?,499,285,TFBA,PC-DenseNet-161,text_model_embed200_hidden100
1803.04572v2,How do the temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients?,151,262,"The temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients in terms of both shape and magnitude. For sickle cell anemia patients, the patterns are generally smoother and more periodic, with lower overall magnitude. For leukemia patients, the patterns are more erratic and have higher overall magnitude.",The bounding box encoder network embeds bounding box information at different scales and outputs attention maps that are used to fuse with feature maps from the encoder before being passed to the decoder.,text_model_embed200_hidden100
1811.10673v1,How does the proposed method compare to H.264 in terms of MS-SSIM score at low bitrates?,398,346,The proposed method achieves significantly higher MS-SSIM scores than H.264 at bitrates below 10 Kbps.,The proposed method is able to generate images with different hair colors more accurately than icGAN.,text_model_embed200_hidden100
1811.10673v1,How does the quality of the reconstructed frames change as the resolution increases?,404,615,The quality of the reconstructed frames increases monotonically as the resolution increases.,Adding Gaussian noise to the images increases the measured sparsity.,text_model_embed200_hidden100
1803.02750v3,Which topology has the highest transmission rate for GMap 100%?,115,308,Mesh,"The topic with the highest internal coherence value is ""turks armenian armenia turkish roads escape soviet muslim mountain soul"".",text_model_embed200_hidden100
1704.07854v4,How do the initial conditions of the simulations vary?,224,316,The initial conditions of the simulations vary in two dimensions: the position of the liquid drop along the x-axis (α1) and the size of the drop (α2).,The encoder understands the last user utterance by using the memory cell representations of the dialog history and KB tuples.,text_model_embed200_hidden100
1812.00281v3,How does HUMBI capture diverse appearance of human expressions?,441,574,"HUMBI includes 772 distinctive subjects across gender, ethnicity, age, clothing style, and physical condition, which generates diverse appearance of human expressions.","Square hashing is a process that uses two hash functions to map a source/destination pair to a bucket in a two-dimensional array. The first hash function, h_i(s), maps the source address to a row in the array, and the second hash function, h_i(d), maps the destination address to a column in the array. The intersection of the row and column is the bucket where the fingerprint is stored.",text_model_embed200_hidden100
1805.04687v2,Which weather condition has the highest classification accuracy?,377,308,Clear weather.,"The topic with the highest internal coherence value is ""turks armenian armenia turkish roads escape soviet muslim mountain soul"".",text_model_embed200_hidden100
1703.04887v4,"Which model and configuration achieves the best performance on the Chinese-English translation task, and how much improvement does it offer compared to the baseline RNNSearch model?",134,241,The Transformer+BR-CSGAN model with λ=0.8 achieves the best performance on the Chinese-English translation task with an average BLEU score of 42.61. This represents an improvement of 0.81 BLEU points compared to the baseline RNNSearch model.,"The DCRL training method appears to have the biggest impact on the F1 score. Removing it leads to a drop of 0.9 points in F1, which is the largest decrease observed for any single component in the ablation study.",text_model_embed200_hidden100
1703.04887v4,What is the relationship between the number of Monte Carlo samples (N) and the translation performance of the BR-CSGAN model? Why is there a trade-off when choosing the value of N?,131,123,"The table and passage show that the translation performance of the BR-CSGAN model generally improves as the number of Monte Carlo samples (N) increases. However, this improvement plateaus after N reaches a certain point (around 20 in this case).

There is a trade-off when choosing the value of N because increasing N also increases the computational complexity and training time. While a higher N leads to more accurate reward estimations and better performance, it also requires more computational resources and longer training times. Therefore, choosing the optimal N involves balancing the desired performance with the available computational resources and time constraints.","When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",text_model_embed200_hidden100
1708.05239v3,How does the performance of the PE-N=5 sampler compare to the HMC sampler?,573,284,The PE-N=5 sampler performs better than the HMC sampler.,The test accuracy of all models decreases as λ increases.,text_model_embed200_hidden100
1805.06447v3,How does the ITN framework generate pseudo-negative samples?,470,574,The ITN framework generates pseudo-negative samples by applying learned transformations to positive samples.,"Square hashing is a process that uses two hash functions to map a source/destination pair to a bucket in a two-dimensional array. The first hash function, h_i(s), maps the source address to a row in the array, and the second hash function, h_i(d), maps the destination address to a column in the array. The intersection of the row and column is the bucket where the fingerprint is stored.",text_model_embed200_hidden100
1701.03077v10,"What is the effect of replacing the loss function in the ""Baseline"" network with the ""adaptive"" loss over wavelet coefficients?",43,121,"Replacing the loss function in the ""Baseline"" network with the ""adaptive"" loss over wavelet coefficients results in significantly improved depth estimates.",The hierarchical part dictionary learned with the bottom-up process is a set of parts that can be combined to create objects. The holistic object model learned with the top-down process is a single model that represents the entire object.,text_model_embed200_hidden100
1611.05742v3,"Which method performs best on the PaSC dataset for the handheld testing scenario (PaSC2), and how does its performance compare to other methods?",7,229,"The method that performs best on the PaSC dataset for the handheld testing scenario (PaSC2) is SPDNet, with an accuracy of 72.83%. This performance is slightly higher than GrNet-2Blocks (72.76%) and significantly higher than other methods like VGGDeepFace (68.24%) and DeepO2P (60.14%).",The saliency map method with the highest sAUC score is **SIM**. Its sAUC score appears to be significantly higher than all other methods listed in the table.,text_model_embed200_hidden100
1707.01922v5,What is the difference between testing domain adaptation and testing sensor fusion?,515,507,"In testing domain adaptation, the source and target CNNs are trained on different domains, and the joint classifier is used to predict the class of the target data. In testing sensor fusion, the source and target CNNs are trained on the same domain, and the joint classifier is used to predict the class of the target data using both the source and target data.",The range of values for the context number hyperparameter is from 1 to 20.,text_model_embed200_hidden100
1611.02654v2,What can you say about the relationship between the sentences in a document based on the t-SNE embeddings?,36,605,Sentences that are closer together in the embedding space are more semantically similar than those that are farther apart.,The generalization gap increases as the average X_ref entropy increases.,text_model_embed200_hidden100
1804.07849v4,"Which method achieved the highest average V-measure (VM) across all languages, and how much higher was its average compared to the Baum-Welch method?",255,105,"The Variational $\wh{J}^{\mathrm{var}}$ method achieved the highest average VM score (50.4). Its average score is 39.6 points higher than the Baum-Welch method, which achieved an average VM score of 10.8.",The C-Tarone method has higher precision and F-measure than the binarization method in all datasets. The C-Tarone method has better or competitive recall than the binarization method. The running time of the C-Tarone method is competitive with the binarization method.,text_model_embed200_hidden100
1811.08257v1,How is convolution represented in the frequency domain?,290,109,"In the frequency domain, convolution is represented by element-wise multiplication.","GCounter measures the number of times an event has occurred, while GSet measures the number of unique elements in a set.",text_model_embed200_hidden100
1706.00633v4,Which combination of training procedure and thresholding metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types?,389,305,RCE training combined with the K-density metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types.,2001,text_model_embed200_hidden100
1706.03847v3,What is the performance of GRU4Rec relative to the baseline in terms of watch time?,447,615,GRU4Rec has a slightly higher performance than the baseline in terms of watch time.,Adding Gaussian noise to the images increases the measured sparsity.,text_model_embed200_hidden100
1710.05654v2,"How well do the approximate bounds of $\theta$ predict sparsity in the ""spherical"" dataset?",613,412,"The approximate bounds of $\theta$ are very effective at predicting sparsity in the ""spherical"" dataset.",The Mean-Shift algorithm is robust to outliers.,text_model_embed200_hidden100
1811.08257v1,What is the function of the DataPreprocessing function?,293,547,"The DataPreprocessing function performs Yao Sharing, which is a cryptographic technique for securely sharing data between multiple parties.",2,text_model_embed200_hidden100
1709.02755v5,"Based on the table, how does the training process handle large vocabulary sizes?",588,339,"The training process uses several techniques to handle large vocabulary sizes. These include:

1. **Token-based batching:** Instead of grouping sentences of similar lengths together, the training process batches together a fixed number of tokens (5120 tokens per batch). This approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation.
2. **Shared embedding:** This technique maps both source and target words to the same embedding space, effectively reducing the memory footprint needed to store word representations. 
3. **Positional encoding:** This method injects information about the position of words in a sentence into the model, helping it better understand long-range dependencies within the text. ",The proposed method produces more realistic and natural-looking images than the method in~\cite{kim2017learning}.,text_model_embed200_hidden100
1705.09882v2,What is the difference between the grayscale depth representation and the result after background subtraction?,327,507," The grayscale depth representation shows the depth of each pixel in the image, with darker pixels representing closer objects and lighter pixels representing further objects. The result after background subtraction shows only the foreground object, with the background removed.",The range of values for the context number hyperparameter is from 1 to 20.,text_model_embed200_hidden100
1605.07496v3,"Between WSN and ALOQ, which method is the most efficient in terms of runtime for both F-SRE1 and F-SRE2?",69,624,ALOQ is significantly more efficient than WSN.,"Algorithm 12(SCDM with Geman-McLure) achieves the fastest processing time per frame at 0.103 seconds. This is approximately 100 times faster than the slowest algorithm, TTD_3WD, which takes 10.343 seconds per frame.",text_model_embed200_hidden100
1704.05958v2,Can you estimate the percentage of entity pairs in the NYT training set that have a corresponding relational fact in the Knowledge Base (KB)?,160,116,Approximately 6.66%.,Posting a tweet will result in 1 + 100 = 101 CRDT updates. This represents 35% of the overall workload.,text_model_embed200_hidden100
1705.02946v3,What is the upper bound on the query complexity for finding an ε-perfect allocation with minimum cuts for 3 or more players?,267,19,O(n^3 / ε)," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed200_hidden100
1705.09296v2,How does the model capture different perspectives on immigration when considering tone as a covariate?,311,416,"The model captures different perspectives on immigration by highlighting contrasting words associated with the same topic, depending on whether the tone is anti-immigration or pro-immigration.",The ChoiceNet model performs poorly on datasets with uniform corruptions.,text_model_embed200_hidden100
1703.04887v4,What is the role of the discriminator (D) in the proposed BR-CSGAN model?,135,248," The discriminator (D) is responsible for distinguishing between real sentence pairs translated by humans and generated sentence pairs produced by the generator (G). It provides feedback to G in the form of rewards, helping G improve its ability to generate realistic sentence pairs.",The GRU is used to process the ranked list of documents provided by a global ranking function.,text_model_embed200_hidden100
1804.07849v4,"Which method achieved the highest accuracy on the 45-tag Penn WSJ dataset, and how does its performance compare to the other methods?",253,229,"The Variational $\wh{J}^{\mathrm{var}}$ method achieved the highest accuracy of 78.1% on the 45-tag Penn WSJ dataset. This is significantly higher than all other methods listed in the table, with the next best performing method (Berg-Kirkpatrick et al., 2010) achieving an accuracy of 74.9%.",The saliency map method with the highest sAUC score is **SIM**. Its sAUC score appears to be significantly higher than all other methods listed in the table.,text_model_embed200_hidden100
1705.09966v2,"Which of the methods among Conditional GAN, Unsupervised GAN and Consitional CycleGAN would you expect to produce images that are most visually similar to the real images in the CelebA dataset?",340,123,The Conditional CycleGAN method is expected to produce images most visually similar to the real images.,"When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",text_model_embed200_hidden100
1805.06431v4,How does the performance of the different models change as the corruption level increases? Which model appears to be the most robust to label corruption?,419,243,"As the corruption level increases, the performance of all models decreases. However, ChoiceNet consistently outperforms both ConvNet and ConvNet+Mixup across all corruption levels, maintaining high accuracy even when almost half of the labels are incorrect. This suggests that ChoiceNet is significantly more robust to label corruption compared to the other models.","The single R.M-Reader model achieves an EM score of 79.5% and an F1 score of 86.6% on the SQuAD test set. This performance is better than all other single models listed in the table, except for SLQA and Hybrid AoA Reader, which achieve slightly higher F1 scores of 87.0% and 87.3%, respectively.",text_model_embed200_hidden100
1811.02721v3,"Based on Table 1 and the passage, why does TCP perform poorly on IEEE 802.15.4 networks compared to other network types listed? ",203,259,"TCP performs poorly on IEEE 802.15.4 networks because the Maximum Transmission Unit (MTU) for these networks is significantly smaller than other network types. This small MTU size results in a high percentage of overhead due to the TCP/IP headers, exceeding 50%. ","The Conv. Self-Corr. method achieved the highest performance on the PASCAL VOC 2012 test set with a score of 82.72. This is approximately 1.11 points higher than the baseline model (""No Self-Corr."") which achieved a score of 81.61.",text_model_embed200_hidden100
