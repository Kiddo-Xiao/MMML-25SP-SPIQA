paper_id,question,true_label,predicted_label,true_answer,predicted_answer,model_name
1804.07931v2,What are the two auxiliary tasks that are used in the ESMM architecture for CVR modeling?,279,538,The two auxiliary tasks are CTR and CTCVR.,All features have the same dimensionality in the first two dimensions.,text_model_embed300_hidden150
1803.03467v4,Which dataset has the highest AUC for all ripple set sizes?,146,451,MovieLens-1M,VIDXL has the highest Recall@20 and MRR@20.,text_model_embed300_hidden150
1804.05938v2,"Explain the difference between the features ""TF-IDF"" and ""BM25"".",324,319,"Both TF-IDF and BM25 are features used to estimate the relevance of a document to a query. However, they differ in their underlying calculations.

TF-IDF: This feature represents the average product of term frequency (TF) and inverse document frequency (IDF) for each query term within different document sections (URL, title, content, and whole document). TF measures how often a term appears in a specific document section, while IDF measures how important that term is across the entire document collection.

BM25: This feature utilizes the BM25 ranking function, which is a probabilistic model that considers term frequency, document length, and average document length to estimate relevance. While it also considers term frequency like TF-IDF, it incorporates additional factors to improve the weighting scheme."," 

The pre-processed SMD Navigate data combines all the properties (such as distance, address) of a point of interest (POI) into a single subject with the object being ""poi"". The original data had separate entries for each property. ",text_model_embed300_hidden150
1805.01216v3,Which model performs best when the percentage of unseen entities in the response is low?,312,552,BoSsNet,LSH-E,text_model_embed300_hidden150
1701.06171v4,How many iterations did the greedy EM-type learning process take to learn the part models for the watch image?,119,362,22 iterations,"The main difference is that the Multilinear Conditioning architecture uses a multilinear map to condition the domain discriminator on the classifier prediction, while the Randomized Multilinear Conditioning architecture uses a randomized multilinear map.",text_model_embed300_hidden150
1704.07121v2,"On the VQAv2-2017 validation set, which model performs best when considering all three sources of information (images, questions, and answers) and how does its performance compare to the model that only uses answers?",187,95,"The model that performs best on VQAv2-2017 val when considering all three sources of information is MLP-IQA. It achieves an accuracy of 61.1% on the \IU+\QU -decoys metric, significantly outperforming the model that only uses answers (MLP-A) which achieves only 27.7% on the same metric. This demonstrates the importance of incorporating all available information for accurate prediction.","PWC-Net (ft) achieved the best performance on the KITTI 2015 test set with an F1-all score of 9.16%. This is significantly better than Devon (ft), which achieved an F1-all score of 14.31% on the same dataset. ",text_model_embed300_hidden150
1809.03550v3,Why is the optimal threshold chosen to be at the right margin of the region around the mode of the histogram?,622,77,"The region around the mode of the histogram mostly contains noise. Therefore, the optimal threshold is chosen to be at the right margin of this region to avoid including too much noise in the thresholded image.","There is a negative correlation between the success rate of the non-overlapping attack and the number of words changed in the input sentence. In other words, the fewer words that are changed, the higher the success rate of the attack.",text_model_embed300_hidden150
1707.00524v2,Which game has the highest code loss in phase 2?,486,65,Pacman,MAP Policy,text_model_embed300_hidden150
1809.02731v3,Which model performed best on average across all tasks?,592,301,The Linear model performed best on average with a score of 70.0.,The Transfer + MTSA model performed best on the SNLI test set with an accuracy of 86.9%.,text_model_embed300_hidden150
1706.00633v4,Which objective function resulted in a higher ratio of f2(x∗) > 0 for the MNIST dataset?,393,388,RCE,ResNet-56 (RCE) performed better on the MNIST dataset with a classification error rate of 0.32% compared to ResNet-32 (CE) which had a classification error rate of 0.38%.,text_model_embed300_hidden150
1809.00458v1,Which method is more efficient at utilizing space while maintaining high accuracy?,561,153,GB-KMV is more efficient at utilizing space while maintaining high accuracy.,COPA is faster than Helwig.,text_model_embed300_hidden150
1708.01425v4,Which step in the methodology resulted in the largest decrease in the size of the dataset?,567,289,"Step 4, Reason disambiguation.","The shared weights allow the two branches of the network to learn similar representations of the input images. This helps to improve the performance of the Euclidean Confusion loss, which measures the distance between the conditional probability distributions of the two branches.",text_model_embed300_hidden150
1804.05995v2,What are the top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method?,272,51,"The top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method are HISTORY, DEMOGRAPHICS, ECONOMY, EDUCATION, and POLITICS.",The proposed method appears to be more accurate than the baseline method. The depth maps generated by the proposed method are more detailed and realistic than those generated by the baseline method.,text_model_embed300_hidden150
1803.03467v4,What is the role of the ripple sets in the RippleNet framework?,144,87,The ripple sets are used to propagate a user's preferences from his or her click history to his or her relevant entities.,"The residual connection allows the output of a layer to be added to the output of another layer, which helps to improve the flow of information through the network.",text_model_embed300_hidden150
1803.04572v2,What are some common medications used to treat Sickle Cell Anemia?,149,141,"According to the table, some common medications used to treat Sickle Cell Anemia include:

Beta-adrenergic agents
Analgesics (narcotics and non-narcotics)
NSAIDs (cyclooxygenase inhibitor - type)
Potassium replacement
Sodium/saline preparations
General inhalation agents
Laxatives and cathartics
IV solutions (dextrose-saline)
Antiemetic/antivertigo agents
Sedative-hypnotics (non-barbiturate)
Glucocorticoids (orally inhaled)
Folic acid preparations
Analgesic narcotic anesthetic adjunct agents",Bing-News.,text_model_embed300_hidden150
1809.00263v5,What is the value of the learning rate α for the BAIR dataset?,537,297,0.0002,"The filter is used to extract features from the input image. It is a small matrix that is applied to each pixel in the image, and the result is a new pixel value.",text_model_embed300_hidden150
1803.02750v3,What is the difference between the `inc_i(p)` and `inc_i'(p)` operations in the Grow-only Counter data type?,114,640,"The `inc_i(p)` operation increments the value associated with the key `i` in the counter `p`, while the `inc_i'(p)` operation increments the value associated with the key `i` in the counter `p` only if the key `i` is not already present in the counter.","The model is discouraged because it is trained using the Maximum Likelihood Estimation (MLE) objective, which prioritizes generating responses that are identical to the ground-truth (GT) response. Even though the RSP integrates relevant content from the candidates and seems appropriate in the context, it is penalized because it deviates from the exact wording of the GT.",text_model_embed300_hidden150
1706.04269v2,What are the three main components of the Action Search model architecture?,453,257,"The three main components of the Action Search model architecture are the visual encoder, the LSTM, and the spotting target.",The BiLSTM takes as input the character-level representations of the words and outputs a word-level representation for each word.,text_model_embed300_hidden150
1706.00633v4,How does the accuracy of the model change as the value of c increases?,392,431,The accuracy of the model decreases as the value of c increases.,"The performance of the model generally improves as the number of views increases. For example, when the model is trained and tested on two-view data, the F1-score is 29.67. However, when the model is trained and tested on three-view data, the F1-score increases to 30.2. This suggests that the model is able to learn more effectively from data with more views.",text_model_embed300_hidden150
1812.00281v3,What are the different stages of HUMBI body and cloth reconstruction?,437,359,"The different stages of HUMBI body and cloth reconstruction are: 
1. Input image of the person (Ibody)
2. Keypoint estimation (Kbody)
3. Occupancy map generation (Obody)
4. Body model fitting (Mbody)
5. Cloth model fitting (Mcloth)",The user study is designed to test which of two images is closer to a reference video.,text_model_embed300_hidden150
1706.00633v4,Which of the following algorithms performs the best when trained via the CE?,391,350,C&W-hc,TecoGAN,text_model_embed300_hidden150
1705.09882v2,Which part of the model is responsible for deciding which frames are most important for the re-identification task?,330,86,The Reinforced Temporal Attention (RTA) unit.,The Sent2Vec uni. + bi. model performed the best on the MSRP task for the Twitter dataset.,text_model_embed300_hidden150
1706.03847v3,How does the training time of the different losses change as the number of additional samples increases?,450,228,The training time of all losses increases as the number of additional samples increases.,The performance of the SIM saliency map increases as the number of fixations increases.,text_model_embed300_hidden150
1611.02654v2,Which model performed the best on the SICK dataset according to the MSE metric?,33,549,The supervised model performed the best on the SICK dataset according to the MSE metric.,"The CoNLL model performed best on the WikiCoref dataset, with an F1 score of 53.40 when using the +linguistic evaluation metric.",text_model_embed300_hidden150
1811.08257v1,Which framework has the lowest total communication cost for MNIST?,292,497,FALCON,A non-negative tensor is a tensor whose elements are all non-negative real numbers.,text_model_embed300_hidden150
1611.03780v2,How is the Hilbert space-filling curve constructed?,17,568,"The Hilbert space-filling curve is constructed recursively. The curve starts with a simple square, and then at each subsequent iteration, the curve is subdivided into four smaller squares. The curve is then drawn through each of these squares in a specific order.","The intra-warrant attention mechanism uses a BiLSTM to encode the reason and claim, and then provides this encoded information as an attention vector to LSTM layers for each warrant. The attention vector allows the model to focus on specific parts of the reason and claim that are most relevant to each warrant.",text_model_embed300_hidden150
1707.00524v2,What is the difference between the encoder and decoder networks in the action-conditional prediction model?,488,63,The encoder network takes a one-hot action and the current state as input and outputs a latent representation of the state. The decoder network takes the latent representation and outputs a prediction of the next state.,"In the simulation, the robot is able to pick up the object and place it in the desired location without any errors. However, in the real world, the robot makes some errors, such as dropping the object or placing it in the wrong location.",text_model_embed300_hidden150
1804.07849v4,"According to the ablation experiments, which factor contributes the most to the best model's performance compared to the baseline model?",254,526,Morphological modeling with LSTMs contributes the most to the best model's performance compared to the baseline model.,"GroundSent-Cap appears to be most beneficial for the MRPC task, achieving an accuracy of 72.9/82.2 compared to the baseline model ST-LN's 69.6/81.2.",text_model_embed300_hidden150
1811.09393v4,Which method has the best perceptual performance according to the tOF score?,349,333,TecoGAN.,UnCoRd-VG-E,text_model_embed300_hidden150
1805.04687v2,"Why does the proposed dataset have a lower number of persons per image compared to the Cityscapes dataset, even though it has a much higher total number of pedestrians?",375,56,"The proposed dataset contains non-city scenes like highways, which typically have fewer pedestrians per image compared to cityscapes.",The complexity of the cake shape generally leads to a higher minimum number of blanks required for a complete partition.,text_model_embed300_hidden150
1812.00281v3,"What is the difference between the ""median appearance"" and the ""view-specific appearance""?",442,10,"The median appearance is the average of all the multiview images, while the view-specific appearance is a single image that is rendered from a specific viewpoint.","The residual block assembles two residual branches sequentially, while the merge-and-run block assembles the same two residual branches in parallel.",text_model_embed300_hidden150
1805.08465v3,Which steganography method achieves the best performance in terms of distortion for both cover and secret images when embedding 2 bits per channel?,514,629,The proposed method achieves the best performance for both cover and secret images when embedding 2 bits per channel.,"ACNN performs best on ""Who"" questions.",text_model_embed300_hidden150
1811.02553v4,How does the number of state-action pairs affect the optimization landscape for the PPO algorithm?,234,249,"As the number of state-action pairs increases, the optimization landscape becomes more complex and has more local optima. This makes it more difficult for the PPO algorithm to find the global optimum.",The NegPair reduction generally increases as the number of perfect results in a query increases.,text_model_embed300_hidden150
1805.04687v2,How does the BDD100K dataset compare to the KITTI and MOT17 datasets in terms of size and complexity?,386,74,"The BDD100K dataset is significantly larger and more complex than both the KITTI and MOT17 datasets. It contains roughly 40 times more frames, 16 times more sequences, and 13 times more identities than KITTI. Compared to MOT17, BDD100K has about 10 times more frames, 80 times more sequences, and 8 times more identities. This increase in size and complexity makes BDD100K a more challenging and comprehensive benchmark for multiple object tracking algorithms. ",The Filtering algorithm performs better than MLE with noise in both the random tree and random graph settings.,text_model_embed300_hidden150
1707.08608v3,Which genre in the SRL-NW network has the lowest failure rate and how does its inference time compare to other genres within the same network?,530,18,"The PT genre within the SRL-NW network has the lowest failure rate at 10.01%. Its inference time is also the lowest across all genres in the SRL-NW network for all three inference procedures (Viterbi, GBI, and A*).","GeoCUTS consistently outperforms the Grid method in identifying highly mobile clusters, regardless of the number of clusters. However, the performance of both methods decreases as the number of clusters increases.",text_model_embed300_hidden150
1804.05938v2,"Which correction method resulted in the best performance in terms of nDCG@10 and ERR@10, and how does it compare to not using any correction method?",322,105,"The DNN trained with DLA achieved the best performance in terms of both nDCG@10 (0.421) and ERR@10 (0.582). Compared to not using any correction method (NoCorrect), DLA shows a significant improvement in both metrics, with nDCG@10 being higher by 0.063 and ERR@10 being higher by 0.082.",The C-Tarone method has higher precision and F-measure than the binarization method in all datasets. The C-Tarone method has better or competitive recall than the binarization method. The running time of the C-Tarone method is competitive with the binarization method.,text_model_embed300_hidden150
1704.07854v4,"Which of the two scenes, Drop or Staris, requires more computation time for rendering?",220,411,Staris,"Multi-X performed worse than PEARL in test case (6), with a misclassification error of 21.72% compared to PEARL's 17.35%. ",text_model_embed300_hidden150
1605.07496v3,How does the predicted return change as a function of θ for a fixed value of π = 1.5?,70,34,"The predicted return decreases as θ increases, with a minimum at around θ = 0.5.",Pre-training with the ordering task increases the ROUGE-L score for extractive summarization.,text_model_embed300_hidden150
1812.06589v2,What is the role of the frame discriminator in the proposed method?,464,297,The frame discriminator is used to detect whether the generated frame and audio are matched or not.,"The filter is used to extract features from the input image. It is a small matrix that is applied to each pixel in the image, and the result is a new pixel value.",text_model_embed300_hidden150
1809.01989v2,Which method achieved the highest tracking accuracy in terms of minimizing the sum of absolute percentage errors? Does this necessarily mean it had the best overall performance?,646,425,"The Ridge method achieved the lowest sum of absolute percentage errors (136.84), indicating the highest tracking accuracy in terms of minimizing absolute deviations from the index. However, this doesn't necessarily translate to the best overall performance.","ChoiceNet generally performed better than MDN in the HalfCheetah task. This is evident from the higher average returns of ChoiceNet across all outlier percentages (10%, 20%, and 30%).

The performance gap between ChoiceNet and MDN appears to decrease as the percentage of outliers increases. At 10% outliers, ChoiceNet has a significantly higher average return than MDN (2068.14 vs. 192.53). However, at 30% outliers, the difference in average return is smaller (2035.91 vs. 363.08).",text_model_embed300_hidden150
1704.07854v4,Which of the methods is able to reconstruct the shape of the liquid properly?,223,350,Only the full method with a deformation network is able to produce a perfect reconstruction.,TecoGAN,text_model_embed300_hidden150
1705.09966v2,What is the difference between the input and output of the frontal face generation process?,344,192,The input is a low-resolution frontal face image and a high-resolution side-face image. The output is a high-resolution frontal face image.,The representation module takes an input image and outputs a feature representation. The learning-to-learn module takes a set of features and learns how to segment the image.,text_model_embed300_hidden150
1805.06431v4,Which of the four methods has the best performance in terms of average error for the step function?,423,100,The proposed method.,The SPIRAL-MSM-kMeans method performs the best in terms of NMI with a score of 0.365. It outperforms the other methods on 89.4% of the datasets.,text_model_embed300_hidden150
1705.09882v2,How does the proposed split-rate RGB-to-Depth transfer scheme differ from the R3D [90] method of Yosinski et al.?,326,132,"The proposed split-rate RGB-to-Depth transfer scheme differs from the R3D [90] method in two ways. First, the proposed method uses a different learning rate for the bottom three layers of the network. Second, the proposed method uses a different initialization for the weights of the bottom three layers of the network.",The BLEU score decreases as the initial accuracy of the discriminator increases.,text_model_embed300_hidden150
1812.06589v2,Which method performed the best according to the LMD metric?,463,333,AMIE (Ours),UnCoRd-VG-E,text_model_embed300_hidden150
1706.08146v3,What is the effect of increasing the projection dimension d on the approximation error for sparse PCA and NMF?,505,291,Increasing the projection dimension d decreases the approximation error for both sparse PCA and NMF.,The setup and online time for the Softmax increases as the number of classes increases.,text_model_embed300_hidden150
1603.00286v5,What is the minimum number of sides that a rectilinear polygon with four reflex vertices must have?,58,415,Six.,ChoiceNet,text_model_embed300_hidden150
1704.05426v4,Which type of word has the greatest difference in frequency of occurrence between MultiNLI and SNLI?,156,371,Negation (PTB),City Street,text_model_embed300_hidden150
1811.02721v3,How does varying the buffer size affect TCP goodput?,205,568,"Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point.","The intra-warrant attention mechanism uses a BiLSTM to encode the reason and claim, and then provides this encoded information as an attention vector to LSTM layers for each warrant. The attention vector allows the model to focus on specific parts of the reason and claim that are most relevant to each warrant.",text_model_embed300_hidden150
1805.04687v2,Which category of object is the least common in the dataset?,385,378,Train,Cars are the most common object in the dataset.,text_model_embed300_hidden150
1703.02507v3,Which dataset has the shortest average sentence length?,85,65,Headlines.,MAP Policy,text_model_embed300_hidden150
1608.02784v2,What is the relationship between BLEU score and human ranking for CCA and SMT systems?,32,329,The correlation between BLEU scores and human ranking is not high for either CCA or SMT systems.,"The Bernoulli parameter is a measure of the probability of a pixel being foreground or background. The higher the Bernoulli parameter, the more likely the pixel is to be foreground. This is reflected in the images, where the pixels with higher Bernoulli parameters are more likely to be part of the person's silhouette.",text_model_embed300_hidden150
1803.03467v4,How does the dimension of embedding affect the AUC of RippleNet on MovieLens-1M?,147,49,The AUC of RippleNet first increases and then decreases with the increase of the dimension of embedding.,RCV1,text_model_embed300_hidden150
1611.07718v2,How does the classification error of a residual network change as the average path length increases?,15,118,The classification error of a residual network generally increases as the average path length increases.,The CPU overhead of classic delta-based is consistently higher than that of delta-based BP+RR as the Zipf coefficient increases.,text_model_embed300_hidden150
1705.07164v8,Which method achieved the highest Inception Score (IS) at the end of training for both CIFAR10 and ImageNet datasets? Did this method also achieve the highest initial IS score?,270,645,"For CIFAR10, WGAN achieved the highest IS at the end of training (2.42). However, RWGAN had a higher initial IS score (1.86) compared to WGAN's 1.63. 

For ImageNet, WGAN again achieved the highest final IS (2.80), while RWGAN had a slightly higher initial IS (2.04 vs. 2.00). ","For all datasets presented, Incremental SVM achieved a slightly lower OFV compared to FISVDD. However, this does not necessarily mean that Incremental SVM is definitively better.",text_model_embed300_hidden150
1605.07496v3,Which of the algorithms performs the best on the robotic arm joint breakage task?,66,607,ALOQ.,KAR,text_model_embed300_hidden150
1805.01216v3,"Why might the authors claim that although BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, it still performs better in conveying necessary entity information?",318,469,"While BOSSNET has a lower BLEU score than Mem2Seq on SMD, it achieves the highest Entity F1 score on that dataset. This suggests that BOSSNET is better at capturing and including the relevant entities in its responses, even though it may not have as much lexical overlap with the gold responses as Mem2Seq.","When trained with only 1% of the MNIST training data, ITN (B-CNN) (w/ DA) performs the best with a testing error of 2.78%. Data augmentation further improves its performance by 0.4%, bringing the testing error down to 2.78% from 3.18% achieved by ITN (B-CNN) without data augmentation.",text_model_embed300_hidden150
1812.00281v3,How does the number of cameras used affect the accuracy of the garment reconstruction?,440,51,The accuracy of the garment reconstruction increases as the number of cameras used increases.,The proposed method appears to be more accurate than the baseline method. The depth maps generated by the proposed method are more detailed and realistic than those generated by the baseline method.,text_model_embed300_hidden150
1605.07496v3,Which algorithm performs the best in the Joint Breakage experiment?,67,603,ALOQ,P-FC,text_model_embed300_hidden150
1603.00286v5,Which agent values the entire share $Z_j$?,54,451,Agent $j$.,VIDXL has the highest Recall@20 and MRR@20.,text_model_embed300_hidden150
1701.03077v10,Why did the authors choose to use a nonlinearity to curve α before fitting the cubic hermite spline?,45,73,"The authors chose to use a nonlinearity to curve α before fitting the cubic hermite spline because it allows for increased knot density near α = 2 and decreased knot density when α > 4. This helps to better approximate the log partition function, which is difficult to evaluate for arbitrary inputs.","The equation that describes the motion of a mass attached to a spring is:
```
m d^2 X / dt^2 + kX = 0
```
where:
* m is the mass of the object
* X is the displacement of the object from its equilibrium position
* k is the spring constant
* t is time",text_model_embed300_hidden150
1703.10730v2,What are the inputs to the image generation network?,139,568,The inputs to the image generation network are the observed images (x) and a random noise vector (z).,"The intra-warrant attention mechanism uses a BiLSTM to encode the reason and claim, and then provides this encoded information as an attention vector to LSTM layers for each warrant. The attention vector allows the model to focus on specific parts of the reason and claim that are most relevant to each warrant.",text_model_embed300_hidden150
1809.00458v1,Which dataset has the highest average record length?,557,451,CaOpenData,VIDXL has the highest Recall@20 and MRR@20.,text_model_embed300_hidden150
1709.02418v2,What is the effect of performing a left-swap on a binary vector y at index j′?,647,415,The left-swap increases the number of misclassified pairs by one.,ChoiceNet,text_model_embed300_hidden150
1809.00458v1,What is the relationship between the element-hash value pairs and the signature size?,558,19,"The element-hash value pairs are the elements of the signature, and the signature size is the number of element-hash value pairs in the signature."," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed300_hidden150
1805.06431v4,What is the purpose of the Cholesky Block in this figure?,427,371,The Cholesky Block is used to distinguish abnormal patterns from normal patterns.,City Street,text_model_embed300_hidden150
1809.03149v2,What is the effect of using CHER on the percentage of ads displayed for each user?,599,335,The percentage of ads displayed for each user is higher when CHER is used.,Training on more diverse data improves the accuracy of graph representation for VQA.,text_model_embed300_hidden150
1707.00189v3,"Which model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, and how does its performance compare to the baselines?",500,300,"The Conv-KNRM model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, achieving an nDCG@20 score of 0.3215. This performance is significantly better than all the baselines: BM25 (B), WT10 (W), and AOL (A).","The model with the highest test accuracy is MTSA, with an accuracy of 86.3%. Its training time per epoch is 180s, which is faster than the training time of several other models with lower accuracy, such as Bi-LSTM (854s), Bi-GRU (850s), and DiSA (390s).",text_model_embed300_hidden150
1811.02553v4,How does the number of state-action pairs affect the reward landscape for the surrogate and true reward functions?,233,367,"As the number of state-action pairs increases, the reward landscape for both the surrogate and true reward functions becomes smoother and more accurate.",Increasing the training set size generally leads to improved performance for both lane marking and drivable area segmentation tasks.,text_model_embed300_hidden150
1805.08751v2,What is the role of the GDU and HFLU modules in the FAKEDETECTOR framework?,524,597,"The GDU (Gated Dilated Unit) modules are responsible for extracting features from the input data, while the HFLU (Hybrid Feature Learning Unit) modules are responsible for fusing the features extracted by the GDU modules.",The Higher Level Policy sets constraints for the next sub-trajectory and provides information about the previous stage to the Lower Level Policy.,text_model_embed300_hidden150
1803.04572v2,Which dataset has the largest number of clinical visits per patient?,154,287,CMS,SVHN,text_model_embed300_hidden150
1802.07459v2,What are the different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents?,103,350,"The different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents are: (a) Representation, (b) Encoding, (c) Transformation, and (d) Aggregation.",TecoGAN,text_model_embed300_hidden150
1707.01917v2,"What does the induced schema Win <A4, B3, C2> represent?",494,287,"The induced schema Win <A4, B3, C2> represents the fact that player A4 won tournament C2, defeating player B3.",SVHN,text_model_embed300_hidden150
1608.02784v2,What is the relationship between the input space and the output space in CCA inference?,30,19,The input space and the output space are related by a cosine similarity measure.," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed300_hidden150
1802.07351v2,Explain the rationale behind using five deformable cost volumes with different hyperparameter settings in Devon's relation module.,94,268,"The five deformable cost volumes in Devon's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery. This is achieved by using different neighborhood sizes (k) and dilation rates (r) for each cost volume, as shown in Table 1. Smaller neighborhood sizes and dilation rates result in denser correspondences, focusing on finer details and small displacements, while larger values capture broader context and larger motions.",The training curves for the ACGAN show that the generator and discriminator losses both decrease over time. This indicates that the ACGAN is able to learn to generate realistic images.,text_model_embed300_hidden150
1804.05936v2,Which relevance label category of documents received the most significant rank promotion according to the NegPair reduction metric?,247,350,The perfect results received the largest promotions in rank.,TecoGAN,text_model_embed300_hidden150
1811.08257v1,Which operation has the lowest online time?,298,510,ReLU,MedBook + MKG,text_model_embed300_hidden150
1704.07854v4,How do the parameter network and the deformation network differ in terms of complexity and function?,217,52,"The parameter network is a simple structure with two fully connected layers, while the deformation network is more complex and contains two fully connected layers followed by two or more four-dimensional de-convolution layers. The parameter network learns how to apply multiple long-range, non-linear deformation fields, while the deformation network learns to generate dense deformation fields to refine the final surface.",Reconstructions from models using general distributions tend to be sharper and more detailed than reconstructions from the corresponding model that uses normal distributions.,text_model_embed300_hidden150
1811.10673v1,How does the quality of the reconstructed frames change as the quantization level of the soft edge detector increases?,405,228,The quality of the reconstructed frames increases as the quantization level of the soft edge detector increases.,The performance of the SIM saliency map increases as the number of fixations increases.,text_model_embed300_hidden150
1812.10735v2,Why do you think the performance of all models is generally lower on Rest15 compared to Rest14?,491,629,The performance of all models is generally lower on Rest15 because it has a larger number of aspect categories (13) compared to Rest14 (5). This increased complexity makes it more challenging for the models to accurately identify and classify the aspects.,"ACNN performs best on ""Who"" questions.",text_model_embed300_hidden150
1809.01246v1,How does the average precision of TCM(256*memory) compare to the other two algorithms in the email-EuAll dataset?,581,140,The average precision of TCM(256*memory) is lower than the other two algorithms in the email-EuAll dataset.,"The presence of noise in the input image can degrade the quality of the generated images, but the proposed algorithm is still able to generate realistic images even with a certain amount of noise.",text_model_embed300_hidden150
1809.01246v1,What is the relationship between the table and the graph sketch in the figure?,578,554,"The table provides the mapping between the nodes in the original graph and their corresponding hash values, which are used to create the graph sketch.","The Jaccard similarity measures the overlap between two sets, while the containment similarity measures how much one set is contained within another set.",text_model_embed300_hidden150
1805.06447v3,Describe the relationship between the update threshold (Tu) and the performance of ITN (B-CNN) on the MNIST dataset.,475,390,The performance of ITN (B-CNN) on the MNIST dataset decreases as the update threshold (Tu) increases. This is evident from the increasing ITN error percentages as Tu goes from 1e-3 to 1e-1.,The most effective attack method at reducing the accuracy of the Resnet-32 model on the MNIST dataset is BIM/CE.,text_model_embed300_hidden150
1803.04572v2,Which constraint has the most significant impact on the FIT values for the CMS data set when the target rank is 15?,148,90,The smoothness constraint on $\M{U_k}$ has the most significant impact on the FIT values for the CMS data set when the target rank is 15.,Removing the normalization in the relation modules had the most significant negative impact on performance for the KITTI 2015 dataset.,text_model_embed300_hidden150
1803.06506v3,"How does the quality of the output heatmap change when the selected concept, predicted concept, and the real entity to be grounded are all aligned?",165,425,"When the selected concept, predicted concept, and the real entity to be grounded are all aligned, the generated heatmap produces a good localization of the phrase.","ChoiceNet generally performed better than MDN in the HalfCheetah task. This is evident from the higher average returns of ChoiceNet across all outlier percentages (10%, 20%, and 30%).

The performance gap between ChoiceNet and MDN appears to decrease as the percentage of outliers increases. At 10% outliers, ChoiceNet has a significantly higher average return than MDN (2068.14 vs. 192.53). However, at 30% outliers, the difference in average return is smaller (2035.91 vs. 363.08).",text_model_embed300_hidden150
1704.05426v4,Which model performs better on the MultiNLI dataset when considering the percentage of individual labels that match the author's label?,157,100,"SNLI performs better than MultiNLI when considering the percentage of individual labels that match the author's label. SNLI has a score of 85.8%, while MultiNLI has a score of 85.2%.",The SPIRAL-MSM-kMeans method performs the best in terms of NMI with a score of 0.365. It outperforms the other methods on 89.4% of the datasets.,text_model_embed300_hidden150
1809.00458v1,Which algorithm performs better in terms of F1 score and precision when the space used is 5%?,556,402,GB-KMV performs better in terms of F1 score and precision when the space used is 5%.,The proposed model delivers significantly better visual quality at low bitrates than H.264.,text_model_embed300_hidden150
1809.04276v2,How does the performance of the discriminator in the proposed approach compare to the conventional discriminator in AL? What evidence suggests this difference in performance?,641,422,The discriminator in the author's approach achieves higher accuracy (95.72%) compared to the conventional discriminator in AL (94.01%).,The WideResNet model has higher accuracy than the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle.,text_model_embed300_hidden150
1702.03584v3,How does the observed error compare to the underlying true error as CPU time increases?,98,118,"The observed error is initially higher than the underlying true error, but it quickly decreases and converges to the true error as CPU time increases.",The CPU overhead of classic delta-based is consistently higher than that of delta-based BP+RR as the Zipf coefficient increases.,text_model_embed300_hidden150
1705.02946v3,"What is the distance from equitability for the allocation that can be obtained by cutting at $x$ with the player order $(1,2)$?",266,121,The distance from equitability is $b-a$.,The hierarchical part dictionary learned with the bottom-up process is a set of parts that can be combined to create objects. The holistic object model learned with the top-down process is a single model that represents the entire object.,text_model_embed300_hidden150
1701.03077v10,"On which dataset did the gRCC* algorithm achieve the largest relative improvement over the RCC algorithm, and by approximately how much did it improve?",41,200,"The gRCC* algorithm achieved the largest relative improvement over the RCC algorithm on the YTF dataset, with a relative improvement of approximately 31.9%.","The actions that are most challenging for the network to recognize are those that include moving directions, such as ""person, move toward (home)"", ""person, move away (home)"", and ""vehicle, move toward (person)"". The proposed methods, distance-based place discretization (DD) and topological feature aggregation (Topo-Agg), significantly improve the average precision on almost all action categories, especially those that are more challenging and are associated with moving directions.",text_model_embed300_hidden150
1811.02721v3,"Which TCP stack provides the most complete implementation of core TCP features, and which stack lacks the most features?",214,350,"The TCP stack presented in this paper (TCPlp) provides the most complete implementation of core TCP features, including flow control, congestion control, RTT estimation, MSS option, OOO reassembly, and various advanced features like timestamps and selective ACKs. In contrast, BLIP lacks the most features, as it does not implement congestion control, RTT estimation, or several other functionalities present in other stacks.",TecoGAN,text_model_embed300_hidden150
1707.01917v2,What is the shape of the tensor $x^1$ for the Shootings dataset?,496,356,The shape of the tensor $x^1$ for the Shootings dataset is 3365 x 1295 x 50.,5.00E-05,text_model_embed300_hidden150
1811.08481v2,Which estimator achieves the highest accuracy on the CLEVR validation set?,336,8,Size estimator.,DMRNet-Wide,text_model_embed300_hidden150
1804.04410v2,How does the performance of the learned policy compare to the production baseline for CAT2 queries in terms of relevance and efficiency?,227,40,"For CAT2 queries, the learned policy shows a slight improvement in relevance (NCG) for the weighted set and a significant reduction in index blocks accessed for both weighted and unweighted sets.",The adaptive model consistently outperforms the fixed model for all values of α.,text_model_embed300_hidden150
1812.00281v3,What is the relationship between the camera yaw angle and the silhouette distance?,433,19,The silhouette distance generally increases as the camera yaw angle increases.," The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph.",text_model_embed300_hidden150
1901.00398v2," Which type of review was more accurately identified by the human evaluators, human-written or machine-generated? ",521,418,The human evaluators were more accurate at identifying human-written reviews than machine-generated reviews.,Mixture of classifiers.,text_model_embed300_hidden150
1608.02784v2,What is the role of the temperature variable t in the CCA decoding algorithm?,31,257,"The temperature variable t controls the probability of accepting a new candidate solution y. As t decreases, the probability of accepting a worse solution decreases.",The BiLSTM takes as input the character-level representations of the words and outputs a word-level representation for each word.,text_model_embed300_hidden150
1707.06320v2,How do the word embeddings learned by the Cap2Img model compare to the original GloVe embeddings in terms of semantic similarity?,528,616,The word embeddings learned by the Cap2Img model outperform the original GloVe embeddings in terms of semantic similarity.,"The Daitch hard scalable model has a higher connectivity than the Daitch soft scalable model. This can be seen in the figure, where the bars for the hard model are generally higher than the bars for the soft model.",text_model_embed300_hidden150
1707.01917v2,Which method achieves the highest accuracy on the Shootings dataset?,499,285,TFBA,PC-DenseNet-161,text_model_embed300_hidden150
1803.04572v2,How do the temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients?,151,235,"The temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients in terms of both shape and magnitude. For sickle cell anemia patients, the patterns are generally smoother and more periodic, with lower overall magnitude. For leukemia patients, the patterns are more erratic and have higher overall magnitude.",TRPO generally converges faster to the true gradient than PPO.,text_model_embed300_hidden150
1811.10673v1,How does the proposed method compare to H.264 in terms of MS-SSIM score at low bitrates?,398,402,The proposed method achieves significantly higher MS-SSIM scores than H.264 at bitrates below 10 Kbps.,The proposed model delivers significantly better visual quality at low bitrates than H.264.,text_model_embed300_hidden150
1811.10673v1,How does the quality of the reconstructed frames change as the resolution increases?,404,474,The quality of the reconstructed frames increases monotonically as the resolution increases.,The quality of the generated samples decreases as the update threshold increases.,text_model_embed300_hidden150
1803.02750v3,Which topology has the highest transmission rate for GMap 100%?,115,478,Mesh,F-DSS,text_model_embed300_hidden150
1704.07854v4,How do the initial conditions of the simulations vary?,224,191,The initial conditions of the simulations vary in two dimensions: the position of the liquid drop along the x-axis (α1) and the size of the drop (α2).,The reconstructions are very similar to the original samples.,text_model_embed300_hidden150
1812.00281v3,How does HUMBI capture diverse appearance of human expressions?,441,161,"HUMBI includes 772 distinctive subjects across gender, ethnicity, age, clothing style, and physical condition, which generates diverse appearance of human expressions.",Conventional distant supervision can lead to wrong labeling of textual relations with KB relations.,text_model_embed300_hidden150
1805.04687v2,Which weather condition has the highest classification accuracy?,377,451,Clear weather.,VIDXL has the highest Recall@20 and MRR@20.,text_model_embed300_hidden150
1703.04887v4,"Which model and configuration achieves the best performance on the Chinese-English translation task, and how much improvement does it offer compared to the baseline RNNSearch model?",134,526,The Transformer+BR-CSGAN model with λ=0.8 achieves the best performance on the Chinese-English translation task with an average BLEU score of 42.61. This represents an improvement of 0.81 BLEU points compared to the baseline RNNSearch model.,"GroundSent-Cap appears to be most beneficial for the MRPC task, achieving an accuracy of 72.9/82.2 compared to the baseline model ST-LN's 69.6/81.2.",text_model_embed300_hidden150
1703.04887v4,What is the relationship between the number of Monte Carlo samples (N) and the translation performance of the BR-CSGAN model? Why is there a trade-off when choosing the value of N?,131,123,"The table and passage show that the translation performance of the BR-CSGAN model generally improves as the number of Monte Carlo samples (N) increases. However, this improvement plateaus after N reaches a certain point (around 20 in this case).

There is a trade-off when choosing the value of N because increasing N also increases the computational complexity and training time. While a higher N leads to more accurate reward estimations and better performance, it also requires more computational resources and longer training times. Therefore, choosing the optimal N involves balancing the desired performance with the available computational resources and time constraints.","When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.

With classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.
Without classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.

This indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied.",text_model_embed300_hidden150
1708.05239v3,How does the performance of the PE-N=5 sampler compare to the HMC sampler?,573,226,The PE-N=5 sampler performs better than the HMC sampler.,The RL policy accesses fewer index blocks than the baseline.,text_model_embed300_hidden150
1805.06447v3,How does the ITN framework generate pseudo-negative samples?,470,574,The ITN framework generates pseudo-negative samples by applying learned transformations to positive samples.,"Square hashing is a process that uses two hash functions to map a source/destination pair to a bucket in a two-dimensional array. The first hash function, h_i(s), maps the source address to a row in the array, and the second hash function, h_i(d), maps the destination address to a column in the array. The intersection of the row and column is the bucket where the fingerprint is stored.",text_model_embed300_hidden150
1701.03077v10,"What is the effect of replacing the loss function in the ""Baseline"" network with the ""adaptive"" loss over wavelet coefficients?",43,5,"Replacing the loss function in the ""Baseline"" network with the ""adaptive"" loss over wavelet coefficients results in significantly improved depth estimates.",The ReOrth Layer re-orthogonalizes the output of the FRMap Layer.,text_model_embed300_hidden150
1611.05742v3,"Which method performs best on the PaSC dataset for the handheld testing scenario (PaSC2), and how does its performance compare to other methods?",7,509,"The method that performs best on the PaSC dataset for the handheld testing scenario (PaSC2) is SPDNet, with an accuracy of 72.83%. This performance is slightly higher than GrNet-2Blocks (72.76%) and significantly higher than other methods like VGGDeepFace (68.24%) and DeepO2P (60.14%).","The SYNONYMNET(Pairwise) model with Leaky Unit performs best on the PubMed + UMLS dataset, achieving an AUC of 0.9838 and a MAP of 0.9872. This is a statistically significant improvement over the DPE baseline, which achieved an AUC of 0.9513 and a MAP of 0.9623.",text_model_embed300_hidden150
1707.01922v5,What is the difference between testing domain adaptation and testing sensor fusion?,515,89,"In testing domain adaptation, the source and target CNNs are trained on different domains, and the joint classifier is used to predict the class of the target data. In testing sensor fusion, the source and target CNNs are trained on the same domain, and the joint classifier is used to predict the class of the target data using both the source and target data.","A standard cost volume computes the matching costs for a neighborhood of the same location on the feature maps of the first and second images. A deformable cost volume computes the matching costs for a dilated neighborhood of the same location on the feature maps of the first and second images, offset by a flow vector.",text_model_embed300_hidden150
1611.02654v2,What can you say about the relationship between the sentences in a document based on the t-SNE embeddings?,36,487,Sentences that are closer together in the embedding space are more semantically similar than those that are farther apart.,"The predicted frame is generated by the prediction model, while the reconstructed frame is generated by the autoencoder. The predicted frame is typically more accurate than the reconstructed frame, as the prediction model is trained to predict the future state of the environment, while the autoencoder is only trained to reconstruct the input image.",text_model_embed300_hidden150
1804.07849v4,"Which method achieved the highest average V-measure (VM) across all languages, and how much higher was its average compared to the Baum-Welch method?",255,645,"The Variational $\wh{J}^{\mathrm{var}}$ method achieved the highest average VM score (50.4). Its average score is 39.6 points higher than the Baum-Welch method, which achieved an average VM score of 10.8.","For all datasets presented, Incremental SVM achieved a slightly lower OFV compared to FISVDD. However, this does not necessarily mean that Incremental SVM is definitively better.",text_model_embed300_hidden150
1811.08257v1,How is convolution represented in the frequency domain?,290,582,"In the frequency domain, convolution is represented by element-wise multiplication.",Edge query.,text_model_embed300_hidden150
1706.00633v4,Which combination of training procedure and thresholding metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types?,389,350,RCE training combined with the K-density metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types.,TecoGAN,text_model_embed300_hidden150
1706.03847v3,What is the performance of GRU4Rec relative to the baseline in terms of watch time?,447,615,GRU4Rec has a slightly higher performance than the baseline in terms of watch time.,Adding Gaussian noise to the images increases the measured sparsity.,text_model_embed300_hidden150
1710.05654v2,"How well do the approximate bounds of $\theta$ predict sparsity in the ""spherical"" dataset?",613,371,"The approximate bounds of $\theta$ are very effective at predicting sparsity in the ""spherical"" dataset.",City Street,text_model_embed300_hidden150
1811.08257v1,What is the function of the DataPreprocessing function?,293,371,"The DataPreprocessing function performs Yao Sharing, which is a cryptographic technique for securely sharing data between multiple parties.",City Street,text_model_embed300_hidden150
1709.02755v5,"Based on the table, how does the training process handle large vocabulary sizes?",588,549,"The training process uses several techniques to handle large vocabulary sizes. These include:

1. **Token-based batching:** Instead of grouping sentences of similar lengths together, the training process batches together a fixed number of tokens (5120 tokens per batch). This approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation.
2. **Shared embedding:** This technique maps both source and target words to the same embedding space, effectively reducing the memory footprint needed to store word representations. 
3. **Positional encoding:** This method injects information about the position of words in a sentence into the model, helping it better understand long-range dependencies within the text. ","The CoNLL model performed best on the WikiCoref dataset, with an F1 score of 53.40 when using the +linguistic evaluation metric.",text_model_embed300_hidden150
1705.09882v2,What is the difference between the grayscale depth representation and the result after background subtraction?,327,71," The grayscale depth representation shows the depth of each pixel in the image, with darker pixels representing closer objects and lighter pixels representing further objects. The result after background subtraction shows only the foreground object, with the background removed.","The ""True max"" curve is the true maximum of the function, while the ""ALOQ"" curve is an approximation of the maximum. The ""ALOQ"" curve is lower than the ""True max"" curve, indicating that it underestimates the maximum value of the function.",text_model_embed300_hidden150
1605.07496v3,"Between WSN and ALOQ, which method is the most efficient in terms of runtime for both F-SRE1 and F-SRE2?",69,184,ALOQ is significantly more efficient than WSN.,The VQA dataset presents the biggest challenge.,text_model_embed300_hidden150
1704.05958v2,Can you estimate the percentage of entity pairs in the NYT training set that have a corresponding relational fact in the Knowledge Base (KB)?,160,448,Approximately 6.66%.,"The VIDXL dataset contains the most interactions (events) in the training set with 69,312,698 events. This is roughly 7.7 times larger than the RSC15 dataset, which has the least interactions (9,011,321) in the training set. ",text_model_embed300_hidden150
1705.02946v3,What is the upper bound on the query complexity for finding an ε-perfect allocation with minimum cuts for 3 or more players?,267,207,O(n^3 / ε),The difference in response time between CoAP and HTTP for a response size of 50 KiB is approximately 20 seconds.,text_model_embed300_hidden150
1705.09296v2,How does the model capture different perspectives on immigration when considering tone as a covariate?,311,269,"The model captures different perspectives on immigration by highlighting contrasting words associated with the same topic, depending on whether the tone is anti-immigration or pro-immigration.","It is difficult to say definitively which model performs better based on the training curves alone. However, it appears that the WGAN(g) model may be performing better than the other models, as its generator and discriminator losses are both lower than the other models.",text_model_embed300_hidden150
1703.04887v4,What is the role of the discriminator (D) in the proposed BR-CSGAN model?,135,644," The discriminator (D) is responsible for distinguishing between real sentence pairs translated by humans and generated sentence pairs produced by the generator (G). It provides feedback to G in the form of rewards, helping G improve its ability to generate realistic sentence pairs.",The LSTM network is used to process the post text and generate a post text embedding.,text_model_embed300_hidden150
1804.07849v4,"Which method achieved the highest accuracy on the 45-tag Penn WSJ dataset, and how does its performance compare to the other methods?",253,229,"The Variational $\wh{J}^{\mathrm{var}}$ method achieved the highest accuracy of 78.1% on the 45-tag Penn WSJ dataset. This is significantly higher than all other methods listed in the table, with the next best performing method (Berg-Kirkpatrick et al., 2010) achieving an accuracy of 74.9%.",The saliency map method with the highest sAUC score is **SIM**. Its sAUC score appears to be significantly higher than all other methods listed in the table.,text_model_embed300_hidden150
1705.09966v2,"Which of the methods among Conditional GAN, Unsupervised GAN and Consitional CycleGAN would you expect to produce images that are most visually similar to the real images in the CelebA dataset?",340,252,The Conditional CycleGAN method is expected to produce images most visually similar to the real images.,"LambdaMART initial list, DLCM model, and AttRank loss function achieved the best overall performance on the Yahoo! set 1, with an nDCG@10 of 0.743 and an ERR@10 of 0.453.",text_model_embed300_hidden150
1805.06431v4,How does the performance of the different models change as the corruption level increases? Which model appears to be the most robust to label corruption?,419,526,"As the corruption level increases, the performance of all models decreases. However, ChoiceNet consistently outperforms both ConvNet and ConvNet+Mixup across all corruption levels, maintaining high accuracy even when almost half of the labels are incorrect. This suggests that ChoiceNet is significantly more robust to label corruption compared to the other models.","GroundSent-Cap appears to be most beneficial for the MRPC task, achieving an accuracy of 72.9/82.2 compared to the baseline model ST-LN's 69.6/81.2.",text_model_embed300_hidden150
1811.02721v3,"Based on Table 1 and the passage, why does TCP perform poorly on IEEE 802.15.4 networks compared to other network types listed? ",203,180,"TCP performs poorly on IEEE 802.15.4 networks because the Maximum Transmission Unit (MTU) for these networks is significantly smaller than other network types. This small MTU size results in a high percentage of overhead due to the TCP/IP headers, exceeding 50%. ","The MLP-IQA model achieved the highest accuracy in the ""All"" category of Visual7W, with a score of 45.1%. However, this performance still falls significantly short of human performance, which stands at 84.1% for the same category.",text_model_embed300_hidden150
