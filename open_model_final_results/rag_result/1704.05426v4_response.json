{"0": {"question": "What are the three types of sentences that the annotators are asked to write?", "response": {"1704.05426v4-Figure1-1.png": ["1 2 <s>", "Descriptive <s>"]}, "referred_figures_names": ["1704.05426v4-Figure1-1.png"], "answer": "The three types of sentences are: \n1. A sentence that is definitely correct about the situation or event in the line.\n2. A sentence that might be correct about the situation or event in the line.\n3. A sentence that is definitely incorrect about the situation or event in the line."}, "1": {"question": "Which type of word has the greatest difference in frequency of occurrence between MultiNLI and SNLI?", "response": {"1704.05426v4-Table5-1.png": ["1980s <s>", "Dev. Freq. is the percentage of dev. set examples that include each phenomenon, ordered by greatest difference in frequency of occurrence (Diff.) between MultiNLI and SNLI. Most Frequent Label specifies which label is the most frequent for each tag in the MultiNLI dev. set, and % is its incidence. Model Acc. is the dev. set accuracy (%) by annotation tag for each baseline model (trained on MultiNLI only). (PTB) marks a tag as derived from Penn Treebank-style parser output tags (Marcus et al., 1993). <s>"]}, "referred_figures_names": ["1704.05426v4-Table5-1.png"], "answer": "Negation (PTB)"}, "2": {"question": "Which model performs better on the MultiNLI dataset when considering the percentage of individual labels that match the author's label?", "response": {"1704.05426v4-Table2-1.png": ["50% <s>", "MultiNLI <s>"]}, "referred_figures_names": ["1704.05426v4-Table2-1.png"], "answer": "SNLI performs better than MultiNLI when considering the percentage of individual labels that match the author's label. SNLI has a score of 85.8%, while MultiNLI has a score of 85.2%."}, "3": {"question": "Which genre in the MultiNLI corpus has the highest percentage of sentences where the Stanford Parser produced a parse rooted with an 'S' (sentence) node, and how does this compare to the overall average for the corpus?", "response": {"1704.05426v4-Table3-1.png": ["<s>", "<s>"]}, "referred_figures_names": ["1704.05426v4-Table3-1.png"], "answer": "The genre with the highest percentage of 'S' parses is **9/11**, with **99%** of its sentences receiving this parse. This is higher than the overall average for the MultiNLI corpus, which sits at **91%**."}, "4": {"question": "How does the performance of the ESIM model differ when trained on MNLI alone versus trained on both MNLI and SNLI combined?", "response": {"1704.05426v4-Table4-1.png": ["Yes <s>", "<s>"]}, "referred_figures_names": ["1704.05426v4-Table4-1.png"], "answer": "When trained on MNLI alone, the ESIM model achieves an accuracy of 60.7% on SNLI, 72.3% on matched genres in MNLI, and 72.1% on mismatched genres in MNLI. However, when trained on both MNLI and SNLI combined, the ESIM model's performance improves across all tasks, reaching 79.7% accuracy on SNLI, 72.4% on matched MNLI genres, and 71.9% on mismatched MNLI genres."}}