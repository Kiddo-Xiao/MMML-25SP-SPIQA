{"0": {"question": "What is the role of the auxiliary discriminator $D_{X_{\\textit{aux}}}$ in the Conditional CycleGAN for identity-guided face generation?", "response": {"1705.09966v2-Figure3-1.png": ["Yes <s>", "The role of the auxiliary discriminator $D_{X_{\\textit{aux}}}$ in the Conditional CycleGAN for identity-guided face generation is to incorporate a face verification network as both the source of conditional vector z and the proposed identity loss. <s>"]}, "referred_figures_names": ["1705.09966v2-Figure3-1.png"], "answer": " The auxiliary discriminator $D_{X_{\\textit{aux}}}$ helps to enforce the identity constraint in the generated image. It takes the generated image or the ground truth image as input and outputs a feature embedding. This embedding is then used to compute the identity loss, which encourages the generated image to have the same identity as the input image."}, "1": {"question": "How does the proposed method compare to the method in~\\cite{kim2017learning}?", "response": {"1705.09966v2-Figure8-1.png": ["1 <s>", "The proposed method outperforms the method in~\\cite{kim2017learning} <s>"]}, "referred_figures_names": ["1705.09966v2-Figure8-1.png"], "answer": "The proposed method produces more realistic and natural-looking images than the method in~\\cite{kim2017learning}."}, "2": {"question": "Which of the methods among Conditional GAN, Unsupervised GAN and Consitional CycleGAN would you expect to produce images that are most visually similar to the real images in the CelebA dataset?", "response": {"1705.09966v2-Table1-1.png": ["1 <s>", "Conditional GAN <s>"]}, "referred_figures_names": ["1705.09966v2-Table1-1.png"], "answer": "The Conditional CycleGAN method is expected to produce images most visually similar to the real images."}, "3": {"question": "How does the proposed attribute-guided face generation method compare to conventional face super-resolution methods in terms of identity preservation?", "response": {"1705.09966v2-Figure1-1.png": ["Yes <s>", "The proposed attribute-guided face generation method outperforms conventional face super-resolution methods in terms of identity preservation. <s>"]}, "referred_figures_names": ["1705.09966v2-Figure1-1.png"], "answer": "The proposed attribute-guided face generation method preserves the identity of the person in the high-resolution result, while conventional face super-resolution methods do not necessarily guarantee this."}, "4": {"question": "What role does the low-resolution input play in the identity-guided face generation process?", "response": {"1705.09966v2-Figure9-1.png": ["1 <s>", "Low-resolution input <s>"]}, "referred_figures_names": ["1705.09966v2-Figure9-1.png"], "answer": "The low-resolution input provides an overall shape constraint for the generated high-resolution image. The head pose and facial expression of the generated high-res images adopt those in the low-res inputs."}, "5": {"question": "What happens when there is a conflict between the low-res image and the feature vector?", "response": {"1705.09966v2-Figure4-1.png": ["1 <s>", "There is a conflict between the low-res image and the feature vector <s>"]}, "referred_figures_names": ["1705.09966v2-Figure4-1.png"], "answer": "The generated high-res digit follows the given class label."}, "6": {"question": "What is the difference between the input and output of the frontal face generation process?", "response": {"1705.09966v2-Figure13-1.png": ["1 <s>", "(b) to (c), (d) to (e) <s>"]}, "referred_figures_names": ["1705.09966v2-Figure13-1.png"], "answer": "The input is a low-resolution frontal face image and a high-resolution side-face image. The output is a high-resolution frontal face image."}, "7": {"question": "How does the proposed method preserve facial details and expression during face swapping?", "response": {"1705.09966v2-Figure11-1.png": ["Yes <s>", "The proposed method preserves facial details and expression during face swapping by altering the appearance of eyes, eyebrows, hairs, etc., while keeping other factors intact, such as head pose, shape of face, and facial expression. <s>"]}, "referred_figures_names": ["1705.09966v2-Figure11-1.png"], "answer": "The proposed method utilizes Light-CNN as both the source of the identity features and face verification loss. This allows the method to transfer the appearance of eyes, eyebrows, hairs, etc., while keeping other factors intact, e.g., head pose, shape of face, and facial expression."}, "8": {"question": "How does the proposed method compare to icGAN in terms of generating images with different hair colors?", "response": {"1705.09966v2-Figure7-1.png": ["Yes <s>", "Generally, our method can generate much better images compared to [13]. <s>"]}, "referred_figures_names": ["1705.09966v2-Figure7-1.png"], "answer": "The proposed method is able to generate images with different hair colors more accurately than icGAN."}, "9": {"question": "What is the role of the attribute vector $z$ in the Conditional CycleGAN network?", "response": {"1705.09966v2-Figure2-1.png": ["Yes <s>", "The role of the attribute vector $z$ in the Conditional CycleGAN network is to guide the generation of high-resolution images with specific attributes, such as blonde hair. <s>"]}, "referred_figures_names": ["1705.09966v2-Figure2-1.png"], "answer": "The attribute vector $z$ provides additional information about the desired attributes of the generated high-resolution face image $\\hat{X}$. This information is used by the generator networks $G_{X \\to Y}$ and $G_{Y \\to X}$ to generate images that are more consistent with the desired attributes."}}