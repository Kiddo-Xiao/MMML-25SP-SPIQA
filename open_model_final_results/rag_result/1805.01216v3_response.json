{"0": {"question": "Which task-oriented dialog system performs the best when the percentage of unseen information in the KB is high?", "response": {"1805.01216v3-Figure1-1.png": ["10 <s>", "The one with the highest percentage of unseen information in the KB is the one that performs the best. <s>"]}, "referred_figures_names": ["1805.01216v3-Figure1-1.png"], "answer": "BoSsNet"}, "1": {"question": "Why did Seq2Seq and Mem2Seq models perform poorly when the percentage of unseen entities in the knowledge base (KB) increased?", "response": {"1805.01216v3-Table4-1.png": ["10% <s>", "The percentage of unseen entities in the knowledge base increased. <s>"]}, "referred_figures_names": ["1805.01216v3-Table4-1.png"], "answer": "Seq2Seq and Mem2Seq models performed poorly because they struggled to capture the semantic representations of unseen entities. This means they couldn't understand the meaning and relationships of new restaurants introduced in the KB. As a result, they were unable to accurately identify the correct restaurant and provide its address when faced with unseen entities."}, "2": {"question": "Which model achieved the highest combined score for informativeness and grammatical correctness on the CamRest dataset?", "response": {"1805.01216v3-Table3-1.png": ["2 <s>", "SMD <s>"]}, "referred_figures_names": ["1805.01216v3-Table3-1.png"], "answer": "The BOSSNET model achieved the highest combined score for informativeness and grammatical correctness on the CamRest dataset."}, "3": {"question": "Can you explain why the BOSSNET with multi-hop encoder performs better on bAbI tasks 3 and 5 compared to the 1-hop encoder, and how this relates to the tasks themselves?", "response": {"1805.01216v3-Table14-1.png": ["Yes <s>", "Yes <s>"]}, "referred_figures_names": ["1805.01216v3-Table14-1.png"], "answer": "The multi-hop encoder performs better on bAbI tasks 3 and 5 because these tasks specifically require inferencing over multiple KB tuples. In other words, the model needs to \"hop\" between different pieces of information in the knowledge base to make the correct inferences and recommendations.\n\nTask 3 involves sorting restaurants by rating, and task 5 requires recommending a restaurant based on user preferences. Both tasks necessitate the model to consider various restaurant attributes and their relationships, which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base."}, "4": {"question": "How does the encoder understand the last user utterance?", "response": {"1805.01216v3-Figure2-1.png": ["<s>", "The encoder understands the last user utterance using only the memory cell representations. The decoder generates the next response using both representations. <s>"]}, "referred_figures_names": ["1805.01216v3-Figure2-1.png"], "answer": "The encoder understands the last user utterance by using the memory cell representations of the dialog history and KB tuples."}, "5": {"question": "Which model performs best on tasks T3 and T3-OOV in terms of per-dialog accuracy, and how does its performance differ between the two test sets?", "response": {"1805.01216v3-Table1-1.png": ["1 <s>", "BOSSNET <s>"]}, "referred_figures_names": ["1805.01216v3-Table1-1.png"], "answer": "The proposed system model (BOSSNET) performs best on both tasks T3 and T3-OOV in terms of per-dialog accuracy. However, its performance is significantly higher on the T3-OOV test set (95.7%) compared to the non-OOV T3 test set (95.2%)."}, "6": {"question": "Why might the authors claim that although BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, it still performs better in conveying necessary entity information?", "response": {"1805.01216v3-Table2-1.png": ["Yes <s>", "The authors claim that BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, but it still performs better in conveying necessary entity information <s>"]}, "referred_figures_names": ["1805.01216v3-Table2-1.png"], "answer": "While BOSSNET has a lower BLEU score than Mem2Seq on SMD, it achieves the highest Entity F1 score on that dataset. This suggests that BOSSNET is better at capturing and including the relevant entities in its responses, even though it may not have as much lexical overlap with the gold responses as Mem2Seq."}, "7": {"question": "Which model performs the best in terms of Entity F1 score when the percentage of unseen entities in the response is low?", "response": {"1805.01216v3-Figure5-1.png": ["1 <s>", "CamRest <s>"]}, "referred_figures_names": ["1805.01216v3-Figure5-1.png"], "answer": "BoSsNet"}, "8": {"question": " \n\nWhat is the difference between the original and pre-processed SMD Navigate data? ", "response": {"1805.01216v3-Figure9-1.png": ["10 <s>", "<s>"]}, "referred_figures_names": ["1805.01216v3-Figure9-1.png"], "answer": " \n\nThe pre-processed SMD Navigate data combines all the properties (such as distance, address) of a point of interest (POI) into a single subject with the object being \"poi\". The original data had separate entries for each property. "}, "9": {"question": "Which model performs best when the percentage of unseen entities in the response is low?", "response": {"1805.01216v3-Figure3-1.png": ["1 <s>", "Per-response accuracy comparison on KA sets <s>"]}, "referred_figures_names": ["1805.01216v3-Figure3-1.png"], "answer": "BoSsNet"}, "10": {"question": "Which task required the highest learning rate and how does this compare to the learning rate used for CamRest?", "response": {"1805.01216v3-Table9-1.png": ["1 <s>", "Table 9: The hyperparameters used to train BOSSNET on the different datasets required the highest learning rate and how does this compare to the learning rate used for CamRest? <s>"]}, "referred_figures_names": ["1805.01216v3-Table9-1.png"], "answer": "Task T1 and T2 required the highest learning rate of 0.001. This is twice the learning rate used for CamRest, which was trained with a learning rate of 0.0005."}, "11": {"question": "What is the difference between the attention weights in the two-level attention model and the one-level attention model?", "response": {"1805.01216v3-Figure7-1.png": ["2 level attention <s>", "The two-level attention model has two levels of attention, while the one-level attention model has only one level of attention. <s>"]}, "referred_figures_names": ["1805.01216v3-Figure7-1.png"], "answer": " The two-level attention model has higher attention weights on the relevant information in the memory, while the one-level attention model has more uniform attention weights."}}