{"0": {"question": "Which method has the highest T-Diff on average for the Vid4 dataset?", "response": {"1811.09393v4-Figure15-1.png": ["10 <s>", "2016-03-01 to 2016-03-31 <s>"]}, "referred_figures_names": ["1811.09393v4-Figure15-1.png"], "answer": "TecoGAN."}, "1": {"question": "Which GAN model is able to generate the most realistic blinking motions?", "response": {"1811.09393v4-Figure8-1.png": ["<s>", "RecycleGAN <s>"]}, "referred_figures_names": ["1811.09393v4-Figure8-1.png"], "answer": "TecoGAN"}, "2": {"question": "Which of the VSR models in the figure achieves the best balance of spatial detail and temporal coherence?", "response": {"1811.09393v4-Figure14-1.png": ["1 <s>", "a) LPIPS <s>"]}, "referred_figures_names": ["1811.09393v4-Figure14-1.png"], "answer": "TecoGAN"}, "3": {"question": "Which method achieves the highest PSNR on the Vid4 data set?", "response": {"1811.09393v4-Table2-1.png": ["1 <s>", "Perceptual Distance to the Ground Truth <s>"]}, "referred_figures_names": ["1811.09393v4-Table2-1.png"], "answer": "DUF"}, "4": {"question": " What is the role of the warped triplets in the conditional VSR Ds,t?", "response": {"1811.09393v4-Figure4-1.png": ["Yes <s>", "Frame-recurrent VSR Generator <s>"]}, "referred_figures_names": ["1811.09393v4-Figure4-1.png"], "answer": " The warped triplets provide additional information about the motion and appearance of the scene, which helps the VSR Ds,t to generate more accurate and realistic results."}, "5": {"question": "How does the PP loss improve the temporal coherence of the video sequence?", "response": {"1811.09393v4-Figure3-1.png": ["<s>", "<s>"]}, "referred_figures_names": ["1811.09393v4-Figure3-1.png"], "answer": "The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence."}, "6": {"question": "What is the role of the Motion Compensation block in the Frame-Recurrent Generator?", "response": {"1811.09393v4-Figure2-1.png": ["Yes <s>", "The role of the Motion Compensation block in the Frame-Recurrent Generator is to compensate for any motion artifacts that may be present in the generated frames. <s>"]}, "referred_figures_names": ["1811.09393v4-Figure2-1.png"], "answer": "The Motion Compensation block estimates the motion between the previous frame and the current frame, and uses this information to warp the previous frame to the current frame. This helps the generator to produce more realistic images by taking into account the temporal information in the video sequence."}, "7": {"question": "Which method produces the least amount of artifacts?", "response": {"1811.09393v4-Figure23-1.png": ["1st row <s>", "TecoGAN\u2296 <s>"]}, "referred_figures_names": ["1811.09393v4-Figure23-1.png"], "answer": "TecoGAN\u2296."}, "8": {"question": "Which method produces the most realistic results for the Vid4 scenes?", "response": {"1811.09393v4-Figure12-1.png": ["1920x368 4K video <s>", "TecoGAN <s>"]}, "referred_figures_names": ["1811.09393v4-Figure12-1.png"], "answer": "TecoGAN."}, "9": {"question": "What is the learning rate for the generator in the DsOnly model?", "response": {"1811.09393v4-Table6-1.png": ["0.1 <s>", "0.001 <s>"]}, "referred_figures_names": ["1811.09393v4-Table6-1.png"], "answer": "5.00E-05"}, "10": {"question": "Why does flow estimation become less accurate near image boundaries?", "response": {"1811.09393v4-Figure22-1.png": ["<s>", "Near image boundaries, flow estimation is less accurate and warping often fails to align content. <s>"]}, "referred_figures_names": ["1811.09393v4-Figure22-1.png"], "answer": "Flow estimation becomes less accurate near image boundaries because there is less information available to estimate the flow. This is because the pixels at the boundaries are only surrounded by pixels on one side, whereas pixels in the interior of the image are surrounded by pixels on all sides."}, "11": {"question": "Which method has the best perceptual performance according to the tOF score?", "response": {"1811.09393v4-Figure18-1.png": ["1 <s>", "Prashnani et al. 2018 on ENet, FRVSR, DUF and TecoGAN for the VSR of Vid4. Bubble size indicates the tOF score. <s>"]}, "referred_figures_names": ["1811.09393v4-Figure18-1.png"], "answer": "TecoGAN."}, "12": {"question": "Which of the methods generated the sharpest details?", "response": {"1811.09393v4-Figure11-1.png": ["1 <s>", "TecoGAN <s>"]}, "referred_figures_names": ["1811.09393v4-Figure11-1.png"], "answer": "TecoGAN"}, "13": {"question": "What is the purpose of the UVT cycle link?", "response": {"1811.09393v4-Figure5-1.png": ["10 <s>", "Unconditional UVT Ds,t <s>"]}, "referred_figures_names": ["1811.09393v4-Figure5-1.png"], "answer": "The UVT cycle link is used to transfer knowledge between two recurrent generators."}, "14": {"question": "What is the purpose of the user study?", "response": {"1811.09393v4-Figure19-1.png": ["1 <s>", "2 <s>"]}, "referred_figures_names": ["1811.09393v4-Figure19-1.png"], "answer": "The user study is designed to test which of two images is closer to a reference video."}}