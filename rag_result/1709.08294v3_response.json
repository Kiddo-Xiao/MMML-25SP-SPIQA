{"0": {"question": "How does the performance of the two-way AdaQA model compare to the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset?", "response": {"1709.08294v3-Table3-1.png": ["10.6% <s>", "The two-way AdaQA model outperforms the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset <s>"]}, "referred_figures_names": ["1709.08294v3-Table3-1.png"], "answer": "The two-way AdaQA model significantly outperforms the one-way AdaQA model and all other CNN-based baseline models on the WikiQA dataset. This is evident from the higher MAP and MRR values achieved by the two-way model (0.7107 and 0.7304 respectively) compared to the one-way model (0.7005 and 0.7161) and the baseline models."}, "1": {"question": "How does the ACNN framework learn context-sensitive filters?", "response": {"1709.08294v3-Figure1-1.png": ["1 <s>", "It learns context-sensitive filters by training a convolutional neural network (CNN) to predict the next word in a sentence based on the previous words. <s>"]}, "referred_figures_names": ["1709.08294v3-Figure1-1.png"], "answer": "The ACNN framework learns context-sensitive filters through two modules: the filter generation module and the adaptive convolution module. The filter generation module produces a set of filters conditioned on the input sentence, while the adaptive convolution module applies the generated filters to an input sentence. The two modules are jointly differentiable, and the overall architecture can be trained in an end-to-end manner."}, "2": {"question": "Which model performed the best on the Quora Question Pairs dataset?", "response": {"1709.08294v3-Table5-1.png": ["2016cn <s>", "Siamese Multi-Perspective CNN <s>"]}, "referred_figures_names": ["1709.08294v3-Table5-1.png"], "answer": "AdaQA (two-way) + att."}, "3": {"question": "Based on the figure, which type of question does ACNN perform the best on?", "response": {"1709.08294v3-Figure3-1.png": ["1 <s>", "(c) t-SNE visualization of learned filter weights <s>"]}, "referred_figures_names": ["1709.08294v3-Figure3-1.png"], "answer": "ACNN performs best on \"Who\" questions."}, "4": {"question": "How does the Adaptive Question Answering (AdaQA) model generate context-aware filters?", "response": {"1709.08294v3-Figure2-1.png": ["1 2 <s>", "<s>"]}, "referred_figures_names": ["1709.08294v3-Figure2-1.png"], "answer": "The AdaQA model generates context-aware filters through the filter generation module. This module takes the question and answer as input and outputs a set of filters that are specific to the question and answer pair."}, "5": {"question": "Based on Table 1, which dataset has the largest vocabulary size and how does this compare to the average number of words per document in that dataset?", "response": {"1709.08294v3-Table1-1.png": ["1 <s>", "The dataset with the largest vocabulary size has 100,000 to 1,000,000 words <s>"]}, "referred_figures_names": ["1709.08294v3-Table1-1.png"], "answer": "The Yelp P. dataset has the largest vocabulary size with 25,709 unique words. This is significantly larger than the average number of words per document in the dataset, which is 138."}, "6": {"question": "Can you explain why the authors claim that their S-ACNN model with a single filter is \"much more expressive\" than the basic S-CNN model, even though it doesn't achieve the best overall performance on either dataset?", "response": {"1709.08294v3-Table2-1.png": ["Yes <s>", "The authors claim that their S-ACNN model with a single filter is \"much more expressive\" than the basic S-CNN model, even though it doesn't achieve the best overall performance on either dataset, because the S-ACNN model has the ability to learn more complex patterns and relationships within the data. <s>"]}, "referred_figures_names": ["1709.08294v3-Table2-1.png"], "answer": "The authors claim that S-ACNN is more expressive than S-CNN because, despite having only one filter, it significantly outperforms S-CNN on both datasets. This suggests that the filter-generation module in ACNN allows for greater flexibility and adaptability, enabling the model to better capture the specific features of each sentence."}, "7": {"question": "Which model performs best on the SelQA dataset and how does it compare to the baseline CNN model reported in Jurczyk et al. (2016)?", "response": {"1709.08294v3-Table4-1.png": ["\u2021 <s>", "\u2021 <s>"]}, "referred_figures_names": ["1709.08294v3-Table4-1.png"], "answer": "The AdaQA (two-way) + att. model achieves the best performance on the SelQA dataset with a MAP score of 0.9021 and an MRR score of 0.9103. Compared to the baseline CNN model from Jurczyk et al. (2016) which has a MAP score of 0.8320 and an MRR score of 0.8420, the AdaQA (two-way) + att. model demonstrates a significant improvement in both metrics."}}