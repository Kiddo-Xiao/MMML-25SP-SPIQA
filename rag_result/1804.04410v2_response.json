{"0": {"question": "How are documents ranked and pruned in the telescoping architecture?", "response": {"1804.04410v2-Figure1-1.png": ["1 <s>", "Rank-and-prune <s>"]}, "referred_figures_names": ["1804.04410v2-Figure1-1.png"], "answer": "Documents are first matched using a pre-defined match plan. Then, they are passed through additional rank-and-prune stages, which are implemented as a cascade of machine learning models."}, "1": {"question": "How does the RL policy compare to the baseline in terms of index blocks accessed?", "response": {"1804.04410v2-Figure2-1.png": ["1 <s>", "The RL policy accesses fewer index blocks than the baseline for CAT2 queries on the weighted set. <s>"]}, "referred_figures_names": ["1804.04410v2-Figure2-1.png"], "answer": "The RL policy accesses fewer index blocks than the baseline."}, "2": {"question": "How does the performance of the learned policy compare to the production baseline for CAT2 queries in terms of relevance and efficiency?", "response": {"1804.04410v2-Table1-1.png": ["No <s>", "Significant reduction in index blocks accessed, although at the cost of some loss in relevance. <s>"]}, "referred_figures_names": ["1804.04410v2-Table1-1.png"], "answer": "For CAT2 queries, the learned policy shows a slight improvement in relevance (NCG) for the weighted set and a significant reduction in index blocks accessed for both weighted and unweighted sets."}}