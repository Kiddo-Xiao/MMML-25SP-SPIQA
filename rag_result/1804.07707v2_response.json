{"0": {"question": "How does the performance of the proposed model compare to other models when trained on the LDC2017T10 dataset, and what does this suggest about the effectiveness of incorporating syntax into the model?", "response": {"1804.07707v2-Table3-1.png": ["Yes <s>", "0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}, "referred_figures_names": ["1804.07707v2-Table3-1.png"], "answer": "When trained on the LDC2017T10 dataset, the proposed model achieves the highest BLEU scores on both Dev and Test sets compared to other models listed in the table. This suggests that incorporating syntax into the model significantly improves its performance in generating text from AMR representations."}, "1": {"question": "How does explicitly modeling meaning-preserving invariances impact the generation of paraphrases?", "response": {"1804.07707v2-Table2-1.png": ["Yes <s>", "It increases the number of acceptable realisations. <s>"]}, "referred_figures_names": ["1804.07707v2-Table2-1.png"], "answer": "Explicitly modeling meaning-preserving invariances leads to the generation of better paraphrases."}, "2": {"question": "Which model performs the best at predicting the delexicalised constituency tree of an example, and how much better does it perform compared to the baseline model in terms of unlabelled F1 score?", "response": {"1804.07707v2-Table1-1.png": ["1 <s>", "Model 1 <s>"]}, "referred_figures_names": ["1804.07707v2-Table1-1.png"], "answer": "The Text-to-parse model performs the best at predicting the delexicalised constituency tree, achieving an unlabelled F1 score of 87.5. This is significantly higher than the baseline Unconditional model, which achieves an unlabelled F1 score of 38.5. The Text-to-parse model therefore performs approximately 49 points better than the baseline."}}