{"0": {"question": "How do the different methods compare in terms of their ability to generate realistic faces?", "response": {"1812.06589v2-Figure6-1.png": ["1 <s>", "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88"]}, "referred_figures_names": ["1812.06589v2-Figure6-1.png"], "answer": "The baseline method generates faces that are blurry and unrealistic, while the other methods generate faces that are more realistic."}, "1": {"question": "What is the effect of adding DA to the baseline method?", "response": {"1812.06589v2-Table3-1.png": ["0 <s>", "0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}, "referred_figures_names": ["1812.06589v2-Table3-1.png"], "answer": "Adding DA to the baseline method improves the PSNR and SSIM values, while slightly decreasing the LMD value."}, "2": {"question": "Which method performed the best on the GRID dataset?", "response": {"1812.06589v2-Table2-1.png": ["1 <s>", "Cross-dataset evaluation of our method on GRID dataset pre-trained on LRW dataset <s>"]}, "referred_figures_names": ["1812.06589v2-Table2-1.png"], "answer": "AMIE (Ours)"}, "3": {"question": "What is the role of the frame discriminator in the proposed method?", "response": {"1812.06589v2-Figure2-1.png": ["1 <s>", "Determine if the input image is real or fake <s>"]}, "referred_figures_names": ["1812.06589v2-Figure2-1.png"], "answer": "The frame discriminator is used to detect whether the generated frame and audio are matched or not."}, "4": {"question": "How does the dynamic attention block improve the transition of generated video for arbitrary identities?", "response": {"1812.06589v2-Figure4-1.png": ["Yes <s>", "The dynamic attention block improves the transition of generated video for arbitrary identities by allowing the model to focus on different parts of the face at different times. <s>"]}, "referred_figures_names": ["1812.06589v2-Figure4-1.png"], "answer": "The dynamic attention block decouples the lip-related and identity-related information, allowing the network to focus on the most important area for generating realistic talking faces."}, "5": {"question": "Which method, AMIE or MINE, produces generated frames that are closer in distribution to the real frames?", "response": {"1812.06589v2-Figure3-1.png": ["<s>", "MINE <s>"]}, "referred_figures_names": ["1812.06589v2-Figure3-1.png"], "answer": "MINE"}, "6": {"question": " What are the limitations of the Zhou \\textit{et al.} and Chen \\textit{et al.} methods for generating talking-face videos, as compared to the method proposed in the paper?", "response": {"1812.06589v2-Figure5-1.png": ["Yes <s>", "1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66."]}, "referred_figures_names": ["1812.06589v2-Figure5-1.png"], "answer": " The Zhou \\textit{et al.} method suffers from a \"zoom-in-and-out\" effect, while the Chen \\textit{et al.} method produces lip shapes that differ from the real ones."}, "7": {"question": "Which method performed the best according to the LMD metric?", "response": {"1812.06589v2-Table1-1.png": ["1 2 <s>", "Method 1 <s>"]}, "referred_figures_names": ["1812.06589v2-Table1-1.png"], "answer": "AMIE (Ours)"}}